#!/usr/bin/python3
#
#  wfa-cgi - Workflow Allocator CGI service
#
#  Andrew McNab, University of Manchester.
#  Copyright (c) 2013-22. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or
#  without modification, are permitted provided that the following
#  conditions are met:
#
#    o Redistributions of source code must retain the above
#      copyright notice, this list of conditions and the following
#      disclaimer. 
#    o Redistributions in binary form must reproduce the above
#      copyright notice, this list of conditions and the following
#      disclaimer in the documentation and/or other materials
#      provided with the distribution. 
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
#  CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
#  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
#  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
#  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
#  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
#  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#

#  This CGI script must be run from an Apache httpd server with
#  X.509 proxy certificates enabled. On a systemd system (like 
#  CentOS 7) you need to enable this in OpenSSL inside mod_ssl
#  by adding this line to /usr/lib/systemd/system/httpd.service
#  in the [Service] section:
#
#  Environment=OPENSSL_ALLOW_PROXY_CERTS=1

import os
import io
import re
import sys
import time
import json
import uuid
import string
import tarfile
import MySQLdb

# wfs/conf.py must define these variables in a way that is both
# valid Python and valid Bash!
#
# mysqlUser='username'
# mysqlPassword='PAsSWoRd'
#
import wfs

def httpError(code, message = None):
  print('Status: ' + code)
  print('Content-Type: text/plain')
  print()
  if message:
    print(message)
  sys.exit(0)

# Successfully identified the request+stage and files so get the 
# bootstrap for this stage and return it
def getBootstrap(stage):

  try:
    query = ("SELECT bootstrap FROM bootstraps "
             "WHERE request_id=%d AND stage_id=%d" 
             % (stage['request_id'], stage['stage_id']))

    wfs.db.cur.execute(query)
    row = wfs.db.cur.fetchone()
    bootstrap = row['bootstrap']
  except:
    return None
  
  return bootstrap

def addFileToTarFile(tar, name, value):

  buffer = io.BytesIO()
  buffer.write(value.encode())

  info       = tarfile.TarInfo(name = name)
  info.size  = buffer.tell()
  info.mtime = time.time()

  buffer.seek(0)
  tar.addfile(tarinfo = info, fileobj = buffer)

# Make an uncompressed tar file to return to the generic job. 
# The generic job 'owns' the files in the tar file, one of which is the
# boostrap.sh script which 'owned' by the user. The generic job has the 
# responsibility to upload the output files matching the patterns defined as
# part of the stage 
def makeTarFile(jsonDict, jobDict, stage, cookie):

  buffer = io.BytesIO()
  tar = tarfile.TarFile(fileobj = buffer, mode = "w")

  # Get and add the bootstrap script
  bootstrap = getBootstrap(stage)
  if not bootstrap:
    return None

  addFileToTarFile(tar, "wfs-bootstrap.sh", bootstrap)

  # Create a file containing the output file patterns
  try:
    query = ("SELECT dataset,file_scope,file_pattern,for_next_stage "
             "FROM stages_outputs "
             "WHERE request_id=%d AND stage_id=%d" 
             % (stage['request_id'], stage['stage_id']))

    wfs.db.cur.execute(query)
    rows = wfs.db.cur.fetchall()
  except:
    return None

  patternsFile = ''

  for row in rows:
    patternsFile += (str(row['for_next_stage']) + ' ' + 
                     row['dataset'] + ' ' +
                     row['file_scope'] + ' ' +
                     row['file_pattern'] + '\n')
    
  addFileToTarFile(tar, 'wfs-output-patterns.txt', patternsFile)

  # Create an ordered output RSE list specific to this stage
  try:
    query = ('SELECT rse_name '
             'FROM storages '
             'LEFT JOIN stages_output_storages '
             'ON (storages.rse_id=stages_output_storages.rse_id '
             'AND stages_output_storages.request_id=%d '
             'AND stages_output_storages.stage_id=%d) '
             'LEFT JOIN sites_storages '
             'ON (stages_output_storages.rse_id=sites_storages.rse_id '
             'AND sites_storages.site_id=%d) '
             'WHERE (use_for_output OR '
             'stages_output_storages.rse_id IS NOT NULL) AND '
             'site_storages.distance IS NOT NULL AND '
             'storages.occupancy < 1.0 AND '
             'storages.rse_write AND '
             'ORDER BY (stages_output_storages.rse_id IS NULL),'
             'distance,occupancy,RAND()' 
             % (stage['request_id'], 
                stage['stage_id'],
                jobDict['site_id']                
               )
            )

    wfs.db.cur.execute(query)
    rseRows = wfs.db.cur.fetchall()
  except:
    return None

  outputRseList = []
  for rseRow in rseRows:
    outputRseList.append(rseRow['rse_name'])
      
  addFileToTarFile(tar, 'wfs-env.sh', 
       (
         'export WFS_REQUEST_ID=' + str(stage['request_id']) + '\n' +
         'export WFS_STAGE_ID=' + str(stage['stage_id']) + '\n' +
         'export WFS_COOKIE="' + cookie + '"\n' +
         'export WFS_OUTPUT_RSE_LIST="' + ' '.join(outputRseList) + '"\n'
       )  
                  )
                  
  addFileToTarFile(tar, 'wfs-get-file.json', 
       (
         '{\n' +
         '"method" : "get_file",\n' +
         '"jobsub_id" : "' + str(jsonDict['jobsub_id']) + '",\n' +
         '"cookie" : "' + cookie + '"\n' 
         '}\n'
       )
                  )
                  
  tar.close()  
  return buffer.getvalue()

# Try to get the stage with the highest priority files still unallocated
def getStageMethod(jsonDict):

  if 'jobsub_id' not in jsonDict or \
     not wfs.db.stringIsJobsubID(jsonDict['jobsub_id']):
    httpError('400 Bad Request', 'Missing jobsub_id in JSON')

  # Check jsonDict contains required integer values (eg rss_bytes)
  for name in ['rss_bytes', 'processors', 'wall_seconds']:  
    try:
      n = int(jsonDict[name])
    except:
      httpError('400 Bad Request', 'Missing/invalid integer value(s) in JSON')

  # Check jsonDict contains required string values
  for name in ['cpuinfo', 'os_release', 'hostname']:
    if name not in jsonDict or not wfs.db.stringNoQuotes(jsonDict[name]):
      httpError('400 Bad Request', 'Missing/invalid value(s) in JSON')

  # Find details of the job
  jobDict = wfs.allocator.makeJobDict(jsonDict['jobsub_id'])

  if jobDict['error_message']:
    httpError('400 Bad Request', jobDict['error_message'])

  # Use the Just In Time decision making: identify the best request+stage 
  # candidate combination at this moment
  stage = wfs.allocator.findStage(jobDict)

  if not stage:
    # No stages/files eligible to be processed by this job
    try:
      query = ('UPDATE slot_sizes SET last_no_match_time=NOW() '
               'WHERE slot_size_id=' + str(jobDict['slot_size_id']))
             
      wfs.db.cur.execute(query)    
    except Exception as e:
      pass

    httpError('404 Not Found', 'No eligible stages found')

  cookie = str(uuid.uuid4())

  try:
    query = ('UPDATE jobs SET '
             'allocation_time=NOW(),' 
             'allocation_state="started",'
             'allocator_name="' + allocatorName + '",' 
             'request_id=' + str(stage['request_id']) + ','
             'stage_id=' + str(stage['stage_id']) + ','
             'cpuinfo="' + str(jsonDict['cpuinfo']) + '",' 
             'os_release="' + str(jsonDict['os_release']) + '",' 
             'hostname="' + str(jsonDict['hostname']) + '",' 
             'rss_bytes=' + str(jsonDict['rss_bytes']) + ',' 
             'processors=' + str(jsonDict['processors']) + ',' 
             'wall_seconds=' + str(jsonDict['wall_seconds']) + ',' 
             'cookie="' + cookie + '" ' 
             'WHERE jobsub_id="' + str(jsonDict['jobsub_id']) + '"'
            )
    wfs.db.cur.execute(query)
  except Exception as e:
    httpError('500 Internal Server Error', 
              'Workflow allocator failed: ' + str(e))

  try:
    query = ('UPDATE slot_sizes SET last_allocation_time=NOW() '
             'WHERE slot_size_id=' + str(jobDict['slot_size_id']))
             
    wfs.db.cur.execute(query)
    
  except Exception as e:
    # We log this but carry on - someone testing?
    httpError('500 Internal Server Error',
              'Workflow allocator failed: ' + str(e))

  tarFile = makeTarFile(jsonDict, jobDict, stage, cookie)
  
  if not tarFile:
    httpError('500 Internal Server Error', 'Failed to create tar file')
        
  wfs.allocator.updateStageCounts(stage['request_id'], 
                                  stage['stage_id'])
 
  # All done so commit the job details.
  # We do this before the HTTP response in case
  # it is received ok by the job and run 
  # but times out and fails here on the server side
  wfs.db.conn.commit()

  # Return the script to the workflow job 
  print('Status: 200 OK')
  print('Content-Type: application/x-tar')
  print()
  sys.stdout.flush()
  sys.stdout.buffer.write(tarFile)
  sys.exit(0)
   
# Get an unallocated file from the given request+stage
def getFileMethod(jsonDict):

  if 'jobsub_id' not in jsonDict or \
     not wfs.db.stringIsJobsubID(jsonDict['jobsub_id']):
    httpError('400 Bad Request', 'Missing/invalid jobsub_id in JSON')

  if 'cookie' not in jsonDict or \
     not wfs.db.stringNoQuotes(jsonDict['cookie']):
    httpError('400 Bad Request', 'Missing/invalid cookie in JSON')

  # Lookup job details
  jobDict = wfs.allocator.makeJobDict(jsonDict['jobsub_id'],
                                      jsonDict['cookie'])
                                          
  if jobDict['error_message']:
    httpError('400 Bad Request', jobDict['error_message'])

  if jobDict['allocation_state'] != 'started' and \
     jobDict['allocation_state'] != 'processing':
    httpError('403 Forbidden', 'Job in wrong state to find file')
    
  # Create a stage dictionary with the next file in this stage  
  oneFile = wfs.allocator.findFile(jobDict)

  if oneFile['error_message']:
    httpError('500 Internal Server Error', 
              'Failed finding one file: ' + oneFile['error_message'])
  
  if oneFile['file_did']:
    if jobDict['allocation_state'] == 'started':
      try:
        query = ('UPDATE jobs SET allocation_state="processing" ' +
                 'WHERE jobsub_id="' + jsonDict['jobsub_id'] + '"'
                )
        wfs.db.cur.execute(query)
        wfs.allocator.updateStageCounts(jobDict['request_id'], 
                                        jobDict['stage_id'])

      except Exception as e:
        httpError('500 Internal Server Error',
                  'Unable to update job to processing: ' + str(e))


    # All done so commit the allocation and updates
    # We do this before the HTTP response in case
    # it is received ok by the job and processed
    # but times out and fails here on the server side
    wfs.db.conn.commit()

    # Now tell the job what file to process and where it is
    print('Status: 200 OK')
    print('Content-Type: text/plain')
    print()
    print(oneFile['file_did'] +  ' ' + 
          oneFile['pfn'] + ' ' + 
          oneFile['rse_name'])

    sys.exit(0)

  # No file eligible to be processed by this job
  httpError('404 Not Found', 'No eligible file found')

def updateFileProcessing(fileList, state, wfsJobID, requestID, stageID):

  processedList = []

  try:
    for fileDid in fileList:
      if '"' in fileDid or "'" in fileDid:
        continue

      processedList.append('files.file_did="' + str(fileDid) + '"')
  except:
    return

  # Update the files the job did or did not manage to process
  if processedList:
    try:
      query = ('UPDATE files SET state="' + state + '" '
               'WHERE (' + ' OR '.join(processedList) + ') '
               'AND request_id=' + str(requestID) + ' '
               'AND stage_id=' + str(stageID) + ' '
               'AND state="allocated"')
      wfs.db.cur.execute(query)
    except:
      pass

    if state == 'processed':
      try:
        query = ('UPDATE allocations SET processed=TRUE,'
                 'processed_time=NOW() '
                 'WHERE wfs_job_id=%d AND '
                 'allocations.file_id IN (SELECT files.file_id FROM files '
                 'WHERE files.request_id=%d AND files.stage_id=%d '
                 'AND (%s)) '
                 'ORDER BY allocation_id DESC LIMIT 1'
                 % (wfsJobID, 
                    requestID,
                    stageID,
                    ' OR '.join(processedList)))

        wfs.db.cur.execute(query)
      except:
        pass
    
# Deal with the output files needed by the next stage
def processNextStageOutputs(nextStageOutputs, requestID, stageID):

  try:
    for outputDid in nextStageOutputs:
      
      if '"' in outputDid or "'" in outputDid:
        continue

      try:
        query = ('INSERT INTO files SET state="find_replicas",'
                 'file_did="'  + str(outputDid) + '",'
                 'request_id=' + str(requestID) + ','
                 'stage_id='   + str(stageID + 1)
                )
        wfs.db.cur.execute(query)
      except:
        # Just do our best if anything goes wrong for now
        # Should decide what to do in these partial failure cases
        pass

  except:
    return
                
def resultsMethod(jsonDict):

  if 'jobsub_id' not in jsonDict or \
     not wfs.db.stringIsJobsubID(jsonDict['jobsub_id']):
    httpError('400 Bad Request', 'Missing jobsub_id in JSON')

  if 'cookie' not in jsonDict or \
     not wfs.db.stringNoQuotes(jsonDict['cookie']):
    httpError('400 Bad Request', 'Missing/invalid cookie in JSON')

  # Check jsonDict contains required values (eg cookie)
  for name in ['processed_inputs', 
               'unprocessed_inputs', 'next_stage_outputs']:
    if name not in jsonDict:
      httpError('400 Bad Request','Missing value (%s) in JSON' % name)
      
    for fileDID in jsonDict[name]:
      if not wfs.db.stringNoQuotes(fileDID):    
        httpError('400 Bad Request', ('Invalid DID in ' + name))


  try:
    query = ('SELECT wfs_job_id, request_id, stage_id, cookie '
             'FROM jobs WHERE jobsub_id="' + jsonDict['jobsub_id'] + '"')

    wfs.db.cur.execute(query)
    row = wfs.db.cur.fetchone()

    wfsJobID  = int(row['wfs_job_id'])
    requestID = int(row['request_id'])
    stageID   = int(row['stage_id'])
  except:
    httpError('500 Internal Server Error', 'Failed finding job')

  if not row['cookie'] or row['cookie'] != jsonDict['cookie']:
    httpError('403 Forbidden', 'Cookie mismatch')
    
  updateFileProcessing(jsonDict['processed_inputs'], 'processed',
                       wfsJobID, requestID, stageID)

  updateFileProcessing(jsonDict['unprocessed_inputs'], 'unprocessed',
                       wfsJobID, requestID, stageID)

  processNextStageOutputs(jsonDict['next_stage_outputs'], requestID, stageID)
  
  wfs.allocator.updateStageCounts(requestID, stageID)

  try:
    query = ('UPDATE jobs SET allocation_state="finished",'
             'finished_time=NOW() '
             'WHERE jobsub_id="' + jsonDict['jobsub_id'] + '"')

    wfs.db.cur.execute(query)
  except Exception as e:
    httpError('500 Internal Server Error', 'Failed updating jobs: ' + str(e))

  try:
    query = ('INSERT INTO jobs_logs SET wfs_job_id=' + str(wfsJobID) + ','
             'bootstrap_log="' +
             jsonDict['bootstrap_log'].replace('"', '_') + '"')

    wfs.db.cur.execute(query)
  except Exception as e:
    httpError('500 Internal Server Error', 'Failed saving job log: ' + str(e))

  # Commit everything, before we return OK to the job
  wfs.db.conn.commit()

  # Return OK to the job
  print('Status: 200 OK')
  print()
  sys.exit(0)

def checkJobUser():

  # Use certificates and proxies for now; will transition to tokens in future
  if 'SSL_CLIENT_S_DN' not in os.environ or not os.environ['SSL_CLIENT_S_DN']:
    httpError('403 Forbidden', 'Forbidden - identity not provided')

  # Convert to the older format with slashes 
  clientDN='/'+'/'.join(os.environ['SSL_CLIENT_S_DN'].split(',')[::-1])

  query = ('SELECT users.generic_jobs FROM x509 '
           'LEFT JOIN users ON users.user_id=x509.user_id '
           'WHERE x509dn=LEFT("%s",LENGTH(x509dn)) ORDER BY users.user_id' % 
           clientDN.replace('\\','\\\\').replace('"','\\"'))

  try:
    wfs.db.cur.execute(query)
    rows = wfs.db.cur.fetchall()
  except:
    httpError('500 Internal Server Error', 'Error reading database')

  # User must be have generic_jobs=TRUE
  if not rows[0]['generic_jobs']:
    httpError('403 Forbidden', 'Forbidden - authorized identity not provided')

#
# PROGRAM MAIN
#

# Quickly reject random GETs etc (if not handled by Apache already)
if os.environ['REQUEST_METHOD'] != 'POST':
    httpError('405 Method not allowed', 'We only support POST')

# Create a unique ID string for this instance that may also help in debugging
allocatorName = "%s:%d:%f" % (os.uname()[1], os.getpid(), time.time())

# Get the JSON document POSTed to us
try:
  jsonDict = json.load(sys.stdin)
except:
  httpError('400 Bad Request', 'Failed to parse JSON')

# Check jsonDict specifies a method
if 'method' not in jsonDict:
  httpError('400 Bad Request', 'Missing method in JSON')

# Do as many checks as we can before connecting to the database here
try:
  wfs.db.conn = MySQLdb.connect(host="localhost", user=wfs.conf.mysqlUser, 
                                passwd=wfs.conf.mysqlPassword, db='wfdb')
  wfs.db.conn.autocommit(False)
  wfs.db.cur = wfs.db.conn.cursor(MySQLdb.cursors.DictCursor) 
except:
  httpError('500 Internal Server Error', 'Problem with database connection')

# Get the stage for the job to work on
if jsonDict['method'] == 'get_stage':
  # Fails with an HTTP error and exit if authorized ID not given
  checkJobUser()

  getStageMethod(jsonDict)

# Get one or more files to process  
elif jsonDict['method'] == 'get_file':
  getFileMethod(jsonDict)
  
# Return results of processing files
elif jsonDict['method'] == 'return_results':
  resultsMethod(jsonDict)

else:
  httpError('400 Bad Request', 'Method in JSON not recognised')

