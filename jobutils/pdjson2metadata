#!/usr/bin/env python3 
#
# Convert protoDUNE metadata from extractor_prod.py into JSON suitable to be 
# the value of the "metadata" key in the JSON sent to MetaCat
#
# THIS IS NOT REALLY PART OF justIN AND IT SHOULD BE INCORPORATED INTO THE 
# SCRIPTS ASSOCIATED WITH APPLICATIONS, LIKE extractor_prod.py !
#
# Adapted from 
# https://github.com/ivmfnal/protodune/blob/main/tools/declare_meta.py
# to write out modified JSON rather than uploading it. This allows the script
# to be run inside jobscripts supplied by users.
#
# A version can be found in the jobutils area of the justIN UPS product
# in cvmfs
#

import sys, json

coreAttributes = {
    "event_count":  "core.event_count",
    "file_type"  :  "core.file_type", 
    "file_format":  "core.file_format",
    "data_tier"  :  "core.data_tier", 
    "data_stream":  "core.data_stream", 
    "events"     :  "core.events",
    "first_event":  "core.first_event_number",
    "last_event" :  "core.last_event_number",
    "event_count":  "core.event_count",
    "application":  "core.application",
    "start_time" :  "core.start_time",
    "end_time"   :  "core.end_time",
    "user"       :  None,
    "group"      :  None
}
   
try:
  inputMetadata = json.load(open(sys.argv[1], "r"))
except Exception as e:
  print("Error reading metadata from file: " + str(e), file=sys.stderr)
  sys.exit(1)

allInputDids = []
if len(sys.argv) > 2:
  try:
    for line in open(sys.argv[2], "r").read().splitlines():
      allInputDids.append(line)

  except Exception as e:
    print("Error read all input DIDs file: " + str(e), file=sys.stderr)
    sys.exit(2)

inputMetadata.pop("file_size", None)
inputMetadata.pop("checksum", None)
inputMetadata.pop("file_name", None)

# Most of the metadata goes in "metadata" within the outer dictionary
outputMetadata = { "metadata": {}}

runsSubruns = set()
runType = None
runs = set()
for run, subrun, rtype in inputMetadata.pop("runs", []):
  runType = rtype
  runs.add(run)
  runsSubruns.add(100000 * run + subrun)

outputMetadata["metadata"]["core.runs_subruns"] = sorted(list(runsSubruns))
outputMetadata["metadata"]["core.runs"] = sorted(list(runs))
outputMetadata["metadata"]["core.run_type"] = runType

for name, value in inputMetadata.items():
  if name == 'parents':
    parentDids = []
    for parent in value:
      matchingDid = None
      for did in allInputDids:
        if did.endswith(parent["file_name"]):
          matchingDid = did
          break

      if matchingDid:
        parentDids.append({ "did" : matchingDid })
      else:
        print("No matching input DID for file %s with parent file_name %s- exiting" 
              % (str(parent), str(parent["file_name"])),
              file=sys.stderr)
        sys.exit(3)
    
    # Add the list of { "did": "..." } dictionaries to top level
    outputMetadata["parents"] = parentDids
      
  else:
    if '.' in name:
      outputMetadata["metadata"][name] = value
    else:
      if name in coreAttributes:
        if coreAttributes[name]:
          outputMetadata["metadata"][coreAttributes[name]] = value
      else:
        outputMetadata["metadata"]['x.' + name] = value
    
outputMetadata["metadata"].setdefault("core.event_count", 
                len(outputMetadata["metadata"].get("core.events", [])))
 
json.dump(outputMetadata, sys.stdout, indent=4, sort_keys=True)
