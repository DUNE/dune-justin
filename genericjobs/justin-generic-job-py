#!/usr/bin/env python3
#
# justin-generic-job-py - HTCondor job submitted by justin-job-factory agent
#
# Copyright 2013-23, Andrew McNab for the University of Manchester
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import sys
import ssl
import time
import json
import glob
import hmac
import hashlib
import base64
import urllib
import urllib.request
import subprocess

# Three globals used again and again
siteName        = 'XX_UNKNOWN'
jobsubJobID     = None
justinJobSecret = '###justin_job_secret###'

def logLine(text):
  print(time.strftime('%b %d %H:%M:%S ' + text + '\n'))

def sendJsonURL(url, sendDict):

  sendDict['jobsub_id']   = jobsubJobID
  sendDict['secret_time'] = str(int(time.time()))
  sendDict['secret_hash'] = hmac.new(bytes(justinJobSecret, 'UTF-8'),
                                     (sendDict['method'] +
                                      sendDict['secret_time'] +
                                      jobsubJobID
                                     ).encode(),
                                     hashlib.sha256).hexdigest()

  httpRequest = urllib.request.Request(url,
                   headers = { 'User-Agent'       : 'justin-generic-job',
                               'X-Jobid'          : jobsubJobID,
                               'X-DUNE-Site-Name' : siteName,
                               'Expect'           : ''
                             },
                   data = json.dumps(sendDict).encode(),
                   method = 'POST')
  sslContext = ssl.SSLContext()
  sslContext.verify_mode = ssl.CERT_REQUIRED
  sslContext.load_verify_locations(capath = '/etc/grid-security/certificates')

  try:
    response = urllib.request.urlopen(httpRequest, context = sslContext)
  except urllib.error.URLError as e:
    try:
      httpCode = e.code
    except:
      httpCode = 0

    logLine('Get JSON URL returns HTTP code %d' % httpCode)
    logLine(e.read().decode('utf-8'))
    return { 'status' : httpCode }

  except Exception as e:
    logLine('Get JSON URL request fails: ' + str(e))
    return { 'status' : 0 }

  try:
    responseString = response.read().decode('utf-8')
  except:
    logLine('Failed reading response: ' + str(e))
    return { 'status' : 1 }
  
# ONCE WE FINISH MOVING TO PYTHON GENERIC JOB THEN ALLOCATOR SHOULD RETURN
# THE TOKEN IN A JSON DOCUMENT AND WE CAN DROP THIS SPECIAL HANDLING
  if sendDict['method'] == 'record_results':
    receivedDict = { 'user_access_token' : responseString }
  elif len(responseString) == 0:
    receivedDict = {}
  else:
    try:
      receivedDict = json.loads(responseString)
    except Exception as e:  
      logLine('Failed loading json: ' + str(e))
      return { 'status' : 1 }

  receivedDict['status'] = response.status
  return receivedDict

def jobAborted(httpCode, abortedMethod, rseName):

  jobAbortedDict = { "method"         : "job_aborted",
                     "http_code"      : httpCode,
                     "aborted_method" : abortedMethod,
                     "rse_name"       : rseName
                   }

  sendJsonURL(
    'https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/job_aborted_'
     + str(httpCode),
    jobAbortedDict)

def executeMetaCatCommand(args):

  for i in range(1, 4):  
    ret = os.system(
     'source /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh ; '
     'setup metacat ; '
     'export METACAT_AUTH_SERVER_URL=https://metacat.fnal.gov:8143/auth/dune ; '
     'export METACAT_SERVER_URL=https://metacat.fnal.gov:9443/dune_meta_demo/app ; '
     'metacat auth login -m x509 dunepro ; '
     'metacat %s' % args)
     
    if ret == 0:
      break

    time.sleep(1)

  return ret
  
def executeRucioCommand(args):

  for i in range(1, 4):
    ret = os.system(
     'source /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh ; '
     'setup rucio ; '
     'unset GFAL_CONFIG_DIR GFAL_PLUGIN_DIR ; '
     'rucio --account dunepro --auth-strategy x509 %s' % args)

    if ret == 0:
      break

    time.sleep(1)

  return ret
  
def webdavUpload(fileName, destination):
# THIS WILL BE REPLACED WITH THE python3 CODE OF justin-webdav-upload ITSELF!
  return os.system(
    '/cvmfs/dune.opensciencegrid.org/products/dune/justin/pro/NULL/'
    'bin/justin-webdav-upload '
    '--verbose '
    '--token-file user-upload-token '
    '--source-file "home/workspace/%s" '
    '--destination-directory %s' % (fileName, destination))

def updateMetadataTmp(fileScope, fileName, 
                      getStageDict, receivedDict, recordResultsDict):
  try:
    metadata = json.load(open('home/workspace/' + fileName + '.json', 'r'))
  except FileNotFoundError:
    metadata = { "metadata" : {} }
  except Exception as e:
    logLine("File home/workspace/%s.json exists but JSON load fails: %s" % 
            (fileName, str(e)))
    raise

  metadata['size']      = os.path.getsize('home/workspace/' + fileName)
  metadata['namespace'] = fileScope
  metadata['name']      = fileName
  metadata['metadata']['DUNE.workflow'] = {}

  metadata['metadata']['DUNE.workflow']['site_name'] \
   = getStageDict['site_name'] 
  metadata['metadata']['DUNE.workflow']['request_id'] \
   = receivedDict['request_id']
  metadata['metadata']['DUNE.workflow']['stage_id'] \
   = receivedDict['stage_id']
  metadata['metadata']['DUNE.workflow']['hostname'] \
   = getStageDict['hostname']

  metadata['metadata']['DUNE.workflow']['jobscript_start'] \
   = recordResultsDict['jobscript_start']
  metadata['metadata']['DUNE.workflow']['jobscript_finish'] \
   = recordResultsDict['jobscript_finish']

  metadata['metadata']['DUNE.workflow']['jobscript_real_seconds'] \
   = 0
  metadata['metadata']['DUNE.workflow']['jobscript_cpu_seconds'] \
   = 0

  metadata['metadata']['DUNE.workflow']['cpuinfo'] \
   = getStageDict['cpuinfo']
  metadata['metadata']['DUNE.workflow']['os_release'] \
   = getStageDict['os_release']
  metadata['metadata']['DUNE.workflow']['job_id'] \
   = jobsubJobID

  with open('tmp.json', 'w') as f:
    f.write(json.dumps(metadata, indent = 4, sort_keys = True))
  
########################################################################
logLine('====Start of justin-generic-job====')

for i in os.environ:
 print('%s=%s' % (i, os.environ[i]))

clusterID = None
procID    = 0

try:
  for line in open(os.environ['_CONDOR_JOB_AD'],'r').readlines():
    if line.startswith('ClusterId = '):
      clusterID = int(line.split('=')[1].strip())

    if line.startswith('ProcId = '):
      procID = int(line.split('=')[1].strip())
except:
  logLine('Failed getting cluster/proc IDs - aborting')
  sys.exit(1)

if clusterID:
  jobsubJobID = ('%d.%d@justin-prod-sched01.dune.hep.ac.uk'
                 % (clusterID, procID))
else:
  logLine('Cluster ID not found - aborting')
  sys.exit(1)

siteName = os.environ.get('GLIDEIN_DUNESite', 'XX_UNKNOWN')

# Subprocess to send regular heartbeats
heartbeatsPID = os.fork()

if heartbeatsPID == 0:

  # Redirect stdout/stderr
  so = open('heartbeats.log', 'a+')
  os.dup2(so.fileno(), sys.stdout.fileno())
  se = open('heartbeats.log', 'a+')
  os.dup2(se.fileno(), sys.stderr.fileno())

  while True:
    sendJsonURL('https://justin-allocator-pro.dune.hep.ac.uk'
                              '/api/allocator/send_heartbeat',
                { "method" : "send_heartbeat" }
               )
             
    time.sleep(600)

justinWorkdir = os.environ['PWD']

# Make $HOME directory and workspace subdirectory for Apptainer/Singularity
os.makedirs('home/workspace')

# Make jobutils scripts available to jobscripts in a known location
for i in ['justin-get-file', 'justin-allocated-files', 'pdjson2metadata']:
  os.symlink('/cvmfs/dune.opensciencegrid.org/products/dune/justin/'
             'pro/NULL/jobutils/' + i, 'home/' + i)

# Assemble values to send to allocator
getStageDict = { 'method' : 'get_stage_json' }

for line in open('/proc/cpuinfo','r').readlines():
  if line.startswith('model name'):
    getStageDict['cpuinfo'] = line.split(':')[1].strip()
    break

getStageDict['os_release'] \
  = open('/etc/redhat-release','r').readlines()[0].strip()
getStageDict['hostname']    = os.environ.get('HOSTNAME', os.uname()[1])
getStageDict['site_name']   = siteName

getStageDict['site_job_id'] = 'XXX'
##  "site_job_id"     : "${JOB_GLIDEIN_SiteWMS_JobId:-unknown}",

for line in open(os.environ['_CONDOR_JOB_AD'],'r').readlines():
  if line.startswith('RequestCpus = '):
    getStageDict['processors'] = int(line.split('=')[1].strip())

  if line.startswith('RequestMemory = '):
    getStageDict['rss_bytes'] = 1048576 * int(line.split('=')[1].strip())

for line in open(os.environ['_CONDOR_MACHINE_AD'],'r').readlines():
  if line.startswith('GLIDEIN_Max_Walltime = '):
    getStageDict['wall_seconds'] = int(line.split('=')[1].strip())
    break

logLine('==== Before try apptainer ====')
getStageDict['inner_apptainer'] = (0 == os.system(
   '/cvmfs/oasis.opensciencegrid.org/mis/apptainer/current/bin/apptainer '
   'shell --shell /usr/bin/hostname '
   '/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:osg3.6'
   ))
logLine('==== After try apptainer ====')

# Make no roles CSR 
os.system('openssl req -batch -nodes -newkey rsa:2048 '
          '-keyout justin-jobs-no-roles.key.pem '
          '-out justin-jobs-no-roles.csr.pem')

getStageDict['csr-no-roles'] = \
  open('justin-jobs-no-roles.csr.pem', 'r').read()

justinJobsNoRolesKeyPem = \
  open('justin-jobs-no-roles.key.pem', 'r').read()

# Make production CSR
os.system('openssl req -batch -nodes -newkey rsa:2048 '
          '-keyout justin-jobs-production.key.pem '
          '-out justin-jobs-production.csr.pem')

getStageDict['csr-production'] = \
  open('justin-jobs-production.csr.pem', 'r').read()

justinJobsProductionKeyPem = \
  open('justin-jobs-production.key.pem', 'r').read()

for i in range(1,6):

  # Sleep for up to 60 seconds to spread out job start storms
  logLine('Random sleep ...')
##REINSTATE THIS AFTER TESTING!!!!
  ##time.sleep(random.randrange(61))

  logLine('====start justin-get-stage.json====')
  print(json.dumps(getStageDict))
  logLine('====end justin-get-stage.json====')

  receivedDict = sendJsonURL(
    'https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/get_stage',
    getStageDict)

  logLine('get_stage returns HTTP code %d' % receivedDict['status'])

  if receivedDict['status'] != 503 and receivedDict['status'] != 0:
    break
    
if receivedDict['status'] != 200:
## WANT TO PRINT OUT MESSAGE NOT JUST CODE AS ABOVE ALREADY
  sys.exit(0)

# Stage-defined and standard environment variables for the jobscript
with open('home/justin-jobscript-env.sh','w') as f:
  for (n,v) in receivedDict['stage_env']:
    f.write('export %s="%s"' % (n,v))

  f.write('export JUSTIN_SITE_NAME=%s\n' % receivedDict['site_name'])
  f.write('export JUSTIN_REQUEST_ID=%d\n' % receivedDict['request_id'])
  f.write('export JUSTIN_STAGE_ID=%d\n' % receivedDict['stage_id'])
  f.write('export JUSTIN_SCOPE=%s\n' % receivedDict['scope'])
  f.write('export JUSTIN_JOBSUB_ID=%s\n' % receivedDict['jobsub_id'])
  f.write('export JUSTIN_JOBSCRIPT_SECRET=%s\n' 
          % receivedDict['jobscript_secret'])
  f.write('export JUSTIN_SAM_WEB_URI='
          '"https://justin.dune.hep.ac.uk/api/samweb/%s/%s"\n' 
          % (receivedDict['jobsub_id'], receivedDict['jobscript_secret']))

# JSON for justin-get-file command to use
with open('home/justin-get-file.json', 'w') as f:
  f.write(json.dumps({ 'method' : 'get_file',
                       'jobsub_id' : receivedDict['jobsub_id'],
                       'jobscript_secret' : receivedDict['jobscript_secret']
                     }
                    )
         )

# JSON for justin-allocated-files command to use
with open('home/justin-allocated-files.json', 'w') as f:
  f.write(json.dumps({ 'method' : 'get_allocated_files',
                       'jobsub_id' : receivedDict['jobsub_id'],
                       'jobscript_secret' : receivedDict['jobscript_secret']
                     }
                    )
         )

# The jobscript in any scripting language supported by the container
with open('home/justin-jobscript','w') as f:
  f.write(receivedDict['jobscript'])

os.chmod('home/justin-jobscript', 0o755)

# Assemble proxy to be used by jobscript
with open('home/justin-jobs-no-roles.proxy.pem', 'w') as f:
  f.write(receivedDict['justin-jobs-no-roles.cert.pem'])
  f.write(justinJobsNoRolesKeyPem)
  f.write(receivedDict['justin-jobs-no-roles.chain.pem'])

os.chmod('home/justin-jobs-no-roles.proxy.pem', 0o400)

# Assemble proxy to be used by generic job itself
with open('justin-jobs-production.proxy.pem', 'w') as f:
  f.write(receivedDict['justin-jobs-production.cert.pem'])
  f.write(justinJobsProductionKeyPem)
  f.write(receivedDict['justin-jobs-production.chain.pem'])

os.chmod('justin-jobs-production.proxy.pem', 0o400)

# AWT jobs get production proxy too
if receivedDict['for_awt']:

  with open('home/justin-awt-rse-list.txt', 'w') as f:
    for (rseName, scheme, pfn) in receivedDict['awt_rses']:
      f.write('%s %s %s\n' % (rseName, scheme, pfn))

  with open('home/awt-proxy.pem', 'w') as f:
    f.write(receivedDict['justin-jobs-production.cert.pem'])
    f.write(justinJobsProductionKeyPem)
    f.write(receivedDict['justin-jobs-production.chain.pem'])

  os.chmod('home/awt-proxy.pem', 0o400)

# Wrapper to be run inside the container
with open('home/jobscript-wrapper.sh','w') as f:
  f.write('''#!/bin/sh
export JUSTIN_PATH="$HOME"
export X509_USER_PROXY="$HOME/justin-jobs-no-roles.proxy.pem"
cd workspace
. ../justin-jobscript-env.sh
stdbuf -oL -eL ../justin-jobscript 2>&1
''')

os.chmod('home/jobscript-wrapper.sh', 0o755)

logLine('====Start of jobscript execution====')
jobscriptStartTime=int(time.time())

### NEED TO RECORD USER SECONDS, MAX MEMORY ETC!!!!
jobscriptOutcome = subprocess.run(
 '/cvmfs/oasis.opensciencegrid.org/mis/apptainer/current/bin/apptainer shell '
 '--shell /home/jobscript-wrapper.sh '
 '--containall '
 '--bind /cvmfs '
 '--workdir %s '
 '--home %s/home:/home '
 '/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:osg3.6 '
 % (justinWorkdir, justinWorkdir),
 stdout=subprocess.PIPE,
 stderr=subprocess.STDOUT,
 shell=True 
)

jobscriptFinishTime=int(time.time())
logLine('====End of jobscript execution====')

logLine('#### start jobscript log ####')
print(jobscriptOutcome.stdout)
logLine('#### end jobscript log ####')

justinRecordResultsDict = {
  'method'                 : 'record_results',
  'output_urls'            : [],
  'output_dids'            : [],
  'next_stage_dids'        : [],
  'jobscript_log' : base64.b64encode(jobscriptOutcome.stdout[-10000:]).decode(),
  'jobscript_exit'         : jobscriptOutcome.returncode,
  'jobscript_start'        : jobscriptStartTime,
  'jobscript_finish'       : jobscriptFinishTime,
  'jobscript_real_seconds' : 0,
  'jobscript_user_seconds' : 0,
  'jobscript_sys_seconds'  : 0,
  'jobscript_max_rss_kb'   : 0
}

outputFiles = []

# Find files matching output patterns specified for this stage
for (lifetimeSeconds, forNextStage, destination, scope, pattern) in \
    receivedDict['patterns']:
  
  matchingPath = glob.glob('home/workspace/' + pattern)
  for i in matches:
    matchingFile = matchingPath.split('/')[-1]
    outputFiles.append((lifetimeSeconds, destination, scope, matchingFile))
    
    if scope == '::URL::':
      justinRecordResultsDict['output_urls'].append(destination + '/' +
                                                        matchingFile)
    elif forNextStage:
      justinRecordResultsDict['next_stage_dids'].append(scope + ':' + 
                                                        matchingFile)    
    else:
      justinRecordResultsDict['output_dids'].append(scope + ':' + matchingFile)

justinRecordResultsDict['processed_dids'] = []
try:
  for i in open('home/workspace/justin-processed-dids.txt','r').readlines():
    justinRecordResultsDict['processed_dids'].append(i.strip())
except:
  pass

justinRecordResultsDict['processed_pfns'] = []
try:
  for i in open('home/workspace/justin-processed-pfns.txt','r').readlines():
    justinRecordResultsDict['processed_pfns'].append(i.strip())
except:
  pass

logLine('record results: ' + str(justinRecordResultsDict))
resultsResponseDict = sendJsonURL(
 'https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/record_results', 
 justinRecordResultsDict)

logLine('record_results returns HTTP code %d' % resultsResponseDict['status'])

if resultsResponseDict['status'] != 200:
  jobAborted(resultsResponseDict['status'], 'record_results', '')

if jobscriptOutcome.returncode != 0:
  jobAborted(900, 'jobscript_error', '')

# Now try to upload the output files we recorded as created by the job
logLine('Output RSEs: ' + str(receivedDict['output_rses']))

# Write out the token for uploading to user's scratch
with open('user-upload-token', 'w') as f:
  f.write(resultsResponseDict['user_access_token'])

confirmResultsDict = { 'method'      : 'confirm_results',
                       'output_dids' : {},
                       'output_urls' : []  }

# Go through the list of output files
for (lifetimeSeconds, destination, fileScope, fileName) in outputFiles:
  
  if fileScope == '::URL::': 
    # Uploading to user scratch
    ret = webdavUpload(fileName, destination)
    if ret:
      logLine('WebDAV upload fails')
      jobAborted(900, 'webdav_upload', '')
    
    confirmResultsDict['output_urls'].append(destination + '/' + fileName)
  elif receivedDict['output_rses']:
    # Uploading to Rucio managed storage
    
    # Create tmp.json metadata file for this output file
    try:
      updateMetadataTmp(fileScope, fileName, 
                        getStageDict, receivedDict, justinRecordResultsDict)
    except:
      jobAborted(900, 'update_metadata', '')

    # First try to register with MetaCat
    ret = executeMetaCatCommand('file declare --json -f tmp.json "%s:%s"' 
                                  % (fileScope, destination))
    if ret:
      logLine('Failed to register %s:%s in MetaCat' % (fileScope, fileName))
      jobAborted(900, 'metacat_registration', '')

    # If that succeeds, then try to register/upload with rucio    
    for (rse,scheme) in receivedDict['output_rses'][:3]:
      logLine('Try %s:%s to %s/%s' 
              % (fileScope, fileName, rse, scheme))
           
      ret = executeRucioCommand('upload %s '
                                '--rse %s '
                                '--transfer-timeout 1200 '
                                '--protocol %s '
                                '--scope %s '
                                '--name "%s" '
                                'home/workspace/%s' %
               (('--lifetime %d' % lifetimeSeconds) if lifetimeSeconds else '',
                scheme,
                fileScope,
                fileName))

      if ret == 0:
        break
      else:
        logLine('Failed to upload %s:%s to %s' % (fileScope, fileName, rse))

    if ret:
      logLine('Failed to upload %s:%s' % (fileScope, fileName))
      jobAborted(900, 'rucio_upload', '')

    # Add to dataset
    logLine('Adding %s:%s to %s:%s' 
            % (fileScope, fileName, fileScope, destination))

    ret = executeRucioCommand('attach "%s:%s" "%s:%s"'
                              % (fileScope, destination, fileScope, fileName))
    if ret:
      logLine('rucio attach fails')
      jobAborted(900, 'rucio_attach', '')

    # Add to list of uploaded files for confirm results
    confirmResultsDict['output_dids'][fileScope + ':' + fileName] = rse

# If all ok, then confirm that to the Workflow Allocator

logLine('confirm results: ' + str(confirmResultsDict))
confirmDict = sendJsonURL(
  'https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/confirm_results',
  confirmResultsDict)

logLine('confirm_results returns HTTP code %d' % confirmDict['status'])

if confirmDict['status'] != 200:
  jobAborted(900, 'confirm_results', '')

logLine('====End of justin-generic-job====')
sys.exit(0)
########################################################################
