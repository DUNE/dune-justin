#!/bin/bash
#
# Generic Job which will get a stage's jobscript from the
# justIN allocator service
#

# Everything goes to stdout
exec 2>&1

function log_line() {
echo `date -u +'%Y-%m-%d %H:%M:%S '`$1
}

log_line '====Start of justin-generic-job===='

function job_aborted() {

  cat <<EOF >justin-job-aborted.json
{
  "method"         : "job_aborted",
  "jobsub_id"      : "$JOBSUBJOBID",
  "http_code"      :  $2,
  "aborted_method" : "$3",
  "rse_name"       : "$4"
}
EOF

  curl \
     --user-agent 'justin-generic-job' \
     --header "X-Jobid: $JOBSUBJOBID" \
     --header "Expect:" \
     --key $X509_USER_PROXY \
     --cert $X509_USER_PROXY \
     --cacert $X509_USER_PROXY \
     --capath $X509_CERTIFICATES \
     --data @justin-job-aborted.json \
     https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/job_aborted_$2

  # If in a subshell, this just exits that, not the job, so must be caught
  # The 1st argument lets the caller choose the exit code on errors
  exit $1
}

echo '### Start of  printenv | sort'
printenv | sort
echo '### End of printenv'

echo 'Before GFAL unsets, do  printenv | grep GFAL'
printenv | grep GFAL
unset GFAL_CONFIG_DIR GFAL_PLUGIN_DIR

echo '### pwd ; ls -lt ###'
pwd
ls -lt
echo '##############'

export X509_CERTIFICATES=${X509_CERTIFICATES:-/etc/grid-security/certificates/}

# Check requirements are present

if [ ! -r "$X509_USER_PROXY" ] ; then
 # Stop if proxy file is missing or deleted
 log_line "Cannot read X509_USER_PROXY file = $X509_USER_PROXY"
 exit 0
fi

curl --version
if [ $? -ne 0 ] ; then
 log_line Failed running curl
 exit 0
fi

cat <<EOF >justin-send-heartbeat.json
{
  "method"       : "send_heartbeat",
  "jobsub_id"    : "$JOBSUBJOBID"
}
EOF

(
# Subprocess to send regular heartbeats

while :
do
  # Stop if JSON file is missing or deleted
  if [ ! -r justin-send-heartbeat.json ] ; then
    exit 0
  fi

  curl \
     --user-agent 'justin-generic-job' \
     --header "X-Jobid: $JOBSUBJOBID" \
     --key $X509_USER_PROXY \
     --cert $X509_USER_PROXY \
     --cacert $X509_USER_PROXY \
     --capath $X509_CERTIFICATES \
     --data @justin-send-heartbeat.json \
     https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/send_heartbeat

  sleep 600
done

) >justin-heartbeat.log 2>&1 &

# All paths are relative to this
export JUSTIN_WORKDIR=`pwd`

# Make $HOME directory and workspace subdirectory for Apptainer/Singularity
mkdir -p $JUSTIN_WORKDIR/home/workspace

# Copy all of the justin-* scripts in jobutils to $HOME
cp -f /cvmfs/dune.opensciencegrid.org/products/dune/justin/pro/NULL/jobutils/* \
 $JUSTIN_WORKDIR/home/

# Assemble values to record
export JUSTIN_CPUINFO=`grep '^model name' /proc/cpuinfo | head -1 | cut -c14-`
export JUSTIN_OS_RELEASE=`head -1 /etc/redhat-release`
export JUSTIN_HOSTNAME=${HOSTNAME:-`hostname`}
export site_name=${GLIDEIN_DUNESite:-XX_UNKNOWN}

export processors=`grep '^RequestCpus = ' $_CONDOR_JOB_AD | cut -d' ' -f3`
export rss_mb=`grep '^RequestMemory = ' $_CONDOR_JOB_AD | cut -d' ' -f3`
export rss_bytes=`expr $rss_mb \* 1048576`
export wall_seconds=`grep '^GLIDEIN_Max_Walltime = ' $_CONDOR_MACHINE_AD | cut -d' ' -f3`

echo '==== Before: ls -l /proc/$$/ns/ ===='
ls -l "/proc/$$/ns/"
echo '==== After: ls -l /proc/$$/ns/ ===='
echo '==== Before try singularity ===='
  singularity shell --shell /usr/bin/hostname \
   /cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:osg3.6
if [ $? = 0 ] ; then
  inner_apptainer=true
else
  inner_apptainer=false
fi
echo '==== After try singularity ===='

openssl req -batch -nodes -newkey rsa:2048 \
 -keyout justin-jobs-no-roles.key.pem -out justin-jobs-no-roles.csr.pem

openssl req -batch -nodes -newkey rsa:2048 \
 -keyout justin-jobs-production.key.pem -out justin-jobs-production.csr.pem

# Create the JSON to send to the allocator
cat <<EOF >justin-get-stage.json
{
  "method"          : "get_stage",
  "jobsub_id"       : "$JOBSUBJOBID",
  "site_name"       : "${site_name:-XX-UNKNOWN}",
  "cpuinfo"         : "${JUSTIN_CPUINFO:-Unknown}",
  "os_release"      : "${JUSTIN_OS_RELEASE:-Unknown}",
  "hostname"        : "${JUSTIN_HOSTNAME:-unknown}",
  "rss_bytes"       : ${rss_bytes:-0},
  "processors"      : ${processors:-0},
  "wall_seconds"    : ${wall_seconds:-0},
  "inner_apptainer" : $inner_apptainer,
  "site_job_id"     : "${JOB_GLIDEIN_SiteWMS_JobId:-unknown}",
  "csr-no-roles"    : "`sed -z 's/\n/\\\\n/g' justin-jobs-no-roles.csr.pem`",
  "csr-production"  : "`sed -z 's/\n/\\\\n/g' justin-jobs-production.csr.pem`"
}
EOF

echo '====start justin-get-stage.json===='
cat justin-get-stage.json
echo '====end justin-get-stage.json===='

for i in 1 2 3 4 5 
do

# Sleep for up to 60 seconds to spread out job start storms
sleep `expr $RANDOM / 512`

# Make the call to the Workflow Allocator
log_line "Attempt $i/5 of curl get_stage"
http_code=`curl \
--retry 0 \
--user-agent 'justin-generic-job' \
--header "X-Jobid: $JOBSUBJOBID" \
--header "Expect:" \
--key $X509_USER_PROXY \
--cert $X509_USER_PROXY \
--cacert $X509_USER_PROXY \
--capath $X509_CERTIFICATES \
--data @justin-get-stage.json \
--output justin-files.tar \
--write-out "%{http_code}\n" \
https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/get_stage`

chmod 0600 justin-files.tar 
log_line "($i/5) curl returns HTTP code $http_code"

if [ "$http_code" != "503" -a "$http_code" != "000" ] ; then
 break
fi
done

if [ "$http_code" != "200" ] ; then
  log_line "curl call to allocator to get stage fails with code $http_code"
  cat justin-files.tar
  echo
  exit 0
fi

tar xvf justin-files.tar

if [ -r justin-env.sh ] ; then
  . ./justin-env.sh
fi

echo '====Start justin-output-patterns.txt===='
cat justin-output-patterns.txt
echo '====End justin-output-patterns.txt===='

echo '====Start justin-env.sh===='
cat justin-env.sh
echo '====End justin-env.sh===='

echo '====Start justin-jobscript-env.sh===='
cat justin-jobscript-env.sh
echo '====End justin-jobscript-env.sh===='
cp justin-jobscript-env.sh $JUSTIN_WORKDIR/home

echo '====Start justin-get-file.json===='
cat justin-get-file.json
echo '====End justin-get-file.json===='
cp justin-get-file.json $JUSTIN_WORKDIR/home

echo '====Start justin-jobscript.sh===='
cat justin-jobscript.sh
echo '====End justin-jobscript.sh===='
cp justin-jobscript.sh $JUSTIN_WORKDIR/home
chmod +x $JUSTIN_WORKDIR/home/justin-jobscript.sh

# Assemble proxy to be used by jobscript
cat justin-jobs-no-roles.cert.pem  \
    justin-jobs-no-roles.key.pem   \
    justin-jobs-no-roles.chain.pem \
  > $JUSTIN_WORKDIR/home/justin-jobs-no-roles.proxy.pem
chmod 0400 $JUSTIN_WORKDIR/home/justin-jobs-no-roles.proxy.pem
    
# Assemble proxy for uploads by generic job itself
cat justin-jobs-production.cert.pem  \
    justin-jobs-production.key.pem   \
    justin-jobs-production.chain.pem > justin-jobs-production.proxy.pem
chmod 0400 justin-jobs-production.proxy.pem

if [ -n "$JUSTIN_FOR_AWT" ] ; then
  # If an AWT job, then we give it the generic job's proxy too
  cp $X509_USER_PROXY $JUSTIN_WORKDIR/home/awt-proxy.pem
  chmod 0400 $JUSTIN_WORKDIR/home/awt-proxy.pem
  cp justin-awt-rse-list.txt $JUSTIN_WORKDIR/home
fi

# Wrapper to be run inside the container
cat <<EOF > $JUSTIN_WORKDIR/home/jobscript-wrapper.sh
#!/bin/sh
export JUSTIN_PATH="\$HOME"
export X509_USER_PROXY="\$HOME/justin-jobs-no-roles.proxy.pem"
cd workspace
. ../justin-jobscript-env.sh
stdbuf -oL -eL ../justin-jobscript.sh 2>&1
EOF
chmod +x $JUSTIN_WORKDIR/home/jobscript-wrapper.sh

echo "====Start of jobscript execution===="
export JUSTIN_JOBSCRIPT_START=`date --iso-8601=seconds --utc`
/usr/bin/time -o $JUSTIN_WORKDIR/time.txt -f '%e %U %S %M' \
    singularity shell \
    --shell /home/jobscript-wrapper.sh \
    --containall \
    --bind /cvmfs \
    --workdir $JUSTIN_WORKDIR \
    --home $JUSTIN_WORKDIR/home:/home \
    /cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:osg3.6 \
    > $JUSTIN_WORKDIR/home/workspace/justin-jobscript.log 
export JUSTIN_JOBSCRIPT_EXIT=$?
export JUSTIN_JOBSCRIPT_FINISH=`date --iso-8601=seconds --utc`
export JUSTIN_JOBSCRIPT_REAL_SECONDS=`cut -d' ' -f1 $JUSTIN_WORKDIR/time.txt`
export JUSTIN_JOBSCRIPT_USER_SECONDS=`cut -d' ' -f2 $JUSTIN_WORKDIR/time.txt`
export JUSTIN_JOBSCRIPT_SYS_SECONDS=`cut -d' ' -f3 $JUSTIN_WORKDIR/time.txt`
export JUSTIN_JOBSCRIPT_MAX_RSS_KB=`cut -d' ' -f4 $JUSTIN_WORKDIR/time.txt`
echo "====End of jobscript execution===="

echo '#### justin-jobscript.log'
cat $JUSTIN_WORKDIR/home/workspace/justin-jobscript.log
echo '####'

# Make the lists of output files and files for the next stage
echo -n > justin-outputs.txt
echo -n > justin-output-dids.txt
echo -n > justin-next-stage-dids.txt

echo '### Contents of workspace directory ###'
ls -lR home/workspace
echo '###'

cat justin-output-patterns.txt | (
while read lifetime for_next_stage dataset scope pattern
do  
  (
    cd $JUSTIN_WORKDIR/home/workspace
    # $pattern is wildcard-expanded here - so a list of files
    for fn in $pattern
    do
      if [ -r "$fn" ] ; then
        # justin-outputs.txt gets DATASET SCOPE FILENAME on each line
        echo "$lifetime $dataset $scope $fn" >> $JUSTIN_WORKDIR/justin-outputs.txt

        if [ "$for_next_stage" = "True" ] ; then
          # justin-next-stage-dids gets a list of DIDs
          echo "$scope:$fn" >> $JUSTIN_WORKDIR/justin-next-stage-dids.txt
        else
          # justin-output-dids.txt gets DID = SCOPE:FILENAME
          echo "$scope:$fn" >> $JUSTIN_WORKDIR/justin-output-dids.txt
        fi
      fi
    done
  )
done
)

echo '#### justin-outputs.txt'
cat $JUSTIN_WORKDIR/justin-outputs.txt
echo '####'
echo
echo '#### justin-output-dids.txt'
cat $JUSTIN_WORKDIR/justin-output-dids.txt
echo '####'
echo
echo '#### justin-next-stage-dids.txt'
cat $JUSTIN_WORKDIR/justin-next-stage-dids.txt
echo '####'
echo
echo '#### justin-output-rse-list.txt'
cat $JUSTIN_WORKDIR/justin-output-rse-list.txt
echo '####'

output_dids=`echo \`sed 's/.*/"&"/' justin-output-dids.txt\`|sed 's/ /,/g'`

next_stage_dids=`echo \`sed 's/.*/"&"/' justin-next-stage-dids.txt\`|sed 's/ /,/g'`

# justin-jobscript.sh should produce lists of successfully processed input files
if [ -f $JUSTIN_WORKDIR/home/workspace/justin-processed-dids.txt ] ; then
  processed_dids=`echo \`sed -r 's/.+/"&"/' $JUSTIN_WORKDIR/home/workspace/justin-processed-dids.txt\`|sed 's/ /,/g'`
fi

if [ -f $JUSTIN_WORKDIR/home/workspace/justin-processed-pfns.txt ] ; then
  processed_pfns=`echo \`sed -r 's/.+/"&"/' $JUSTIN_WORKDIR/home/workspace/justin-processed-pfns.txt\`|sed 's/ /,/g'`
fi

tail -c 10000 $JUSTIN_WORKDIR/home/workspace/justin-jobscript.log | base64 --wrap=0 > justin-jobscript.log.b64

cat <<EOF >justin-record-results.json
{
  "method": "record_results",
  "jobsub_id": "$JOBSUBJOBID",
  "processed_dids": [$processed_dids],
  "processed_pfns": [$processed_pfns],
  "output_dids": [$output_dids],
  "next_stage_dids": [$next_stage_dids],
  "jobscript_log": "`cat justin-jobscript.log.b64`",
  "jobscript_exit": $JUSTIN_JOBSCRIPT_EXIT,
  "jobscript_start": "$JUSTIN_JOBSCRIPT_START",
  "jobscript_finish": "$JUSTIN_JOBSCRIPT_FINISH",
  "jobscript_real_seconds": $JUSTIN_JOBSCRIPT_REAL_SECONDS,
  "jobscript_user_seconds": $JUSTIN_JOBSCRIPT_USER_SECONDS,
  "jobscript_sys_seconds": $JUSTIN_JOBSCRIPT_SYS_SECONDS,
  "jobscript_max_rss_kb": $JUSTIN_JOBSCRIPT_MAX_RSS_KB
}
EOF

echo "=====Start justin-record-results.json=="
cat justin-record-results.json
echo "=====End justin-record-results.json=="

http_code=`curl \
--retry 5 \
--retry-max-time 300 \
--max-time 600 \
--user-agent 'justin-generic-job' \
--key $X509_USER_PROXY \
--cert $X509_USER_PROXY \
--cacert $X509_USER_PROXY \
--header "X-Jobid: $JOBSUBJOBID" \
--header "Expect:" \
--capath $X509_CERTIFICATES \
--data @justin-record-results.json \
--output record-results.log \
--write-out "%{http_code}\n" \
https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/record_results`

log_line "record_results returns HTTP code $http_code"
echo "=====Start record-results.log=="
touch record-results.log
cat record-results.log
echo "=====End record-results.log=="

if [ "$http_code" != 200 ] ; then
  job_aborted 0 $http_code record_results
fi

if [ "$JUSTIN_JOBSCRIPT_EXIT" != 0 ] ; then
  job_aborted 0 900 jobscript_error
fi

# Just try the first RSE for now; eventually will do failovers on errors
export OUTPUT_RSE=`head -1 justin-output-rse-list.txt | cut -f1 -d' '`
export OUTPUT_PROTOCOL=`head -1 justin-output-rse-list.txt | cut -f2 -d' '`
log_line "Using $OUTPUT_RSE for output"

cat $JUSTIN_WORKDIR/justin-outputs.txt | (

cat <<EOF >$JUSTIN_WORKDIR/rucio.cfg
[client]
rucio_host = https://dune-rucio.fnal.gov
auth_host = https://auth-dune-rucio.fnal.gov
account = dunepro
auth_type = x509_proxy
request_retries = 3
EOF

echo '====Start rucio.cfg===='
cat $JUSTIN_WORKDIR/rucio.cfg
echo '====End rucio.cfg===='

source /cvmfs/dune.opensciencegrid.org/products/dune/setup_dune.sh
setup rucio
setup metacat

export METACAT_AUTH_SERVER_URL=https://metacat.fnal.gov:8143/auth/dune
export METACAT_SERVER_URL=https://metacat.fnal.gov:9443/dune_meta_demo/app

rucio --config $JUSTIN_WORKDIR/rucio.cfg --version
if [ $? != 0 ] ; then
  job_aborted 1 900 rucio_test
fi

metacat auth login -m x509 dunepro
metacat auth whoami
if [ $? != 0 ] ; then
  job_aborted 1 900 metacat_test
fi

touch justin-output-dids-rses.txt

while read lifetime dataset scope fn
do
  /cvmfs/fifeuser3.opensciencegrid.org/sw/dune/a0f91b7b24130be3e95b0987af20fd47d8f8bfaa/justin-metadata \
    "$scope" "$fn" > tmp.json
#  $JUSTIN_WORKDIR/home/justin-metadata "$scope" "$fn" > tmp.json
  echo "==== Start MetaCat JSON for $fn ===="
  cat tmp.json
  echo "==== End MetaCat JSON for $fn ===="

  log_line "Try to declare file in MetaCat (1/3)"
  echo "metacat file declare --json -f tmp.json "$dataset""
  metacat file declare --json -f tmp.json "$dataset"
  metacat_return_code=$?
  echo "metacat returns $metacat_return_code"
  if [ $metacat_return_code != 0 ] ; then
    sleep 1
    log_line "Retry declare file in MetaCat (2/3)"
    metacat file declare --json -f tmp.json "$dataset"
    metacat_return_code=$?
    if [ $metacat_return_code != 0 ] ; then
      sleep 1
      log_line "Last chance to declare file in MetaCat (3/3)"
      metacat file declare --json -f tmp.json "$dataset"
      metacat_return_code=$?
    fi
  fi

  if [ $metacat_return_code = 0 ] ; then
    if [ "$lifetime" -gt 0 ] ; then
      lifetime_option="--lifetime $lifetime"
    fi
    log_line "Upload $scope:$fn to $OUTPUT_RSE/$OUTPUT_PROTOCOL"
    rucio --config $JUSTIN_WORKDIR/rucio.cfg --verbose \
          upload \
          $lifetime_option \
          --rse "$OUTPUT_RSE" \
          --transfer-timeout 1200 \
          --protocol "$OUTPUT_PROTOCOL" \
          --scope "$scope" --name "$fn" "$JUSTIN_WORKDIR/home/workspace/$fn"

    if [ $? = 0 ] ; then
      log_line "Add $scope:$fn to $dataset"
      rucio --config $JUSTIN_WORKDIR/rucio.cfg \
            --verbose attach "$dataset" "$scope:$fn"
      if [ $? != 0 ] ; then
        log_line "rucio attach fails"
        job_aborted 1 900 rucio_attach
      fi
      echo "\"$scope:$fn\":\"$OUTPUT_RSE\"" >> justin-output-dids-rses.txt
    else
      log_line "rucio upload fails"
      job_aborted 1 900 rucio_upload "$OUTPUT_RSE"
    fi
  else
    log_line "metacat file declaration fails"
    job_aborted 1 900 metacat_declare
  fi 
done

)
if [ $? != 0 ] ; then
  # Exit/aborts inside subshell just exit the subshell with a non-zero code
  # So we exit the generic job script properly here
  exit 0
fi

# If all ok, then confirm that to the Workflow Allocator

cat <<EOF >justin-confirm-results.json
{
  "method": "confirm_results",
  "jobsub_id": "$JOBSUBJOBID",
  "output_dids": {
EOF

echo `cat justin-output-dids-rses.txt` | sed 's/ /,/g' >>justin-confirm-results.json

echo '} }' >>justin-confirm-results.json

echo "=====Start justin-confirm-results.json=="
cat justin-confirm-results.json
echo "=====End justin-confirm-results.json=="

http_code=`curl \
--retry 5 \
--retry-max-time 300 \
--max-time 600 \
--user-agent 'justin-generic-job' \
--header "X-Jobid: $JOBSUBJOBID" \
--header "Expect:" \
--key $X509_USER_PROXY \
--cert $X509_USER_PROXY \
--cacert $X509_USER_PROXY \
--capath $X509_CERTIFICATES \
--data @justin-confirm-results.json \
--output confirm-results.log \
--write-out "%{http_code}\n" \
https://justin-allocator-pro.dune.hep.ac.uk/api/allocator/confirm_results`

log_line "confirm_results returns HTTP code $http_code"
echo "=====Start confirm-results.log=="
touch confirm-results.log
cat confirm-results.log
echo "=====End confirm-results.log=="

if [ "$http_code" != 200 ] ; then
  job_aborted 0 $http_code confirm_results
fi

log_line '====End of justin-generic-job===='
exit 0

