#!/usr/bin/env python3
#
#  wfs-info-collector - WFS Info Collector agent
# 
#  Andrew McNab, University of Manchester.
#  Copyright (c) 2013-22. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or
#  without modification, are permitted provided that the following
#  conditions are met:
#
#    o Redistributions of source code must retain the above
#      copyright notice, this list of conditions and the following
#      disclaimer.
#    o Redistributions in binary form must reproduce the above
#      copyright notice, this list of conditions and the following
#      disclaimer in the documentation and/or other materials
#      provided with the distribution.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
#  CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
#  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
#  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
#  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
#  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
#  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#

import os
import sys
import stat
import time
import pathlib
import tempfile
import xml.dom.minidom

# Needs MySQL-python RPM
import MySQLdb

# Installed by pip install of Rucio
import rucio.client

# wfs/conf.py must define these variables in a way that is both
# valid Python and valid Bash!
#
# mysqlUser='username'
# mysqlPassword='PAsSWoRd'
#
import wfs

updateUsersInterval    = 3600
updateSitesInterval    = 3600
updateStoragesInterval = 3600

sleepSeconds = 60

class wfsError(Exception):
  pass

def logLine(text):
  sys.stdout.write(time.strftime('%b %d %H:%M:%S [') + str(os.getpid()) + ']: ' + text + '\n')
  sys.stdout.flush()

def updateUsers():
  # Get info about users Rucio knows about
  logLine('---- Start updateUsers ----')
  
  try:
    accClient = rucio.client.accountclient.AccountClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return
  
  try:
    accountsList = accClient.list_accounts()  
  except Exception as e:
    logLine("Reading accounts list from Rucio fails with: " + str(e))
    return

  for account in accountsList:
    logLine(str(account))
    if account['type'] != 'USER' or account['account'] == 'test':
      continue

    try:
      identitiesList = accClient.list_identities(account['account'])
    except Exception as e:
      logLine("Reading %s identities fails with: %s" % 
              (account['account'], str(e)))
      continue

    for identity in identitiesList:
      if identity['type'] == 'X509' and 'identity' in identity:
        try:
          query = ('INSERT INTO users SET '
                   'name="' + account['account'] + '",' +
                   'x509dn="' + identity['identity'] + '" ' +
                   'ON DUPLICATE KEY UPDATE name="' + account['account'] + '"'
                  )

          wfs.db.cur.execute(query)
        except Exception as e:
          # Log the error and hope it was transitory
          logLine('Failed inserting %s into database: %s' % 
                  (identity['identity'], str(e)))

def cleanupNodeXML(node):
  if node.nodeType == xml.dom.Node.TEXT_NODE \
     and node.nodeValue.strip() == "":
    node.nodeValue = ""
  
  for childNode in node.childNodes:
    cleanupNodeXML(childNode)

def processOneFileXML(sitesDict, fileName):
  xmlDocument = xml.dom.minidom.parse(fileName)
  cleanupNodeXML(xmlDocument)
  xmlDocument.normalize()

  xmlEntries = xmlDocument.firstChild.firstChild

  for xmlEntry in xmlEntries.childNodes:

    if xmlEntry.nodeType == xml.dom.Node.ELEMENT_NODE and \
       xmlEntry.tagName == 'entry':

      try:
        entryName = xmlEntry.getAttribute('name')
      except:
        continue

      siteName        = None
      jobsubSiteName  = None
      voList          = []
      processors      = 1
      rssBytes        = 2147483648
      wallSeconds     = 86400            

      for xmlEntryChild in xmlEntry.childNodes:
        if xmlEntryChild.nodeType == xml.dom.Node.ELEMENT_NODE and \
           xmlEntryChild.tagName == 'attrs':

          for xmlAttr in xmlEntryChild.childNodes:
            
            if xmlAttr.nodeType == xml.dom.Node.ELEMENT_NODE and \
               xmlAttr.tagName == 'attr':
               
              name  = xmlAttr.getAttribute('name')
              value = xmlAttr.getAttribute('value')
               
              if name == 'GLIDEIN_DUNESite':
                siteName = xmlAttr.getAttribute('value')

              elif name == 'GLIDEIN_Site':
                jobsubSiteName = xmlAttr.getAttribute('value')

              elif name == 'GLIDEIN_CPUS':
                try:
                  processors = int(xmlAttr.getAttribute('value'))
                except:
                  pass
                
              elif name == 'GLIDEIN_MaxMemMBs':
                try:
                  rssBytes = int(xmlAttr.getAttribute('value')) * 1048576
                except:
                  pass
                
              elif name == 'GLIDEIN_Max_Walltime':
                try:
                  wallSeconds = int(xmlAttr.getAttribute('value'))
                except:
                  pass
                
              elif name == 'GLIDEIN_Supported_VOs':
                voList = xmlAttr.getAttribute('value').split(',')

      if (siteName and jobsubSiteName and processors and rssBytes and
          wallSeconds and ('DUNE' in voList)):

        if siteName not in sitesDict:
          logLine("Create maxima for %s:%s to %d bytes, %d processors" %
                  (siteName, entryName, rssBytes, processors))

          sitesDict[siteName] = { 'jobsub_site_name'      : jobsubSiteName,
                                  'largest_rss_bytes'     : rssBytes,
                                  'largest_processors'    : processors,
                                  'smallest_wall_seconds' : wallSeconds
                                }

        if rssBytes > sitesDict[siteName]['largest_rss_bytes']:
          logLine("Update maxima for %s:%s to %d bytes, %d processors" %
                  (siteName, entryName, rssBytes, processors))
          sitesDict[siteName]['largest_rss_bytes']    = rssBytes
          sitesDict[siteName]['largest_processors']   = processors
          
        if wallSeconds < sitesDict[siteName]['smallest_wall_seconds']:
          sitesDict[siteName]['smallest_wall_seconds'] = wallSeconds

def buildSites(sitesDict):

  tmpDir = tempfile.TemporaryDirectory()
  os.system('git clone https://github.com/opensciencegrid/osg-gfactory.git '
             + tmpDir.name)

  for fileName in os.listdir(tmpDir.name):
    if fileName[-4:] == '.xml':
      processOneFileXML(sitesDict, tmpDir.name + '/' + fileName)

def updateSites():
  # Get info about sites the pilot factories know about
  logLine('---- Start updateSites ----')

  sitesDict = {}
  buildSites(sitesDict)

  for siteName in sitesDict:
    # Ensure the sites exist
    query = ('INSERT INTO sites SET site_name="%s",jobsub_site_name="%s" '
             'ON DUPLICATE KEY UPDATE jobsub_site_name="%s"' 
             % (siteName, 
                sitesDict[siteName]['jobsub_site_name'], 
                sitesDict[siteName]['jobsub_site_name']
               )
            )

    wfs.db.cur.execute(query)
    
    maxProcessors  = sitesDict[siteName]['largest_processors']
    maxRssBytes    = sitesDict[siteName]['largest_rss_bytes']
    maxWallSeconds = int(sitesDict[siteName]['smallest_wall_seconds'] * 0.95)

    logLine('Site: %s, %d processors, %d bytes, %s seconds' %
            (siteName, maxProcessors, maxRssBytes, maxWallSeconds))

    # Go through the range of processors we found
    for processors in range(1, maxProcessors + 1):

      query = ('INSERT INTO slot_sizes SET '
               'last_seen_time=NOW(),'
               'site_id=(SELECT site_id FROM sites WHERE site_name="' + 
                  siteName + '"),' 
               'min_processors=%d,max_processors=%d,' 
               'min_rss_bytes=%d,'
               'max_rss_bytes=%d,' 
               'max_wall_seconds=%d '
               'ON DUPLICATE KEY UPDATE last_seen_time=NOW()' %
               (processors - 1, processors,
                int((maxRssBytes / maxProcessors) * (processors - 1)),
                int((maxRssBytes / maxProcessors) *  processors),
                maxWallSeconds
               )
              ) 

      wfs.db.cur.execute(query)

def updateSitesStorages(): 
  # Update the matrix of sites to storage mappings
  logLine('---- Start updateSitesStorages ----')

  # For now, these are hardcoded but eventually they will come from CRIC
  locations = { 'CERN,CERN_PDUNE_EOS'      : 'samesite',
                'CZ_FZU,PRAGUE'            : 'samesite',
                'UK_Manchester,MANCHESTER' : 'samesite',
                'UK_Lancaster,LANCASTER'   : 'samesite',
                'UK_QMUL,QMUL'             : 'samesite',
                'UK_RAL-Tier1,RAL_ECHO'    : 'samesite',
                'UK_RAL-PPD,RAL_ECHO'      : 'nearby',
                'UK_RAL-Tier1,RAL_PPD'     : 'nearby',
                'UK_RAL-PPD,RAL_PPD'       : 'samesite'
              }

  wfs.db.cur.execute('SELECT site_id,site_name FROM sites')
  siteRows = wfs.db.cur.fetchall()
  
  wfs.db.cur.execute('SELECT rse_id,rse_name FROM storages')
  storageRows = wfs.db.cur.fetchall()
  
  for siteRow in siteRows:
    for storageRow in storageRows:
      siteStorage = siteRow['site_name'] + ',' + storageRow['rse_name']    

      if siteStorage in locations:
        location = locations[siteStorage]
      else:
        location = 'accessible'

      query = ('INSERT INTO sites_storages SET '
               'location="' + location + '",' +
               'site_id=(SELECT site_id FROM sites WHERE site_name="' + 
                 siteRow['site_name'] + '"),' +
               'rse_id=(SELECT rse_id FROM storages WHERE rse_name="' + 
                 storageRow['rse_name'] + '") ' +
               'ON DUPLICATE KEY UPDATE '
               'location="' + location + '"'
              ) 
              
      wfs.db.cur.execute(query)

#  wfs.db.conn.commit()

def updateStorages():
  # Get info about storages Rucio knows about
  logLine('---- Start updateStorages ----')
  
  # Ensure the dummy MONTECARLO RSE exists, with rse_id 1
  wfs.db.cur.execute('INSERT INTO storages SET rse_id=%d,'
    'rse_name="MONTECARLO",occupancy=1,rse_write=FALSE,'
    'rse_read=TRUE,rse_delete=FALSE ` 
    'ON DUPLICATE KEY UPDATE occupancy=1'
    % wfs.conf.MonteCarloRseID)

  try:
    rseClient = rucio.client.rseclient.RSEClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return
  
  try:
    rseList = rseClient.list_rses()  
  except Exception as e:
    logLine("Reading RSE list from Rucio fails with: " + str(e))
    return

  for rse in rseList:
  
    logLine(str(rse))
  
    if rse['rse_type'] != 'DISK' and rse['rse'] != 'FNAL_DCACHE':
      # We ignore tape RSEs apart from tape-backed dCache at FNAL
      continue
      
    try:
      availability = rse['availability']
    except:
      availability = 0  

    try:
      usageList = rseClient.get_rse_usage(rse['rse'],
                                          filters = {"source": "storage"})
    except Exception as e:
      logLine("Reading %s usage fails with: %s" % 
              (rse['rse'], str(e)))
 
      occupancy = 1.0

    else:
      try:
        usage = next(usageList)
      except:
        occupancy = 1.0
      else:
        occupancy = float(usage['used']) / usage['total']
       
    # The FIRST time these are seen, they get set to ignore  
    if rse['rse'] in ['MONTECARLO', 'FNAL_DCACHE_TEST', 'SCRATCH_DCACHE']:
      ignoreForOutput = True
    else:
      ignoreForOutput = False

    try:
      # We should sanitise this name just in case...
      query = ('INSERT INTO storages SET rse_name="%s",'
               'occupancy=%f,rse_write=%d,rse_read=%d,rse-delete=%d,'
               'ignore_for_output=%d '
               'ON DUPLICATE KEY UPDATE occupancy=%f,rse_write=%d,'
               'rse_read=%d,rse_delete=%d '
               % (rse['rse'], 
                  occupancy, 
                  ((availability & wfs.db.rseAvailabilityWrite)  != 0), 
                  ((availability & wfs.db.rseAvailabilityRead)   != 0), 
                  ((availability & wfs.db.rseAvailabilityDelete) != 0),
                  ignoreForOutput,
                  occupancy,
                  ((availability & wfs.db.rseAvailabilityWrite)  != 0), 
                  ((availability & wfs.db.rseAvailabilityRead)   != 0), 
                  ((availability & wfs.db.rseAvailabilityDelete) != 0)
                 )
              )

      wfs.db.cur.execute(query)
    except Exception as e:
      # Log the error and hope it was transitory
      logLine('Failed inserting RSE %s into database: %s' % 
              (rse['rse'], str(e)))

#  wfs.db.conn.commit()

def oneCycle():

  # Is it time to update users?
  try:
    lastUpdateUsers = os.stat('/var/run/wfs/last-update-users').st_mtime
  except:
    lastUpdateUsers = 0

  if lastUpdateUsers + updateUsersInterval < time.time():
    pathlib.Path('/var/run/wfs/last-update-users').touch(exist_ok=True)
    updateUsers()

  # Is it time to update storages from Rucio?
  try:
    lastUpdateStorages = os.stat('/var/run/wfs/last-update-storages').st_mtime
  except:
    lastUpdateStorages = 0

  if lastUpdateStorages + updateStoragesInterval < time.time():
    pathlib.Path('/var/run/wfs/last-update-storages').touch(exist_ok=True)
    updateStorages()

  # It is time to update sites from the OSG pilot factory config?
  try:
    lastUpdateSites = os.stat('/var/run/wfs/last-update-sites').st_mtime
  except:
    lastUpdateSites = 0

  if lastUpdateSites + updateSitesInterval < time.time():
    pathlib.Path('/var/run/wfs/last-update-sites').touch(exist_ok=True)
    updateSites()
    updateSitesStorages()

  wfs.db.conn.commit()

#
# PROGRAM MAIN
#

if __name__ == '__main__':

  if (os.fork() != 0):
    sys.exit() # first parent

  else:
    os.chdir("/")
    os.setsid()
    os.umask(0)

    if os.fork() != 0:
      sys.exit() # second parent

    else:

      try:
        os.makedirs('/var/run/wfs',         
                    stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | 
                    stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
      except:
        pass
        
      try:
        f = open('/var/run/wfs/info-collector.pid', 'w')
        f.write(str(os.getpid()) + '\n')
        f.close()
      except:
        print('Failed to create /var/run/wfs/info-collector.pid - exiting')
        sys.exit(1)

      # Close stdin now
      si = open('/dev/null', 'r')
      os.dup2(si.fileno(), sys.stdin.fileno())

      while True:

        # Ensure /var/log/wfs directory exists
        try:
          os.makedirs('/var/log/wfs', 
                      stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR|stat.S_IRGRP|stat.S_IXGRP|stat.S_IROTH|stat.S_IXOTH)
        except:
          pass

        # Close and reopen stdout->log file, in case of logrotate
        try:
          close(so)
        except:
          pass

        so = open('/var/log/wfs/info-collector', 'a+')
        os.dup2(so.fileno(), sys.stdout.fileno())

        # Close and reopen stderr->log file, in case of logrotate
        try:
          close(se)
        except:
          pass

        se = open('/var/log/wfs/info-collector', 'a+')
        os.dup2(se.fileno(), sys.stderr.fileno())

        try:
          pf = open('/var/run/wfs/info-collector.pid', 'r')
          pid = int(pf.read().strip())
          pf.close()

          if pid != os.getpid():
            print('new /var/run/wfs/info-collector.pid - exiting')
            break

        except:
          print('no /var/run/wfs/info-collector.pid - exiting')
          break

        # Fork a subprocess to run each cycle
        cyclePid = os.fork()

        if cyclePid == 0:
          logLine('=============== Start cycle ===============')
          
          try:
            wfs.db.conn = MySQLdb.connect(host="localhost", 
                                  user=wfs.conf.mysqlUser,
                                  passwd=wfs.conf.mysqlPassword, 
                                  db='wfdb')
            wfs.db.conn.autocommit(False)
            wfs.db.cur = wfs.db.conn.cursor(MySQLdb.cursors.DictCursor)
          except Exception as e:
            logLine('Failed to create database connection (' + str(e) + ') - skipping cycle')
          else:
            try:
              oneCycle()
            except Exception as e:
              print('Cycle fails with exception ' + str(e))

          logLine('================ End cycle ================')
          sys.exit(0)

        # wait for cyclePid subprocess to finish
        os.waitpid(cyclePid, 0)

        # wait the allotted time between cycles
        time.sleep(sleepSeconds)

      sys.exit(0) # if we break out of the while loop then we exit

