#!/usr/bin/env python3
#
# justin-job-logs - justIN Finder agent
#
# Copyright 2013-25, Andrew McNab for the University of Manchester
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import sys
import ssl
import stat
import json
import time
import base64
import shutil
import hashlib
import tempfile
import subprocess
import urllib.request
import pathlib
import xml.dom.minidom

## Needs MySQL-python RPM
#import MySQLdb

# WE NEED TO REMOVE OLD MySQLdb REFERENCES STILL!
import pymysql
pymysql.install_as_MySQLdb()
MySQLdb=pymysql

# Installed by pip3 install of Rucio
import rucio.client

import justin

sleepSeconds = 60

class justinError(Exception):
  pass

def fetchHTCondorJobLog(jobsubID):

  try:
    (clusterProc, schedd) = jobsubID.split('@')
    (cluster, proc)       = clusterProc.split('.')

    outcome = subprocess.run(['/var/lib/justin/justin-get-output',
                              str(cluster),
                              str(proc),
                              str(schedd),
                              justin.htcondorCollectors[0],
                              'remove'
                             ],
                              encoding = 'utf-8',
                              stderr   = subprocess.STDOUT,
                              stdout   = subprocess.PIPE,
                              timeout  = 120)
  except Exception as e:
    raise RuntimeError('For %s.%s@%s justin-get-output fails with %s' 
                       % (cluster, proc, schedd, str(e)))


  if outcome.returncode != 0:
    raise RuntimeError('For %s.%s@%s justin-get-output fails with '
                       'error code %d'
                       % (cluster, proc, schedd, outcome.returncode))

  return outcome.stdout

def saveTerminalJobsLogs():
  # Returns the number of jobs with logs saved this time

  justin.logLine('Start of saving HTCondor jobs')

  nowTime = int(time.time())

  terminalWithQuotes = []
  for i in justin.jobStatesTerminal:
    terminalWithQuotes.append('"%s"' % i)
    
  # Get a list of jobs in terminal states without saved wrapper logs
  # that finished in the last week and still have tries left 
  # (so we don't try forever)
  query = ('SELECT jobs.justin_job_id,jobsub_id,job_state,'
           'jobs.workflow_id,jobs.stage_id,jobs.site_id,jobs.entry_id '
           'FROM jobs '
           'LEFT JOIN jobs_logs '
           'ON jobs_logs.justin_job_id=jobs.justin_job_id '
           'WHERE wrapper_log="" AND job_state IN (%s) '
           'AND wrapper_tries_left > 0 '
           'AND jobs.finished_time > DATE_SUB(NOW(),INTERVAL 7 DAY) '
           'ORDER BY jobs.justin_job_id LIMIT 1000' 
           % ','.join(terminalWithQuotes))

  dbJobRows = justin.select(query)

  # Make a set of unique HTCondor schedd names from the database
  schedds = set()
  for dbJobRow in dbJobRows:
    schedds.add( dbJobRow['jobsub_id'].split('@',1)[1] )

  # Gather details of HTCondor jobs from our set of schedds
  condorJobs = {}  

  for scheddHostname in schedds:
    try: 
      outcome = subprocess.run(
               ['/usr/bin/condor_q',
                '-name',
                scheddHostname,
                '-pool',
                justin.htcondorCollectors[0],
                '-long:json',
                '-attributes',
                'clusterid,procid,jobstatus,enteredcurrentstatus'
               ],
               env      = dict(os.environ, 
                 BEARER_TOKEN_FILE='/etc/justin-secrets/bearer-token-file'),
               encoding = 'utf-8',
               stderr   = subprocess.STDOUT,
               stdout   = subprocess.PIPE,
               timeout  = 120
                            ) 
    except Exception as e:
      justin.logLine("condor_q fails with error: " + str(e))
      return 0

    justin.logLine('condor_q exit code: ' + str(outcome.returncode))
    
    if outcome.returncode != 0:
      justin.logLine("condor_q fails with return code %d" % outcome.returncode)
      return 0

    try:
      jsonJobs = json.loads(outcome.stdout)
    except:
      justin.logLine('Failed to load JSON output by condor_q')
      return 0

    for jsonJob in jsonJobs:  
      if 'jobstatus' not in jsonJob or \
         'enteredcurrentstatus' not in jsonJob or \
         'clusterid' not in jsonJob or \
         'procid' not in jsonJob:
        continue
      
      condorJobs['%d.%d@%s' % 
                 (jsonJob['clusterid'], 
                  jsonJob['procid'],
                  scheddHostname)] = \
           (jsonJob['jobstatus'], jsonJob['enteredcurrentstatus'])

  if not condorJobs:
    # If we get nothing at all then something must be going wrong
    justin.logLine('Failed to find any job info from HTCondor')
    return 0

  # Go back to the list of jobs from the database that have no wrapper log
  # saved and check each one against its HTCondor status, and try to fetch
  # logs
  
  subprocessDir  = tempfile.mkdtemp(prefix='justin-job-logs-')
  subprocessList = []

  for dbJobRow in dbJobRows:
    
    if dbJobRow['jobsub_id'] not in condorJobs:
      # if Condor is unaware of the job, then we're never going to get it
      justin.logLine('Job %s is not known to HTCondor - put placeholder log' 
              % dbJobRow['jobsub_id'])
      try:
        justin.insertUpdate('UPDATE jobs_logs '
              'SET wrapper_tries_left=0,saved_time=NOW() '
              'WHERE justin_job_id=%d' % dbJobRow['justin_job_id'])
      except Exception as e:
        # Log but otherwise ignore error
        justin.logLine('Failed to add placeholder wrapper log for %s: %s'
                       % (dbJobRow['jobsub_id'], str(e)))
    
      continue      

    (jobStatus, enteredCurrentStatus) = condorJobs[dbJobRow['jobsub_id']]

    # If not yet in an HTCondor terminal state them skip for now
    if ((jobStatus != justin.htcondorREMOVED) and
        (jobStatus != justin.htcondorCOMPLETED)):
      justin.logLine('Job %s is in HTCondor state %d - skip for now' %
                (dbJobRow['jobsub_id'], jobStatus))
      continue

    # In a terminal state so try to get the logs and remove from spool
    try:
      justin.insertUpdate('UPDATE jobs_logs '
                          'SET wrapper_tries_left=wrapper_tries_left-1 '
                          'WHERE wrapper_tries_left > 0 AND '
                          'justin_job_id=%d' % dbJobRow['justin_job_id'])
    except Exception as e:
      justin.logLine('Failed to update wrapper_tries_left (%s) - ignoring'
                       % str(e))
      continue

    subprocessPID = os.fork()
    
    if subprocessPID == 0:
      # In subprocess, try to fetch logs and remove job
      try:
        wrapperLog = fetchHTCondorJobLog(dbJobRow['jobsub_id'])
      except Exception as e:
        justin.logLine('Failed fetching wrapper job log for %s: %s' %
                       (dbJobRow['jobsub_id'], str(e)))
      else:
        justin.logLine('Fetched wrapper job log for %s (%d)' %
                       (dbJobRow['jobsub_id'], dbJobRow['justin_job_id']))
        try:
          f = open(subprocessDir+'/'+str(dbJobRow['justin_job_id']), 'w')
          f.write(wrapperLog)
          f.close()
        except Exception as e:
          justin.logLine('Failed writing wrapper log for %s: %s' %
                         (dbJobRow['jobsub_id'], str(e)))                         
      sys.exit(0)
          
    # In parent
    justin.logLine('Forked %d for %s (%d)' % 
                   (subprocessPID, 
                    dbJobRow['jobsub_id'], 
                    dbJobRow['justin_job_id']))
    subprocessList.append(subprocessPID)

    if len(subprocessList) > justin.parallelJobLogs:
      # We only fork so many times
      break

  # Wait until all subprocesses have finished
  for count in range(0, 31):
    anyActive = False
    for i in subprocessList:
      if justin.pidIsActive(i):
        anyActive = True
        break
    
    if not anyActive:
      break
      
    time.sleep(1)

  # Kill any still running
  if anyActive:
    for i in subprocessList:
      if justin.pidIsActive(i):
        try:
          os.kill(cyclePid)
        except Exception:
          # Not much we can do except log it
          justin.logLine('Kill of %d fails with: %s' % (i, str(e)))

  # Go through the subprocess outputs and save logs in the database
  numberSaved = 0
  for justinJobID in os.listdir(subprocessDir):
    justin.logLine('Processing %s' % justinJobID)
    try:
      wrapperLog = open(subprocessDir + '/' + justinJobID, 'r').read()
    except Exception as e:
      justin.logLine('Failed reading logs file for %s: %s' %
                     (justinJobID, str(e)))
      continue
      
    # Save the HTCondor job log
    try:
      justin.insertUpdate('UPDATE jobs_logs '
              'SET wrapper_log="%s",saved_time=NOW() '
              'WHERE justin_job_id=%s' % 
              (wrapperLog.replace('\\','\\\\').replace('"','\\"'), 
               justinJobID))
    except Exception as e:
      justin.logLine('Failed to save wrapper job log (%s) - skipping'
                     % str(e))
      continue
    else:
      justin.logEvent(eventTypeID = justin.event_JOB_HTCONDOR_LOGS_CACHED,
#                      workflowID  = dbJobRow['workflow_id'],
#                      stageID     = dbJobRow['stage_id'],
#                      siteID      = dbJobRow['site_id'],
#                      entryID     = dbJobRow['entry_id'],
                      justinJobID = justinJobID)
    
    numberSaved += 1
    justin.logEvent(eventTypeID = justin.event_JOB_REMOVED_FROM_HTCONDOR,
#                      workflowID  = dbJobRow['workflow_id'],
#                      stageID     = dbJobRow['stage_id'],
#                      siteID      = dbJobRow['site_id'],
#                      entryID     = dbJobRow['entry_id'],
                      justinJobID = justinJobID)

  # All ok, so remove temp directory and commit everything to the DB
  shutil.rmtree(subprocessDir, ignore_errors = True)
  justin.conn.commit()

  return numberSaved
 
def oneCycle():

  if saveTerminalJobsLogs() == 0:
    # Only sleep between cycles if we found no logs to save
    # This means if the job rate is big enough, we never sleep
    justin.logLine('No logs saved, so sleep for %d seconds' % sleepSeconds)
    time.sleep(sleepSeconds)
#
# PROGRAM MAIN
#

if __name__ == '__main__':
  # 0 means no sleeps between cycles. We do the sleeps in oneCycle() itself
  justin.agentMainLoop('job-logs', oneCycle, 0, 3600)
