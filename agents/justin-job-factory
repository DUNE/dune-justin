#!/usr/bin/env python3
#
# justin-job-factory - justIN Job Factory
#
# Copyright 2013-23, Andrew McNab for the University of Manchester
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import pwd
import sys
import stat
import time
import secrets
import tempfile
import subprocess

# Needs MySQL-python RPM
import MySQLdb

# justin/conf.py must define these variables in a way that is both
# valid Python and valid Bash!
#
# mysqlUser='username'
# mysqlPassword='PAsSWoRd'
#
import justin

sleepSeconds      = 60
jobsPerCluster    = 192
maxSubmitted      = 2000

# Jobsub names of all sites we always ignore. This is for sites unknown to us 
# because they do not have pilot factory entries. Known sites are disabled in
# the database.
alwaysIgnoreSitesList = [ ] # [ 'UConn-HPC' ] 

def logLine(text):
  sys.stdout.write(time.strftime('%b %d %H:%M:%S [') + str(os.getpid()) + ']: ' + text + '\n')
  sys.stdout.flush()

#def updateSiteCounts():
#
#  try:
#    justin.db.cur.execute('UPDATE sites SET '
#        'submitted_jobs='
#        '(SELECT COUNT(*) FROM jobs WHERE '
#         '(sites.site_id = jobs.site_id) AND '
#         '(jobs.submitted_time > DATE_SUB(NOW(),INTERVAL 24 HOUR)) AND '
#         '(allocation_state = "submitted")),'
#        'running_jobs='
#        '(SELECT COUNT(*) FROM jobs WHERE '
#         'sites.site_id=jobs.site_id AND allocation_state '
#         'IN ("started","processing","outputting"))')
#  except Exception as e:
#    logLine('Update site counts fails with: ' + str(e))
#  else:
#    justin.db.conn.commit()
#    logLine('Updated site job counts')
   
def submitJobs(numberToSubmit, 
               workflowID,
               stageID,
               firstSiteID,
               desiredSiteNames,
               desiredEntryNames,
               requestedProcessors,
               requestedRssBytes,
               requestedWallSeconds):

  #Â If targetting one site, then firstSiteID should be non-zero
  # desiredSiteNames is a comma separated list of jobsub style site names
  # to match GLIDEIN_Site classads and others used by GlideInWMS

  logLine('submitJobs %d w%ds%s %s %s %s %d %d %d' %
          (numberToSubmit,
               workflowID,
               stageID,
               firstSiteID,
               desiredSiteNames,
               desiredEntryNames,
               requestedProcessors,
               requestedRssBytes,
               requestedWallSeconds))
  try:
    wrapperText = open('/var/lib/justin/justin-wrapper-job','r').read()
  except Exception as e:
    logLine('Failed loading justin-wrapper-job: ' + str(e))
    return

  justinJobSecret = secrets.token_urlsafe(64)

  for (p, s) in (('###justin_job_secret###',  justinJobSecret),
                 ('###justin_prodev###',      justin.conf.proDev),
                 ('###justin_workflow_id###', str(workflowID)),
                 ('###justin_stage_id###',    str(stageID))
                ):
    wrapperText = wrapperText.replace(p,s)

  try:    
    wrapperFile = tempfile.NamedTemporaryFile(mode='w+',
                                              prefix = 'justin-wrapper-job-',
                                              dir = '/tmp', 
                                              delete = False)

    wrapperFile.write(wrapperText)
  except Exception as e:
    logLine('Failed writing %s: %s'  % (wrapperFile.name, str(e)))
    return
  finally:
    wrapperFile.close()

  submitFile = """
+Desired_Sites          = "%s"
+Desired_Entries        = "%s"
+SingularityImage       = "/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest"
+Jobsub_Group           = "dune"
+Job_Expected_Max_Lifetime = %d
+JUSTIN_%s_Stage        = w%ds%d
universe                = vanilla
environment = "JUSTIN_JOBSUB_ID=$(Cluster).$(Process)@justin-prod-sched01.dune.hep.ac.uk"
periodic_remove         = (JobStatus == 1) && ((time() - QDate) > 86400)
max_retries             = 0
retry_until             = True
notification            = Never
executable              = %s
arguments               = 
accounting_group        = group_dune.prod_mcsim
#accounting_group        = group_dune.prod_keepup
accounting_group_user   = dunejustin
rank                    = Mips / 2 + Memory
job_lease_duration      = 3600
request_memory          = %dKB
request_cpus            = %d
request_disk            = 1
getenv                  = False
output                  = /tmp/justin-wrapper-$(Cluster).$(Process).out
error                   = /tmp/justin-wrapper-$(Cluster).$(Process).out
log                     = /tmp/justin-wrapper-$(Cluster).$(Process).log
transfer_output_files   = ""
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
requirements = ((isUndefined(target.GLIDEIN_Site) == FALSE) && (stringListIMember(target.GLIDEIN_Site,my.Desired_Sites)))
#requirements = ((isUndefined(target.GLIDEIN_Entry_Name) == FALSE) && (stringListIMember(target.GLIDEIN_Entry_Name,my.Desired_Entries)))
queue %d
""" % (desiredSiteNames, 
       desiredEntryNames, 
       requestedWallSeconds,
       justin.conf.proDev.upper(),
       workflowID, stageID,
       wrapperFile.name,
       int(requestedRssBytes / 1024), 
       requestedProcessors,
       numberToSubmit)
  
  # For debugging the submit file
  if False:
    lineNumber = 1
    for line in submitFile.splitlines():
      print('%03d %s' % (lineNumber, line))
      lineNumber += 1

  try: 
    outcome = subprocess.run(
               ['/usr/bin/condor_submit',
                '-spool',
                '-terse'
               ],
               input    = submitFile,
               encoding = 'utf-8',
               stderr   = subprocess.STDOUT,
               stdout   = subprocess.PIPE,
               timeout  = 60
                            ) 
  except Exception as e:
    logLine("condor_submit fails with error: " + str(e))
    return
  finally:
    os.remove(wrapperFile.name)

  logLine('%s' % str(outcome.stdout))
  logLine('condor_submit exit code: ' + str(outcome.returncode))

  try:
    clusterID = int(outcome.stdout.split('.')[0])
  except:
    logLine('Failed to get cluster ID from %s' % outcome.stdout)
    return

  scheddHostname = 'justin-prod-sched01.dune.hep.ac.uk'
  jobsubJobID = '%d.0@%s' % (clusterID, scheddHostname)
 
  logLine("Submitted cluster %s to %s%s" % 
          (jobsubJobID, 
           desiredSiteNames,
           ' (AWT job)' if workflowID == justin.awtWorkflowID else ''))

  # Record the job(s) in the database
  for i in range(0, numberToSubmit):
    try:
      justin.db.cur.execute('INSERT INTO jobs '
                  'SET factory_name="%s",'
                  'workflow_id=%d,'
                  'stage_id=%d,'
                  'site_id=%d,'
                  'requested_processors=%d,'
                  'requested_rss_bytes=%d,'
                  'requested_wall_seconds=%d,'
                  'submitted_time=NOW(),'
                  'need_to_fetch_jobsub_log=%s,'
                  'for_awt=%s,'
                  'justin_job_secret="%s",'
                  'jobscript_secret="%s",'
                  'jobsub_id="%s.%d@%s"'
                  % (os.uname()[1],
                     workflowID,
                     stageID,
                     firstSiteID,
                     requestedProcessors,
                     requestedRssBytes,
                     requestedWallSeconds,
                     "TRUE" if i == 0 else "FALSE",
                     "TRUE" if workflowID == justin.awtWorkflowID else "FALSE",
                     justinJobSecret,
                     secrets.token_urlsafe(64),
                     clusterID, i, scheddHostname)
                 )

    except Exception as e:
      # But try to keep going
      logLine('INSERT INTO jobs fails with: ' + str(e))

  # Record that we've done a submission if just for one site
  if firstSiteID:
    try:
      justin.db.cur.execute('UPDATE sites SET last_submitted_time=NOW() '
                            'WHERE site_id=%d' % firstSiteID)

    except Exception as e:
      # But try to keep going
      logLine('Update last_submitted_time fails with: ' + str(e))

  # Commit it all to the DB
  justin.db.conn.commit()

# Submit jobs for highest priority workflows/stages 
def workflowJobs():

  # Find stages of running workflows  
  try:
    stagesRows = justin.select(
     'SELECT workflows.workflow_id,stages.stage_id,max_distance,'
     'wlcg_group_name,stages.processors,stages.wall_seconds,stages.rss_bytes '
     'FROM workflows '
     'LEFT JOIN stages ON stages.workflow_id=workflows.workflow_id '
     'LEFT JOIN scopes ON workflows.scope_id=scopes.scope_id '
     'LEFT JOIN wlcg_groups ON wlcg_groups.wlcg_group_id=scopes.wlcg_group_id '
     'WHERE workflows.state="running" AND workflows.workflow_id<>%d '
     'ORDER BY workflows.workflow_id'
     % justin.awtWorkflowID
                              )
  
  except Exception as e:
    logLine('Failed to get list of stages of running workflows: ' + str(e))
    return             

  for stageRow in stagesRows:
  
    logLine('Processing ' + str(stageRow))

    # Count unallocated files for this stage    
    try:
      row = justin.select('SELECT COUNT(*) AS count FROM files '
                          'WHERE workflow_id=%d AND stage_id=%d '
                          'AND state="unallocated"'
                          % (stageRow['workflow_id'],
                             stageRow['stage_id']), justOne = True)
   
      unallocatedCount = int(row['count'])
    except:
      unallocatedCount = 0

    # Count submitted jobs for this stage    
    try:
      row = justin.select('SELECT COUNT(*) AS count FROM jobs '
                          'WHERE workflow_id=%d AND stage_id=%d AND '
                          'allocation_state="submitted" AND '
                          'submitted_time > DATE_SUB(NOW(),INTERVAL 1 DAY)',
                          justOne = True)
   
      submittedCount = int(row['count'])
    except:
      submittedCount = 0

    logLine('unallocatedCount=%d  submittedCount=%d  maxSubmitted=%d' 
            % (unallocatedCount, submittedCount, maxSubmitted))

    if unallocatedCount > submittedCount:
      # Need to submit more jobs: find suitable entries and sites
      try:
        entriesRows = justin.select(
   "SELECT entries.entry_name,sites.site_name "
   "FROM files "
   "LEFT JOIN replicas ON files.file_id=replicas.file_id "
   "LEFT JOIN storages ON replicas.rse_id=storages.rse_id "
   "LEFT JOIN sites_storages ON replicas.rse_id=sites_storages.rse_id "
   "AND sites_storages.distance <= %f "
   "LEFT JOIN entries ON entries.site_id=sites_storages.site_id "
   "LEFT JOIN sites ON sites.site_id=entries.site_id "
   "WHERE files.workflow_id=%d "
   "AND files.stage_id=%d "
   "AND files.state='unallocated' " 
   "AND replicas.accessible_until > NOW() "
   "AND storages.rucio_read "
   "AND storages.justin_read "
   "AND NOT storages.decommissioned "
   "AND sites.site_id IS NOT NULL "
   "%s "
   "ORDER BY sites_storages.distance,files.file_id "
   "LIMIT 1000 "
         % (stageRow['max_distance'],
            stageRow['workflow_id'],
            stageRow['stage_id'],            
            '' if (stageRow['wlcg_group_name'] == '/dune/production') 
            else 'AND entries.always_inner_apptainer'))

      except Exception as e:
        logLine('Failed to get list of entries/sites: ' + str(e))
        continue
        
      logLine('entriesRows %s' % str(entriesRows))
 
      if submittedCount > maxSubmitted:
        logLine('Skipping due to number already submitted > %d' % maxSubmitted)
        continue

      desiredSites   = set()
      desiredEntries = set()
    
      # Submit clusters of jobs
      for entryRow in entriesRows:
        desiredSites.add(  entryRow['site_name'])
        desiredEntries.add(entryRow['entry_name'])

      if desiredSites and desiredEntries \
         and (unallocatedCount > submittedCount):
        desiredSiteNames  = ','.join(desiredSites)
        desiredEntryNames = ','.join(desiredEntries)

        numberToSubmit = unallocatedCount - submittedCount
        if numberToSubmit > jobsPerCluster:
         numberToSubmit = jobsPerCluster

        logLine('Submit %d jobs with desired sites: %s'
               % (numberToSubmit, desiredSiteNames))

        submitJobs(numberToSubmit       = numberToSubmit,
                   workflowID           = stageRow['workflow_id'],
                   stageID              = stageRow['stage_id'],
                   firstSiteID          = 0,
                   desiredSiteNames     = desiredSiteNames,
                   desiredEntryNames    = desiredEntryNames,
                   requestedProcessors  = stageRow['processors'],
                   requestedRssBytes    = stageRow['rss_bytes'],
                   requestedWallSeconds = stageRow['wall_seconds'])

#       logLine('%d processors %d MB has %d submitted and %d unallocated' % 
#            (processors, 
#             int((bytesPerProcessor * processors) / (1024 * 1024)),
#             numberSubmitted, numberUnallocated))

def awtJobsToSites():
  # Go through the sites deciding where to submit AWT jobs

  try:
    rows = justin.db.select('SELECT site_id,'
      'site_name,'
      'jobsub_site_name '
      'FROM sites '
      'WHERE '
      '((SELECT COUNT(*) FROM jobs WHERE'
      '  jobs.site_id=sites.site_id AND for_awt AND'
      '  submitted_time > DATE_SUB(NOW(),INTERVAL 6 HOUR)) = 0) AND '
      '(last_seen_time > DATE_SUB(NOW(),INTERVAL %d DAY)) '
      'ORDER BY site_name' % justin.unseenSitesExpireDays
      # Should change this to random order?
               )

  except Exception as e:
    logLine('Failed getting list of sites for AWT jobs: ' + str(e))
    return
  
  for row in rows:
      submitJobs(numberToSubmit       = 1,
                 workflowID           = justin.awtWorkflowID,
                 stageID              = 1,
                 firstSiteID          = row['site_id'],
                 desiredSiteNames     = row['jobsub_site_name'],
                 desiredEntryNames    = '',
                 requestedProcessors  = 1,
                 requestedRssBytes    = 1024 * 1024 * 1024,
                 requestedWallSeconds = 3600)
    
def oneCycle():
  # Update the database with the states of submitted jobsub jobs

#  logLine("updateSiteCounts()")
#  updateSiteCounts()

  logLine("awtJobsToSites()")
  awtJobsToSites()

#  logLine("anySiteJobs()")
#  anySiteJobs()

  logLine("workflowJobs()")
  workflowJobs()

#
# PROGRAM MAIN
#

if __name__ == '__main__':

  if (os.fork() != 0):
    sys.exit() # first parent

  else:
    os.chdir("/")
    os.setsid()
    os.umask(0)

    if os.fork() != 0:
      sys.exit() # second parent

    else:

      try:
        os.makedirs('/var/run/justin',         
                    stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | 
                    stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
      except:
        pass
        
      try:
        f = open('/var/run/justin/job-factory.pid', 'w')
        f.write(str(os.getpid()) + '\n')
        f.close()
      except:
        print('Failed to create /var/run/justin/job-factory.pid - exiting')
        sys.exit(1)

      # Close stdin now
      si = open('/dev/null', 'r')
      os.dup2(si.fileno(), sys.stdin.fileno())

      while True:

        # Ensure /var/log/justin directory exists
        try:
          os.makedirs('/var/log/justin', 
                      stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR|stat.S_IRGRP|stat.S_IXGRP|stat.S_IROTH|stat.S_IXOTH)
        except:
          pass

        # Close and reopen stdout->log file, in case of logrotate
        try:
          close(so)
        except:
          pass

        so = open('/var/log/justin/job-factory', 'a+')
        os.dup2(so.fileno(), sys.stdout.fileno())

        # Close and reopen stderr->log file, in case of logrotate
        try:
          close(se)
        except:
          pass
          
        se = open('/var/log/justin/job-factory', 'a+')
        os.dup2(se.fileno(), sys.stderr.fileno())

        try:
          pf = open('/var/run/justin/job-factory.pid', 'r')
          pid = int(pf.read().strip())
          pf.close()

          if pid != os.getpid():
            print('new /var/run/justin/job-factory.pid - exiting')
            break

        except:
          print('no /var/run/justin/job-factory.pid - exiting')
          break

        # Fork a subprocess to run each cycle
        cyclePid = os.fork()

        if cyclePid == 0:
          logLine('=============== Start cycle ===============')
          
          justin.conf.readConf()
          
          try:
            justin.db.conn = MySQLdb.connect(host=justin.conf.mysqlHostname, 
                                  user=justin.conf.mysqlUsername,
                                  passwd=justin.conf.mysqlPassword, 
                                  db=justin.conf.mysqlDbName)
            justin.db.conn.autocommit(False)
            justin.db.cur = justin.db.conn.cursor(MySQLdb.cursors.DictCursor)
          except Exception as e:
            logLine('Failed to create database connection (' + str(e) + ') - skipping cycle')
          else:
            try:
              p = pwd.getpwnam(justin.conf.agentUsername)
              os.setgid(p[3])
              os.setuid(p[2])
              oneCycle()
            except Exception as e:
              print('Cycle fails with exception ' + str(e))

          logLine('================ End cycle ================')
          sys.exit(0)

        # wait for cyclePid subprocess to finish
        os.waitpid(cyclePid, 0)

        # wait the allotted time between cycles
        time.sleep(sleepSeconds)

      sys.exit(0) # if we break out of the while loop then we exit

