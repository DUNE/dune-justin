#!/usr/bin/env python3
#
# justin-info-collector - justIN info collector agent
#
# Copyright 2013-23, Andrew McNab for the University of Manchester
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import sys
import stat
import pwd
import time
import ssl
import json
import urllib
import urllib.request
import pathlib
import tempfile
import warnings
import subprocess
import xml.dom.minidom

# Needs MySQL-python RPM
import MySQLdb

# Installed by pip install of Rucio
import rucio.client

# Needs python36-PyYAML
import yaml

import justin

updateSitesInterval    = 3600
updateStoragesInterval = 3600
updateJwksInterval     = 86400

sleepSeconds = 60

def logLine(text):
  sys.stdout.write(time.strftime('%b %d %H:%M:%S [') + str(os.getpid()) + ']: ' + text + '\n')
  sys.stdout.flush()

def getJsonURL(url):
  httpRequest = urllib.request.Request(url)
  sslContext  = ssl.SSLContext()
  sslContext.verify_mode = ssl.CERT_REQUIRED
  sslContext.check_hostname = True
  sslContext.load_verify_locations(capath = '/etc/grid-security/certificates')

  try:
    response = urllib.request.urlopen(httpRequest, context = sslContext)
  except Exception as e:
    logLine('Get JSON URL workflow fails: ' + str(e))
    return None
  else:
    if response.status != 200:
      logLine('Get JSON URL response not 200, code=%d' 
              % response.status)
      return None

  try:
    responseData = response.read().decode('utf-8')
    responseDict = json.loads(responseData)
  except Exception as e:
    logLine('Failed loading json: ' + str(e))
    return None

  return responseDict

def updateJwks():
  logLine('Start update of JWT keys')

  # Upate the database with current JWT keys for DUNE from CILogon 
  openidConfiguration = getJsonURL(
              'https://cilogon.org/dune/.well-known/openid-configuration')
              
  if openidConfiguration and 'jwks_uri' in openidConfiguration:
    cilogonJwks = getJsonURL(openidConfiguration['jwks_uri'])
    if cilogonJwks and 'keys' in cilogonJwks:
      for jwtKey in cilogonJwks['keys']:
        if (not justin.stringIsSite(jwtKey['n']) or 
            not justin.stringIsSite(jwtKey['e']) or 
            not justin.stringIsSite(jwtKey['alg']) or 
            not justin.stringIsSite(jwtKey['kid']) or 
            not justin.stringIsSite(jwtKey['use']) or 
            not justin.stringIsSite(jwtKey['kty'])):
          logLine('Problem with key format')
          continue
      
        try:
          justin.insertUpdate('REPLACE INTO jwt_keys SET '
                              'jwks_n="%s",'
                              'jwks_e="%s",'
                              'jwks_alg="%s",'
                              'jwks_kid="%s",'
                              'jwks_use="%s",'
                              'jwks_kty="%s"'
                              % (jwtKey['n'], jwtKey['e'], jwtKey['alg'],
                                 jwtKey['kid'], jwtKey['use'], jwtKey['kty']))
        except Exception as e:                         
          logLine('Failed updating JWKS: ' + str(e))
        else:
          logLine('Updating JWT key kid=%s' % jwtKey['kid'])
 
      justin.conn.commit()
      return
      
  logLine('Failed updating CILogon JWT keys')

def cleanupNodeXML(node):
  if node.nodeType == xml.dom.Node.TEXT_NODE \
     and node.nodeValue.strip() == "":
    node.nodeValue = ""
  
  for childNode in node.childNodes:
    cleanupNodeXML(childNode)

def processOneFileXML(sitesDict, fileName):

  try:
# NASTY HACKY FIX FOR BAD XML FROM OSG!!!
    xmlStr = open(fileName).read().replace('comment"','comment="')
    xmlDocument = xml.dom.minidom.parseString(xmlStr)
  except Exception as e:
    logLine('Parsing XML file %s fails with: %s' % (fileName, str(e)))
    return

  cleanupNodeXML(xmlDocument)
  xmlDocument.normalize()

  xmlEntries = xmlDocument.firstChild.firstChild

  for xmlEntry in xmlEntries.childNodes:

    #Â Find an entry and process it
    if xmlEntry.nodeType == xml.dom.Node.ELEMENT_NODE and \
       xmlEntry.tagName == 'entry':

      try:
        entryName = xmlEntry.getAttribute('name')
      except:
        continue

      try:
        gatekeeper = xmlEntry.getAttribute('gatekeeper').split(' ')[0]
      except:
        gatekeeper = entryName

      try:
        entryEnabled = xmlEntry.getAttribute('enabled')
      except:
        entryEnabled = 'True'

      try:
        gridType = xmlEntry.getAttribute('gridtype')
      except:
        gridType = ''

      if entryEnabled == 'False' or gridType == 'cream':
        continue

      siteName        = None
      jobsubSiteName  = None
      wlcgSiteName    = ''
      voList          = []
      processors      = 1
      rssBytes        = 2000 * 1024 * 1024
      wallSeconds     = 86400            

      # Assemble the GLIDEIN values for this entry
      for xmlEntryChild in xmlEntry.childNodes:
        if xmlEntryChild.nodeType == xml.dom.Node.ELEMENT_NODE and \
           xmlEntryChild.tagName == 'attrs':

          for xmlAttr in xmlEntryChild.childNodes:
            
            if xmlAttr.nodeType == xml.dom.Node.ELEMENT_NODE and \
               xmlAttr.tagName == 'attr':
               
              name  = xmlAttr.getAttribute('name')
              value = xmlAttr.getAttribute('value')
               
              if name == 'GLIDEIN_DUNESite':
                siteName = xmlAttr.getAttribute('value')

              elif name == 'GLIDEIN_Site':
                jobsubSiteName = xmlAttr.getAttribute('value')

              elif name == 'GLIDEIN_ResourceName':
                wlcgSiteName = xmlAttr.getAttribute('value')

              elif name == 'GLIDEIN_CPUS':
                try:
                  processors = int(xmlAttr.getAttribute('value'))
                except:
                  pass
                
              elif name == 'GLIDEIN_MaxMemMBs':
                try:
                  rssBytes = int(xmlAttr.getAttribute('value')) * 1048576
                except:
                  pass
                
              elif name == 'GLIDEIN_Max_Walltime':
                try:
                  wallSeconds = int(xmlAttr.getAttribute('value'))
                except:
                  pass
                
              elif name == 'GLIDEIN_Supported_VOs':
                voList = xmlAttr.getAttribute('value').split(',')

      # If we found the necessary GLIDEIN values, then carry on
      if (siteName and jobsubSiteName and processors and rssBytes and
          wallSeconds and ('DUNE' in voList)):

        if siteName not in sitesDict:
          logLine("Create maxima for %s:%s to %d bytes, %d processors" %
                  (siteName, entryName, rssBytes, processors))

          sitesDict[siteName] = { 'jobsub_site_name'      : jobsubSiteName,
                                  'wlcg_site_name'        : wlcgSiteName,
                                  'largest_rss_bytes'     : rssBytes,
                                  'largest_processors'    : processors,
                                  'smallest_wall_seconds' : wallSeconds,
                                  'entries'               : []
                                }

        sitesDict[siteName]['entries'].append({ 'entry_name'  : entryName,
                                                'gatekeeper'  : gatekeeper,
                                                'max_rss_bytes'   : rssBytes,
                                                'max_wall_seconds': wallSeconds,
                                                'max_processors'  : processors
                                              })

        if rssBytes > sitesDict[siteName]['largest_rss_bytes']:
          logLine("Update maxima for %s:%s to %d bytes, %d processors from %s"
                  % (siteName, entryName, rssBytes, processors, fileName))
          sitesDict[siteName]['largest_rss_bytes']    = rssBytes
          sitesDict[siteName]['largest_processors']   = processors
          
        if wallSeconds < sitesDict[siteName]['smallest_wall_seconds']:
          sitesDict[siteName]['smallest_wall_seconds'] = wallSeconds

def processOneFileYAML(sitesDict, fileName):

  try:
    yamlDict = yaml.safe_load(open(fileName,'r'))
  except Exception as e:
    logLine('Parsing YAML file %s fails with: %s' % (fileName, str(e)))
    return
    
  logLine('Parsing YAML file %s' % fileName)

  for osgSiteName in yamlDict:
    for osgGatekeeper in yamlDict[osgSiteName]:
      if osgGatekeeper == 'common_entry_fields':
        logLine('Skipping common_entry_fields of %s' % osgSiteName)
        continue
    
      if 'BEST_FIT' not in yamlDict[osgSiteName][osgGatekeeper]:
        logLine('%s:%s has no BEST_FIT - ignoring' 
                % (osgSiteName,osgGatekeeper))
        continue

#      print(osgGatekeeper)
#      print(yamlDict[osgSiteName][osgGatekeeper])
    
      for entryName in yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']:
        if (not yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT'][entryName] 
            or 'attrs' not in 
            yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT'][entryName]):
          logLine('%s has no attrs! - ignoring' % entryName)
          continue

        # Check if this entry even supports DUNE
        try:
          voList = yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']\
                           [entryName]['attrs']['GLIDEIN_Supported_VOs']\
                           ['value'].split(',')
        except:
          try:
            voList = yamlDict[osgSiteName]['common_entry_fields']\
                             ['attrs']['GLIDEIN_Supported_VOs']\
                             ['value'].split(',')
          except:
            voList = []
          
        if 'DUNE' not in voList:
          logLine('%s does not support DUNE - ignoring' % entryName)
          continue

        # GLIDEIN_Site = justIN jobsubSiteName
        try:
          jobsubSiteName = yamlDict[osgSiteName][osgGatekeeper]\
                     ['BEST_FIT'][entryName]['attrs']['GLIDEIN_Site']['value']
        except:
          try:
            jobsubSiteName = yamlDict[osgSiteName]['common_entry_fields']\
                               ['attrs']['GLIDEIN_Site']['value']
          except:
            jobsubSiteName = None

        if not jobsubSiteName:
          logLine('%s has no GLIDEIN_Site - ignoring' % entryName)
          continue

        # GLIDEIN_DUNESite = justIN siteName
        try:
          siteName = yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']\
                       [entryName]['attrs']['GLIDEIN_DUNESite']['value']
        except:
          try:
            siteName = yamlDict[osgSiteName]['common_entry_fields']\
                         ['attrs']['GLIDEIN_DUNESite']['value']
          except:
            siteName = None

        if not siteName:
          logLine('%s has no GLIDEIN_DUNESite - ignoring' % entryName)
          continue

        # GLIDEIN_ResourceName = justIN wlcgSiteName
        try:
          wlcgSiteName = yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']\
                          [entryName]['attrs']['GLIDEIN_ResourceName']['value']
        except:
          try:
            wlcgSiteName = yamlDict[osgSiteName]['common_entry_fields']\
                             ['attrs']['GLIDEIN_ResourceName']['value']
          except:
            wlcgSiteName = ''

        #Â GLIDEIN_CPUS = justIN processors
        try:
          processors = int(yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']\
                            [entryName]['attrs']['GLIDEIN_CPUS']['value'])
        except:
          try:
            processors = int(yamlDict[osgSiteName]['common_entry_fields']\
                               ['attrs']['GLIDEIN_CPUS']['value'])
          except:
            processors = 1

        # GLIDEIN_MaxMemMBs = justIN rssBytes        
        try:
          rssBytes = 1024 * 1024 * int(yamlDict[osgSiteName][osgGatekeeper]\
                ['BEST_FIT'][entryName]['attrs']['GLIDEIN_MaxMemMBs']['value'])
        except:
          try:
            rssBytes = 1024 * 1024 * int(yamlDict[osgSiteName]\
              ['common_entry_fields']['attrs']['GLIDEIN_MaxMemMBs']['value'])
          except:
            # default from OSG_autoconf/etc/default.yml
            rssBytes = 2500 * 1024 * 1024

        # GLIDEIN_Max_Walltime = justIN wallSeconds
        try:
          wallSeconds = int(yamlDict[osgSiteName][osgGatekeeper]['BEST_FIT']\
                [entryName]['attrs']['GLIDEIN_Max_Walltime']['value'])
        except:
          try:
            wallSeconds = int(yamlDict[osgSiteName]['common_entry_fields']\
                                 ['attrs']['GLIDEIN_Max_Walltime']['value'])
          except:
            wallSeconds = 86400

        # Add to sitesDict if not already there
        if siteName not in sitesDict:
          logLine("Create maxima for %s:%s to %d bytes, %d processors" %
                  (siteName, entryName, rssBytes, processors))

          sitesDict[siteName] = { 'jobsub_site_name'      : jobsubSiteName,
                                  'wlcg_site_name'        : wlcgSiteName,
                                  'largest_rss_bytes'     : rssBytes,
                                  'largest_processors'    : processors,
                                  'smallest_wall_seconds' : wallSeconds,
                                  'entries'               : []
                                }

        sitesDict[siteName]['entries'].append({ 'entry_name'  : entryName,
                                                'gatekeeper'  : osgGatekeeper,
                                                'max_rss_bytes'   : rssBytes,
                                                'max_wall_seconds': wallSeconds,
                                                'max_processors'  : processors
                                              })

        # Add as maximas for rss_bytes and processors
        if rssBytes > sitesDict[siteName]['largest_rss_bytes']:
          logLine("Update maxima for %s:%s to %d bytes, %d processors from %s"
                  % (siteName, entryName, rssBytes, processors, fileName))
          sitesDict[siteName]['largest_rss_bytes']    = rssBytes
          sitesDict[siteName]['largest_processors']   = processors
          
        # Add as miniumum wall seconds
        if wallSeconds < sitesDict[siteName]['smallest_wall_seconds']:
          sitesDict[siteName]['smallest_wall_seconds'] = wallSeconds

def buildSites(sitesDict):

  tmpDir = tempfile.TemporaryDirectory()
  os.system('git clone https://github.com/opensciencegrid/osg-gfactory.git '
             + tmpDir.name)

  for fileName in os.listdir(tmpDir.name):
    if fileName[-4:] == '.xml':
      logLine('Process XML file: %s' % fileName)
      processOneFileXML(sitesDict, tmpDir.name + '/' + fileName)

  for fileName in os.listdir(tmpDir.name + '/OSG_autoconf'):
    if fileName[-4:] == '.yml':
      logLine('Process YAML file: %s' % fileName)
      processOneFileYAML(sitesDict, tmpDir.name + '/OSG_autoconf/' + fileName)

def updateSites():
  # Get info about sites the pilot factories know about
  logLine('---- Start updateSites ----')

  sitesDict = {}
  buildSites(sitesDict)

  try:
    justinSiteRows = justin.select('SELECT site_name,sites.site_id,'
                                   'entry_name,entry_id FROM sites '
                                   'LEFT JOIN entries '
                                   'ON entries.site_id=sites.site_id '
                                   'ORDER BY site_name,entry_name')
  except Exception as e:
    logLine('Failed to get list of existing sites from justIN: ' + str(e))
    return

  justinSiteIDs  = {}
  justinEntryIDs = {}
  lastSiteName = ''
  for justinSiteRow in justinSiteRows:
    if justinSiteRow['site_name'] != lastSiteName:
      justinSiteIDs[justinSiteRow['site_name']] = justinSiteRow['site_id']
      lastSiteName = justinSiteRow['site_name']
    justinEntryIDs[justinSiteRow['entry_name']] = \
      justinSiteRow['entry_id']

  for siteName in sitesDict:
    maxProcessors  = sitesDict[siteName]['largest_processors']
    maxRssBytes    = sitesDict[siteName]['largest_rss_bytes']
    maxWallSeconds = int(sitesDict[siteName]['smallest_wall_seconds'] * 0.95)

    if siteName == 'CERN':
      country = 'CERN'
    else:
      country = siteName[:2]

    if country in justin.rseCountriesRegions:
      region = justin.rseCountriesRegions[country]
    else:
      region = ''

    # Ensure the site exists
    if siteName not in justinSiteIDs:
      query = ('INSERT INTO sites SET '
               'site_name="%s",'
               'jobsub_site_name="%s",'
               'wlcg_site_name="%s",'
               'max_processors=%d,'
               'max_rss_bytes=%d,'
               'max_wall_seconds=%d,'
               'country="%s",'
               'region="%s",'
               'last_seen_time=NOW() '
               % (siteName, 
                  sitesDict[siteName]['jobsub_site_name'], 
                  sitesDict[siteName]['wlcg_site_name'],
                  maxProcessors,
                  maxRssBytes,
                  maxWallSeconds,
                  country,
                  region)
              )

      try:
        newID = justin.insertUpdate(query)
      except Exception as e:
        logLine('Failed inserting %s: %s' % (siteName, str(e)))
        continue
      else:
        justinSiteIDs[siteName] = newID

    else:
      query = ('UPDATE sites SET '
               'jobsub_site_name="%s",'
               'wlcg_site_name="%s",'
               'max_processors=%d,'
               'max_rss_bytes=%d,'
               'max_wall_seconds=%d,'
               'country="%s",'
               'region="%s",'
               'last_seen_time=NOW() '
               'WHERE site_name="%s"'
               % (sitesDict[siteName]['jobsub_site_name'],
                  sitesDict[siteName]['wlcg_site_name'],
                  maxProcessors,
                  maxRssBytes,
                  maxWallSeconds,
                  country,
                  region,
                  siteName
                 )
              )
      try:
        justin.insertUpdate(query)
      except Exception as e:
        logLine('Failed updating %s: %s' % (siteName, str(e)))
        continue

    for entryDict in sitesDict[siteName]['entries']:
       if entryDict['entry_name'] not in justinEntryIDs:
          query = ('INSERT INTO entries SET '
                   'entry_name="%s",'
                   'gatekeeper="%s",'
                   'site_id=%d,'
                   'max_processors=%d,'
                   'max_rss_bytes=%d,'
                   'max_wall_seconds=%d,'
                   'last_seen_time=NOW() '
                   % (entryDict['entry_name'], 
                      entryDict['gatekeeper'],
                      justinSiteIDs[siteName],
                      maxProcessors,
                      maxRssBytes,
                      maxWallSeconds)
                  )
          try:
            newID = justin.insertUpdate(query)
          except Exception as e:
            logLine('Failed inserting %s: %s' 
                  % (entryDict['entry_name'], str(e)))
            continue
          else:
            justinEntryIDs[entryDict['entry_name']] = newID

       else:
          query = ('UPDATE entries SET '
                   'gatekeeper="%s",'
                   'site_id=%d,'
                   'max_processors=%d,'
                   'max_rss_bytes=%d,'
                   'max_wall_seconds=%d,'
                   'last_seen_time=NOW() '
                   'WHERE entry_name="%s"'
                   % (entryDict['gatekeeper'],
                      justinSiteIDs[siteName],
                      maxProcessors,
                      maxRssBytes,
                      maxWallSeconds,
                      entryDict['entry_name']
                     )
                  )
          try:
            justin.insertUpdate(query)
          except Exception as e:
            logLine('Failed inserting/updating %s: %s' 
                  % (entryDict['entry_name'], str(e)))
            continue

       logLine('Entry: %s, %d processors, %d bytes, %s seconds' %
            (entryDict['entry_name'], maxProcessors, maxRssBytes, 
             maxWallSeconds))

    logLine('Site: %s, %d processors, %d bytes, %s seconds' %
            (siteName, maxProcessors, maxRssBytes, maxWallSeconds))

  justin.conn.commit()

def updateSitesStorages(): 
  # Update the matrix of sites to storage mappings
  # Ensure there is an entry for each combination
  logLine('---- Start updateSitesStorages ----')

  justin.cur.execute('SELECT site_id,site_name,country,region FROM sites')
  siteRows = justin.cur.fetchall()
  
  justin.cur.execute('SELECT rse_id,rse_name,storages.country,'
                     'storages.region,site_name FROM storages '
                     'LEFT JOIN sites '
                     'ON sites.site_id=storages.site_id')
  storageRows = justin.cur.fetchall()
  
  for siteRow in siteRows:
    for storageRow in storageRows:

      sitePrefix = siteRow['site_name'].split('-')[0]
      if storageRow['site_name']:
        rseSitePrefix = storageRow['site_name'].split('-')[0]
      else:
        rseSitePrefix = ''
    
      if siteRow['site_name'] == storageRow['site_name']:
        #Â RSEs at sites have zero distance
        distance = 0
      elif siteRow['site_name'].startswith('US_FNAL') \
        and storageRow['site_name'] \
        and storageRow['site_name'].startswith('US_FNAL'):
        #Â Everything Fermilab at zero distance to get internal Rucio config
        distance = 0
      elif sitePrefix and rseSitePrefix \
           and sitePrefix == rseSitePrefix:
        # Same prefix on RSE and site name 
        distance = 10
      elif siteRow['country'] and \
           siteRow['country'] == storageRow['country']:
        # Same country as just 20
        distance = 20
      elif siteRow['region'] and \
           siteRow['region'] == storageRow['region']:
        # Same region, so distance 30
        distance = 30
      elif storageRow['site_name'] in ['CERN', 'US_FNAL-FermiGrid']:
        # Catchall if RSE at CERN/FNAL then 90
        distance = 90
      else:
        # Catchall if nothing chosen above.
        distance = 100

      justin.insertUpdate('REPLACE sites_storages SET '
               'distance=%d,site_id=%d,rse_id=%d'
               % (distance, siteRow['site_id'], storageRow['rse_id']))
              
  justin.conn.commit()

def updateStorages():
  # Get info about storages Rucio knows about
  logLine('---- Start updateStorages ----')
  
  #Â Ensure the dummy MONTECARLO RSE exists, with rse_id 1
  justin.cur.execute('INSERT IGNORE INTO storages SET rse_id=%d,'
    'rse_name="MONTECARLO",occupancy=1,rucio_write=FALSE,'
    'rucio_read=TRUE,justin_write=FALSE,justin_read=TRUE'
    % justin.MonteCarloRseID)

  justinStorageNames = []
  try:
    justinStorageRows = justin.select('SELECT rse_name FROM storages')
  except Exception as e:
    logLine('Failed to get names of existing justIN storages')
    return
    
  for justinStorageRow in justinStorageRows:
    justinStorageNames.append(justinStorageRow['rse_name'])

  try:
    rseClient = rucio.client.rseclient.RSEClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return
  
  try:
    accountClient = rucio.client.accountclient.AccountClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return
  
  try:
    rseList = rseClient.list_rses()  
  except Exception as e:
    logLine("Reading RSE list from Rucio fails with: " + str(e))
    return

  for rse in rseList:
  
    if not justin.stringIsSite(rse['rse']):
      logLine('Skip RSE with bad name %s' % rse['rse'])
      continue
  
    try:
      attributes = rseClient.list_rse_attributes(rse['rse'])
    except:
      logLine('Failed to get attributes for %s' % rse['rse'])
      continue

    logLine('Processing %s: %s' % (rse['rse'], rse))

    if (rse['rse_type'] != 'DISK' and rse['rse'] != 'FNAL_DCACHE') \
       or ('decommissioned' in attributes and 
           attributes['decommissioned'] == True):
      rseDecommissioned = True
    else:
      rseDecommissioned = False

    availabilityRead = rse['availability_read']

    if rse['deterministic']:
      availabilityWrite = rse['availability_write']
    else:
      #Â Force non-deterministic RSEs to read only
      availabilityWrite = False

    bestLanWriteScheme   = 'root'
    bestLanWritePriority = None

    bestWanWriteScheme   = 'root'
    bestWanWritePriority = None

    try:
      protocols = rseClient.get_protocols(rse['rse'])
    except Exception as e:
      logLine('Failed getting protocols for RSE %s: %s' 
              % (rse['rse'], str(e)))
      protocols = []

    for protocolDict in protocols:
      try:
        scheme = protocolDict['scheme']
      except:
        continue
      
      if scheme not in ['root', 'roots', 'https', 'davs']:
        continue
      
      try: 
        priority = protocolDict['domains']['lan']['write']
      except:
        pass
      else:
        if (priority > 0) and \
           (bestLanWritePriority is None or 
            priority < bestLanWritePriority or
            (priority == bestLanWritePriority and scheme < bestLanWriteScheme)):
          bestLanWriteScheme   = scheme
          bestLanWritePriority = priority
        
      try: 
        priority = protocolDict['domains']['wan']['write']
      except:
        pass
      else:
        if (priority > 0) and \
           (bestWanWritePriority is None or 
            priority < bestWanWritePriority or           
            (priority == bestWanWritePriority and scheme < bestWanWriteScheme)):
          bestWanWriteScheme   = scheme
          bestWanWritePriority = priority

    rseCountry = ''
    rseRegion  = ''
    if 'country' in attributes:
      rseCountry = attributes['country']
      if rseCountry in justin.rseCountriesRegions:
        rseRegion = justin.rseCountriesRegions[rseCountry]
  
    try:
      row = justin.select('SELECT site_id FROM sites WHERE site_name="%s"' 
                          % attributes['site'], justOne=True)
      rseSiteID = int(row['site_id'])
    except:
      rseSiteID = 0
      
    try:
      usageList = rseClient.get_rse_usage(rse['rse'],
                                          filters = {"source": "rucio"})
    except Exception as e:
      logLine("Reading %s usage fails with: %s" % 
              (rse['rse'], str(e)))
 
      occupancy = 0.0

    else:
      try:
        accLimits = accountClient.get_account_limits('dunepro', 
                                                     rse['rse'], 
                                                     'local')
      except Exception as e:
        logLine("Reading %s account limits fails with: %s" % 
                (rse['rse'], str(e)))
             
      try:
        usage     = next(usageList)        
        occupancy = float(usage['used']) / float(accLimits[rse['rse']])
      except:
        occupancy = 0.0

    try:
      if rse['rse'] not in justinStorageNames:
        query = ('INSERT INTO storages SET rse_name="%s",justin_write=FALSE'
                 % rse['rse']) 
        justin.select(query)

      query = ('UPDATE storages SET '
               'occupancy=%f,'
               'rucio_write=%s,rucio_read=%s,'
               'decommissioned=%s,'
               'region="%s",'
               'country="%s",'
               'site_id=%d,'
               'lan_write_scheme="%s",wan_write_scheme="%s",'
               'needs_pin=%s '
               'WHERE rse_name="%s"'
               % (occupancy,
                  availabilityWrite,
                  availabilityRead,
                  rseDecommissioned,
                  rseRegion,
                  rseCountry,
                  rseSiteID,
                  bestLanWriteScheme, bestWanWriteScheme,
                  'TRUE' if 'FNAL_DCACHE' in rse['rse'] else 'FALSE',
                  rse['rse']
                 )
              )

      justin.select(query)
    except Exception as e:
      # Log the error and hope it was transitory
      logLine('Failed inserting RSE %s into database: %s' % 
              (rse['rse'], str(e)))

  justin.conn.commit()

# Make sure HTCondor accounting groups are in database
def updateGroupsHTCondor():
  logLine('---- Start updateGroupsHTCondor ----')
  
  try: 
    outcome = subprocess.run(
               ['/usr/bin/condor_userprio',
                '-pool',
                'dunegpcoll01.fnal.gov',
                '-quotas',
                '-allusers'
               ],
               encoding = 'utf-8',
               stderr   = subprocess.STDOUT,
               stdout   = subprocess.PIPE,
               timeout  = 60
                            ) 

    lines = outcome.stdout.splitlines()
  except Exception as e:
    logLine("condor_userprio fails with error: " + str(e))
    return

  logLine('condor_userprio exit code: ' + str(outcome.returncode))

  for line in lines:
    try:
      (groupName, effQuota, confQuota, surplus, subtreeQuota, weighted) \
        = line.split()
# SHOULD RECORD confQuota IN JUSTINDB
    except:
      groupName = ''

    if groupName.startswith('group_dune') and justin.stringNoQuotes(groupName):
      logLine('Checking Condor Group %s is in database' % groupName)
      try:
        rows = justin.select('SELECT condor_group_id FROM condor_groups '
                             'WHERE condor_group_name="%s"' % groupName)
        if len(rows) == 0:
          # Not there yet, so add
          try:
            justin.insertUpdate('INSERT INTO condor_groups '
                                'SET condor_group_name="%s"' % groupName)
          except Exception as e:
            logLine('Failed inserting Condor Group %s : %s'
                  % (groupName, str(e)))

      except Exception as e:
        logLine('Failed finding Condor Group %s in database : %s'
                % (groupName, str(e)))

# Make sure WLCG groups in config are in database
def updateGroupsWLCG():
  logLine('---- Start updateGroupsWLCG ----')

  for groupName in justin.wlcgGroups:
    logLine('Checking WLCG Group %s is in database' % groupName)
    try:
      rows = justin.select('SELECT wlcg_group_id FROM wlcg_groups '
                          'WHERE wlcg_group_name="%s"' % groupName)
      if len(rows) == 0:
        # Not there yet, so add
        try:
          justin.insertUpdate('INSERT INTO wlcg_groups '
                              'SET wlcg_group_name="%s"' % groupName)
        except Exception as e:
          logLine('Failed inserting WLCG Group %s : %s'
                  % (groupName, str(e)))

    except Exception as e:
      logLine('Failed finding WLCG Group %s in database : %s'
              % (groupName, str(e)))

def updateScopes():
  # Get info about scopes Rucio knows about
  logLine('---- Start updateScopes ----')

  try:
    row = justin.select('SELECT wlcg_group_id FROM wlcg_groups '
                        'WHERE wlcg_group_name="/dune"', justOne = True)
    duneWLCGGroupID = int(row['wlcg_group_id'])

    row = justin.select('SELECT wlcg_group_id FROM wlcg_groups '
                        'WHERE wlcg_group_name="/dune/production"', 
                        justOne = True)
    productionWLCGGroupID = int(row['wlcg_group_id'])
  except Exception as e:
    logLine('Failed getting /dune and /dune/production group IDs: ' + str(e))
    return

  try:
    row = justin.select('SELECT condor_group_id FROM condor_groups '
                        'WHERE condor_group_name="group_dune"', justOne = True)
    duneCondorGroupID = int(row['condor_group_id'])

    row = justin.select('SELECT condor_group_id FROM condor_groups '
                        'WHERE condor_group_name="group_dune.prod_mcsim"', 
                        justOne = True)
    productionCondorGroupID = int(row['condor_group_id'])
  except Exception as e:
    logLine('Failed getting Condor group IDs: ' + str(e))
    return
    
  justinScopeNames = []
  try:
    justinScopeRows = justin.select('SELECT scope_name FROM scopes')
  except Exception as e:
    logLine('Failed to get names of existing justIN scopes')
    return
    
  for justinScopeRow in justinScopeRows:
    justinScopeNames.append(justinScopeRow['scope_name'])

  try:
    scopeClient = rucio.client.scopeclient.ScopeClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return
    
  try:
    rucioScopeNames = scopeClient.list_scopes()
  except Exception as e:
    logLine("Reading scope list from Rucio fails with: " + str(e))
    return

  try:
    productionScopeNames = scopeClient.list_scopes_for_account(
                                                  justin.rucioProductionUser)
  except Exception as e:
    logLine("Reading production scopes list from Rucio fails with: " + str(e))
    return

  for rucioScopeName in rucioScopeNames:
    if rucioScopeName not in justinScopeNames:
      # A new scope we need to add
      logLine('Adding new scope %s from Rucio' % rucioScopeName)

      try:
        justin.insertUpdate('INSERT INTO scopes SET scope_name="%s"'
                            % rucioScopeName)
      except Exception as e:
        logLine('Failed to insert new scope %s into justIN database: %s'
                % (rucioScopeName, str(e)))
        continue
        
    if rucioScopeName in productionScopeNames:
      # A production scope, that wrapper jobs can write to
      if rucioScopeName == 'usertests':
        # Any /dune member can write to usertests via justIN
        wlcgGroupID   = duneWLCGGroupID
        condorGroupID = duneCondorGroupID
      else:
        # Everything else requires /dune/production group membership
        wlcgGroupID   = productionWLCGGroupID
        condorGroupID = productionCondorGroupID
    else:
      # If not writeable via wrapper jobs as production user, then no groups
      wlcgGroupID   = 0
      condorGroupID = 0

    logLine('Update scope %s with wlcg_group_id=%d' 
            % (rucioScopeName, wlcgGroupID))
    try:
      justin.insertUpdate('UPDATE scopes SET wlcg_group_id=%d,'
                          'condor_group_id=%d '
                          'WHERE scope_name="%s"' 
                          % (wlcgGroupID, 
                             condorGroupID,
                             rucioScopeName))
    except Exception as e:
      logLine('Failed updating wlcg_group_id=%d condor_group_id=%d for %s: %s'
              % (wlcgGroupID, condorGroupID, rucioScopeName, str(e)))
      continue

  justin.conn.commit()

def oneCycle():

  # Is it time to update storages from Rucio?
  try:
    lastUpdateJwks = os.stat('/var/run/justin/last-updates/jwks').st_mtime
  except:
    lastUpdateJwks = 0

  if lastUpdateJwks + updateJwksInterval < time.time():
    pathlib.Path('/var/run/justin/last-updates/jwks').touch(exist_ok=True)
    updateJwks()

  # Is it time to update storages from Rucio?
  try:
    lastUpdateStorages = os.stat('/var/run/justin/last-updates/storages').st_mtime
  except:
    lastUpdateStorages = 0

  if lastUpdateStorages + updateStoragesInterval < time.time():
    pathlib.Path('/var/run/justin/last-updates/storages').touch(exist_ok=True)
    updateStorages()
    updateGroupsHTCondor()
    updateGroupsWLCG()
    updateScopes()

  # It is time to update sites from the OSG pilot factory config?
  try:
    lastUpdateSites = os.stat('/var/run/justin/last-updates/sites').st_mtime
  except:
    lastUpdateSites = 0

  if lastUpdateSites + updateSitesInterval < time.time():
    pathlib.Path('/var/run/justin/last-updates/sites').touch(exist_ok=True)
    updateSites()
    updateSitesStorages()

  justin.conn.commit()

#
# PROGRAM MAIN
#

if __name__ == '__main__':

  if (os.fork() != 0):
    sys.exit() # first parent

  else:
    os.chdir("/")
    os.setsid()
    os.umask(0)

    if os.fork() != 0:
      sys.exit() # second parent

    else:

      try:
        os.makedirs('/var/run/justin',         
                    stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | 
                    stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
      except:
        pass
        
      try:
        f = open('/var/run/justin/info-collector.pid', 'w')
        f.write(str(os.getpid()) + '\n')
        f.close()
      except:
        print('Failed to create /var/run/justin/info-collector.pid - exiting')
        sys.exit(1)

      # Close stdin now
      si = open('/dev/null', 'r')
      os.dup2(si.fileno(), sys.stdin.fileno())

      while True:

        # Ensure /var/log/justin directory exists
        try:
          os.makedirs('/var/log/justin', 
                      stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR|stat.S_IRGRP|stat.S_IXGRP|stat.S_IROTH|stat.S_IXOTH)
        except:
          pass

        # Close and reopen stdout->log file, in case of logrotate
        try:
          close(so)
        except:
          pass

        so = open('/var/log/justin/info-collector', 'a+')
        os.dup2(so.fileno(), sys.stdout.fileno())

        # Close and reopen stderr->log file, in case of logrotate
        try:
          close(se)
        except:
          pass

        se = open('/var/log/justin/info-collector', 'a+')
        os.dup2(se.fileno(), sys.stderr.fileno())

        try:
          pf = open('/var/run/justin/info-collector.pid', 'r')
          pid = int(pf.read().strip())
          pf.close()

          if pid != os.getpid():
            print('new /var/run/justin/info-collector.pid - exiting')
            break

        except:
          print('no /var/run/justin/info-collector.pid - exiting')
          break

        # Fork a subprocess to run each cycle
        cyclePid = os.fork()

        if cyclePid == 0:
          logLine('=============== Start cycle ===============')
          
          justin.readConf()
          
          try:
            justin.conn = MySQLdb.connect(host=justin.mysqlHostname, 
                                  user=justin.mysqlUsername,
                                  passwd=justin.mysqlPassword, 
                                  db=justin.mysqlDbName)
            justin.conn.autocommit(False)
            justin.cur = justin.conn.cursor(MySQLdb.cursors.DictCursor)
            
            # Do not bother us with such trifles!
            warnings.filterwarnings('ignore', category=MySQLdb.Warning)
          except Exception as e:
            logLine('Failed to create database connection (' + str(e) + ') - skipping cycle')
          else:
            try:
              p = pwd.getpwnam(justin.agentUsername)
              os.setgid(p[3])
              os.setuid(p[2])              
              oneCycle()
            except Exception as e:
              print('Cycle fails with exception ' + str(e))

          logLine('================ End cycle ================')
          sys.exit(0)

        # wait for cyclePid subprocess to finish
        os.waitpid(cyclePid, 0)

        # wait the allotted time between cycles
        time.sleep(sleepSeconds)

      sys.exit(0) # if we break out of the while loop then we exit

