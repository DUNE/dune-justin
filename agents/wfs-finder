#!/usr/bin/env python3
#
#  wfs-finder - WFS Finder agent
# 
#  Andrew McNab, University of Manchester.
#  Copyright (c) 2013-22. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or
#  without modification, are permitted provided that the following
#  conditions are met:
#
#    o Redistributions of source code must retain the above
#      copyright notice, this list of conditions and the following
#      disclaimer.
#    o Redistributions in binary form must reproduce the above
#      copyright notice, this list of conditions and the following
#      disclaimer in the documentation and/or other materials
#      provided with the distribution.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
#  CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
#  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
#  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
#  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
#  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
#  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#

import os
import sys
import ssl
import stat
import json
import time
import urllib.request
import pathlib
import tempfile
import xml.dom.minidom

# Needs MySQL-python RPM
import MySQLdb

# Installed by pip3 install of Rucio
import rucio.client

# wfs/conf.py must define these variables in a way that is both
# valid Python and valid Bash!
#
# mysqlUser='username'
# mysqlPassword='PAsSWoRd'
#
import wfs

maxFileFindsPerCycle = 500
sleepSeconds         = 60

class wfsError(Exception):
  pass

def logLine(text):
  sys.stdout.write(time.strftime('%b %d %H:%M:%S [') + str(os.getpid()) + ']: ' + text + '\n')
  sys.stdout.flush()

def addFilesMonteCarlo(requestID, count):
  # Add dummy files to keep track of Monte Carlo processing
  
  for i in range(1, count + 1):
    try:
      query = ('INSERT INTO files SET state="unallocated",'
               'request_id=%d,file_did="monte-carlo-%06d-%06d"' 
               % (requestID, requestID, i)
              )

      wfs.db.cur.execute(query)
    except Exception as e:
      logLine('Failed inserting dummy Monte Carlo file for request %d: %s' 
              % (requestID, str(e)))
      return

    try:
      query = ('INSERT INTO replicas SET rse_id=%d,file_id=%d,'
               'wan_pfn="%06d",lan_pfn=""'
               % (wfs.conf.MonteCarloRseID, 
                  wfs.db.cur.lastrowid,
                  i))

      wfs.db.cur.execute(query)
    except Exception as e:
      logLine('Failed inserting dummy Monte Carlo replica for request %d: %s' 
               % (requestID, str(e)))
      return

    wfs.db.logEvent(eventTypeID = wfs.db.event_FILE_ADDED,
                    requestID = requestID,
                    stageID = 1,
                    fileID = wfs.db.cur.lastrowid)


  try:
    query = ('UPDATE requests SET refind_last_time=NOW() WHERE request_id=' +
             str(requestID))

    wfs.db.cur.execute(query)
  except Exception as e:
    logLine('Failed updating request ' + str(requestID))

  # All ok, so commit it all to the DB
  wfs.db.conn.commit()

def findFilesRucio(didClient, requestID, scope, name):
  # Find files to be processed for each request in the finding state

  try:
    didsList = didClient.list_files(scope, name)
  except Exception as e:
    logLine("Reading file list from Rucio fails with: " + str(e))
    return

  for did in didsList:  
    try:
      query = ('INSERT INTO files SET '
               'request_id=' + str(requestID) + ',' +
               'file_did="' + did['scope'] + ':' + did['name'] + '" '
               'ON DUPLICATE KEY UPDATE request_id=request_id'
              )

      wfs.db.cur.execute(query)
    except Exception as e:
      logLine('Failed inserting DID %:%s' % (did['scope'], did['name']))
      return

    wfs.db.logEvent(eventTypeID = wfs.db.event_FILE_ADDED,
                    requestID = requestID,
                    stageID = 1,
                    fileID = wfs.db.cur.lastrowid)

  # All files found for this request so update its state
  try:
    query = ('UPDATE requests SET refind_last_time=NOW() WHERE request_id=' +
             str(requestID))

    wfs.db.cur.execute(query)
  except Exception as e:
    logLine('Failed updating request ' + str(requestID))

  # All ok, so commit it all to the DB
  wfs.db.conn.commit()

def findFilesMetaCat(requestID, mql):
  # Find files matching the mql query from MetaCat

  for i in range(3,0,-1):
    try:
      response = urllib.request.urlopen(
       "https://metacat.fnal.gov:9443/dune_meta_demo/app/data/query?"
       "with_meta=no&with_provenance=no",
       data = mql.encode()           )

      if response.status != 200:
        logLine("Reading files list from MetaCat fails with HTTP code "
                + str(response.status))
        return

      fileLines = response.readlines()
    except Exception as e:    
      logLine("Reading files list from MetaCat fails with: " + str(e))
      
      if i > 1:
        # Try again as Metacat has transitory errors on large queries
        # which seem to go away when repeated
        time.sleep(1)        
        continue
      else:
        # Give up
        return

  for fileLine in fileLines:
    # Remove any weirdness
    if fileLine[0] < 32:
      fileLine = fileLine[1:]

    try:
      fileDict = json.loads(fileLine)
    except:
      logLine("Parsing line from MetaCat fails with: " + str(e))
      return
        
    if 'namespace' not in fileDict or not fileDict['namespace'] \
       or 'name' not in fileDict or not fileDict['name']:
      logLine('Ignore file with invalid SCOPE:NAME from MetaCat: '
              + str(fileDict))
      continue

    try:
      query = ('INSERT INTO files SET '
               'request_id=' + str(requestID) + ',' +
               'file_did="' + fileDict['namespace'] + ':' 
                + fileDict['name'] + '" '
               'ON DUPLICATE KEY UPDATE request_id=request_id'
              )

      wfs.db.cur.execute(query)
      
    except Exception as e:
      logLine('Failed inserting DID %:%s' % 
              ( fileDict['namespace'], fileDict['name'] ))
      return

    wfs.db.logEvent(eventTypeID = wfs.db.event_FILE_ADDED,
                    requestID = requestID,
                    stageID = 1,
                    fileID = wfs.db.cur.lastrowid)

  # All files found for this request so update its state
  try:
    query = ('UPDATE requests SET refind_last_time=NOW() WHERE request_id=' +
             str(requestID))

    wfs.db.cur.execute(query)
  except Exception as e:
    logLine('Failed updating request ' + str(requestID))

  # All ok, so commit it all to the DB
  wfs.db.conn.commit()

def findFiles():
  # Find files to be processed for each request in the finding state
  # By default we use MetaCat, but MQLs starting rucio-dataset or monte-carlo 
  # are handled directly.

  query = ('SELECT request_id,mql FROM requests '
           'WHERE state="running" AND '
           '((refind_seconds=0 AND refind_last_time="%s")'
           ' OR '
           ' (refind_seconds > 0 AND '
           ' DATE_ADD(refind_last_time, INTERVAL refind_seconds SECOND) '
           ' < NOW() AND refind_start_time < NOW() AND '
           'refind_end_time >= NOW())) '
           'ORDER BY request_id' % wfs.db.unixEpoch)

  wfs.db.cur.execute(query)

  findingRequests = wfs.db.cur.fetchall()
  if not findingRequests:  
    # Nothing to do
    return

  didClient = None

  for request in findingRequests:
  
    logLine('Finding files for Request %d with MQL %s' %
            (request['request_id'], request['mql']))
  
    mqlSplit = request['mql'].split()

    # Request for a Rucio dataset: "rucio-dataset SCOPE:NAME"
    if len(mqlSplit) == 2 and mqlSplit[0] == 'rucio-dataset':

      if not didClient:      
       # Only set up Rucio if we see a rucio-dataset
       try:
         didClient = rucio.client.didclient.DIDClient()
       except Exception as e:
         logLine("Connect to Rucio fails with: " + str(e))
         continue

      datasetSplit = mqlSplit[1].split(':')
      if len(datasetSplit) == 2:
        findFilesRucio(didClient,
                       request['request_id'], 
                       datasetSplit[0], 
                       datasetSplit[1])
        
    # Monte Carlo request with a count
    elif len(mqlSplit) == 2 and mqlSplit[0] == 'monte-carlo':
      
      try:
        count = int(mqlSplit[1])
      except:
        continue
      
      addFilesMonteCarlo(request['request_id'], count)

    else:
    
      findFilesMetaCat(request['request_id'], request['mql'])

#    # Update the stats for the first stage
#    wfs.allocator.updateStageCounts(request['request_id'], 1)
    wfs.db.conn.commit()

def findReplicas():
  # Find replicas of files in the finding state

  query = (
    'SELECT requests.request_id,stages.stage_id '
    'FROM requests '
    'LEFT JOIN stages ON requests.request_id=stages.request_id '
    'LEFT JOIN files ON requests.request_id=files.request_id AND '
    'stages.stage_id=files.stage_id '
    'WHERE requests.state="running" AND files.state="finding" '
    'GROUP BY requests.request_id,stages.stage_id '
    'ORDER BY stage_rank DESC,RAND() LIMIT 1')

  try:
    stageRow = wfs.db.select(query, justOne = True)
    requestID = stageRow['request_id']
    stageID   = stageRow['stage_id']

  except Exception as e:
    logLine('Finding request/stage to find replicas for fails: %s' % str(e))
    return

  logLine('Looking for replicas in finding state for request=%d stage=%d'
          % (requestID, stageID))

  # Make a list of up to maxFileFindsPerCycle files to work on 
  # but only for Rucio DIDs in scope:name format
  didsList = []

  try:
    fileRows = wfs.db.select(
           'SELECT files.request_id,files.stage_id,file_id,file_did '
           'FROM files '
           'LEFT JOIN requests ON requests.request_id=files.request_id '
           'WHERE files.request_id=%d '
           'AND files.stage_id=%d '
           'AND files.state="finding" '
           'AND requests.state="running" '
           'AND file_did LIKE "%%:%%" '
           'ORDER BY file_id LIMIT %d'
           % (requestID, stageID, maxFileFindsPerCycle))

  except Exception as e:
    logLine('Finding list of files to find fails: ' + str(e))
    return
  
  # Nothing to do
  if not fileRows:
    logLine('No files found in finding state')
    return

  # Check we can talk to Rucio
  try:
    repClient = rucio.client.replicaclient.ReplicaClient()
  except Exception as e:
    logLine("Connect to Rucio fails with: " + str(e))
    return

  # Cache rse_id of every known RSE into a local dictionary
  storagesDict = {}
  wfs.db.cur.execute('SELECT rse_name,rse_id,needs_pin FROM storages')
  allStorages = wfs.db.cur.fetchall()
  
  for storageRow in allStorages:
    storagesDict[storageRow['rse_name']] = { 
                     'rse_id'    : storageRow['rse_id'],
                     'needs_pin' : bool(storageRow['needs_pin']) }

  # Receives a list of unique (requestID,stageID) combinations
  requestsStages = set()
  filesList = []

  # Make a list of files we want replicas for, in the Rucio API's format
  for fileRow in fileRows:
    (didScope, didName) = fileRow['file_did'].split(':')
    filesList.append({'scope' : didScope, 'name'  : didName })

  # Use the Rucio API to get big lists of replicas for the files
  try:
    # WE FORCE THE RETURNED SCHEME TO BE root FOR NOW
    # domain='all' does not seem to work for now
    wanRepsList = repClient.list_replicas(filesList,
                                          schemes=['root'], 
                                          domain='wan')

    lanRepsList = repClient.list_replicas(filesList,
                                          schemes=['root'], 
                                          domain='lan')

  except Exception as e:
    logLine("Reading RSE replicas info from Rucio fails with: " + str(e))
    return

  # Make a dictionary with DIDs as keys and lists of replicas from Rucio
  # as the values
  repsDict = {}
  for rep in list(wanRepsList) + list(lanRepsList):
    if rep['scope']+':'+rep['name'] not in repsDict:
      repsDict[rep['scope']+':'+rep['name']] = []
      
    for pfn in rep['pfns']:
      pfnDict = rep['pfns'][pfn]
      pfnDict['pfn'] = pfn
      repsDict[rep['scope']+':'+rep['name']].append(pfnDict)
                      
  # Go through the files again, pulling out the replica info obtained 
  # for the file's DID
  for fileRow in fileRows:
    try:
      pfnsList = repsDict[fileRow['file_did']]
    except:
      continue
    
    rses = {}

    # Save the wan and lan PFNs returned for each RSE with a replica
    # These go into the SAME rses dictionary so separate LAN and WAN
    # replica information is merged into one data dictionary
    for pfnDict in pfnsList:
        if pfnDict['type'] != 'DISK':
          continue

        if pfnDict['rse'] not in rses:
            rses[pfnDict['rse']] = {}
      
        if pfnDict['domain'] == 'lan':
            rses[pfnDict['rse']]['lan_pfn'] = wfs.db.fixPfn(pfnDict['pfn'])
        else:
            rses[pfnDict['rse']]['wan_pfn'] = wfs.db.fixPfn(pfnDict['pfn'])

    # Now go through the replicas for this file, RSE by RSE
    for rse in rses:
        try:
          lanPFN = rses[rse]['lan_pfn'] 
        except:
          lanPFN = ''

        try:
          wanPFN = rses[rse]['wan_pfn'] 
        except:
          wanPFN = ''
          
        # If PFN wan=lan then set lan PFN to ''        
        if wanPFN == lanPFN:
          lanPFN = ''       
  
        if storagesDict[rse]['needs_pin']:
          accessibleUntil = ',accessible_until="%s" ' % wfs.db.unixEpoch
        else:
          accessibleUntil = ''
        
        try:
          query = ('INSERT INTO replicas SET '
                   'rse_id=%d,file_id=%d,'
                   'wan_pfn="%s",lan_pfn="%s"%s' %
                   (storagesDict[rse]['rse_id'],
                    fileRow['file_id'],
                    wanPFN,
                    lanPFN,
                    accessibleUntil))

          wfs.db.cur.execute(query)
        except Exception as e:
          logLine('Failed inserting replica: ' + str(e))
          # We give up if this happens, without the commit
          return
           
        # Add request/stage to the list to have updated stats at the end
        requestsStages.add((fileRow['request_id'], fileRow['stage_id']))

    if rses:
      # If we got this far, then we found all the replicas for this 
      # file so we update its state to unallocated (not finding any more)
      try:
        query = ('UPDATE files SET state="unallocated" WHERE file_id=%d' %
                 fileRow['file_id'])

        wfs.db.cur.execute(query)
      except Exception as e:
        logLine('Failed updating file (%d,%d,%s): %s' %
                (fileRow['request_id'],
                 fileRow['stage_id'],
                 fileRow['file_did'],
                 str(e)))
        # We give up if this happens, without the commit
        return
    else:
      try:
        query = ('UPDATE files SET state="notfound" WHERE file_id=%d' %
                 fileRow['file_id'])

        wfs.db.cur.execute(query)
      except Exception as e:
        logLine('Failed updating file (%d,%d,%s): %s' %
                (fileRow['request_id'], 
                 fileRow['stage_id'],
                 fileRow['file_did'],
                 str(e)))
        # We give up if this happens, without the commit
        return

#  # Update all the stages for which we've updated a file
#  for (requestID, stageID) in requestsStages:
#    wfs.allocator.updateStageCounts(requestID, stageID)
    
  # All ok, so commit it all to the DB
  wfs.db.conn.commit()

def findFinishedRequests():
  # Find requests with all files in terminal states and set to finished

  try:
    query = ('SELECT request_id FROM requests '
             'WHERE state="running" AND '
             '((refind_seconds = 0) OR (refind_end_time < NOW())) '
             'ORDER BY request_id')

    wfs.db.cur.execute(query)

    findingRequests = wfs.db.cur.fetchall()
  except:
    logLine('Failed to get list of running requests')
    return
    
  if not findingRequests:
    logLine('No running requests to check')
    return

  for request in findingRequests:

    try:
      query = ('SELECT COUNT(*) AS count FROM files '
               'WHERE request_id=%d AND '
               'state <> "processed" AND '
               'state <> "notfound" AND '
               'state <> "failed" AND ' 
               'state <> "recorded" AND '
               'state <> "output"' %
               int(request['request_id']))
             
      wfs.db.cur.execute(query)
      count = int(wfs.db.cur.fetchone()['count'])
    except Exception as e:
      logLine('Failed to count non-terminal files for Request ID %d: %s' % 
              (request['request_id'], str(e)))
      continue

    if count > 0:
      # Some files have not reached terminal states
      logLine('Still non-terminal files for Request ID %d (%d)' % 
              (request['request_id'], count))
      continue
    
    try:
      query = ('UPDATE requests SET state="finished",finished=NOW() '
               'WHERE request_id=%d' % int(request['request_id']))
    
      wfs.db.cur.execute(query)
    except:
      logLine('Failed to update state to finished for Request ID %d' % 
              request['request_id'])
      continue

    logLine('Request ID %d set to finished' % request['request_id'])
    
  wfs.db.conn.commit()

def findStalledAbortedJobs():
  # Find jobs which have not sent a heartbeat in jobStalledSeconds
  # or which have reported they have aborted

  try:
    query = ('SELECT request_id,stage_id,wfs_job_id,jobsub_id,site_id,'
             'allocation_state '
             'FROM jobs '
             'WHERE ((allocation_state="started" OR '
             'allocation_state="processing" OR '
             'allocation_state="outputting") AND '
             '(heartbeat_time < DATE_SUB(NOW(),INTERVAL %d SECOND))) '
             'OR allocation_state="aborted" '
             'ORDER BY wfs_job_id' % wfs.db.jobStallSeconds)

    wfs.db.cur.execute(query)

    jobRows = wfs.db.cur.fetchall()
  except Exception as e:
    logLine('Failed to get list of stalled or aborted jobs: ' + str(e))
    return
    
  if not jobRows:
    logLine('No stalled or aborted jobs to process')
    return

  for jobRow in jobRows:

    if jobRow['allocation_state'] != 'aborted':
      # If not here due to 'aborted', we mark the job as stalled
      try:
        query = ('UPDATE jobs SET allocation_state="stalled",finished_time=NOW() '
                 'WHERE wfs_job_id=%d' % jobRow['wfs_job_id'])
    
        wfs.db.cur.execute(query)
      except Exception as e: 
        logLine('Failed to set job %s to stalled: %s' 
              % (jobRow['jobsub_id'], str(e)))
        continue

      logLine('Job %s set to stalled from %s' % (jobRow['jobsub_id'], 
                                                 jobRow['allocation_state']))
    
      wfs.db.logEvent(eventTypeID = wfs.db.event_JOB_STALLED,
                      requestID = jobRow['request_id'],
                      stageID = jobRow['stage_id'],
                      wfsJobID = jobRow['wfs_job_id'],
                      siteID = jobRow['site_id'])

    # Then find the file(s) allocated to this stalled or aborted job 
    # (IN THE FUTURE WE SHOULD DO SOMETHING CLEVER WITH Rucio/MetaCat 
    #  CHECKS FOR FILE IN THE outputting STATE)
    try:
      query = ('SELECT file_id,allocations,file_did,state '
               'FROM files '
               'WHERE (state="allocated" OR state="outputting") '
               'AND wfs_job_id=%d '
               'ORDER BY file_id' % jobRow['wfs_job_id'])

      wfs.db.cur.execute(query)

      fileRows = wfs.db.cur.fetchall()
    except:
      logLine('Failed to get list of files of the stalled or aborted job')
      # We should give up at this point rather than commit a mess?
      sys.exit(0)
    
    for fileRow in fileRows: 
    
      if fileRow['allocations'] >= wfs.db.maxAllocations:
        # Reached max allocations allowed per file
        # Mark file as failed in case it is the file causing the problem
        # (eg pathological file causes memory to balloon leading to the site
        # killing the job, and to us the job just appears stalled.)

        try:
          query = ('UPDATE files SET state="failed" '
                   'WHERE file_id=%d' % fileRow['file_id'])

          wfs.db.cur.execute(query)
        except:
          logLine('Failed to set file %s to failed in '
                  'request %d, stage %d after job %s' 
                  % (fileRow['file_did'], jobRow['request_id'], 
                     jobRow['stage_id'], jobRow['jobsub_id']))
          # Again, just stop for now on errors
          sys.exit(0)
            
        wfs.db.logEvent(eventTypeID = wfs.db.event_FILE_SET_TO_FAILED,
                        requestID = jobRow['request_id'],
                        stageID = jobRow['stage_id'],
                        fileID = fileRow['file_id'],
                        wfsJobID = jobRow['wfs_job_id'],
                        siteID = jobRow['site_id'])
      else:
      
        try:
          query = ('UPDATE files SET state="unallocated" '
                   'WHERE file_id=%d' % fileRow['file_id'])

          wfs.db.cur.execute(query)
        except:
          logLine('Failed to set file %s to unallocated in '
                  'request %d, stage %d after job %s' 
                  % (fileRow['file_did'], jobRow['request_id'], 
                     jobRow['stage_id'], jobRow['jobsub_id']))
          # Again, just stop for now on errors
          sys.exit(0)

        wfs.db.logEvent(eventTypeID = 
                        wfs.db.event_FILE_OUTPUTTING_RESET 
                         if fileRow['state'] == 'outputting'
                         else wfs.db.event_FILE_ALLOCATED_RESET,
                        requestID = jobRow['request_id'],
                        stageID = jobRow['stage_id'],
                        fileID = fileRow['file_id'],
                        wfsJobID = jobRow['wfs_job_id'],
                        siteID = jobRow['site_id'])

        logLine('Reset file %s in %d,%d to unallocated for job %s' % 
                (fileRow['file_did'], jobRow['request_id'],
                 jobRow['stage_id'], jobRow['jobsub_id']))

  # Everything went ok so commit
  wfs.db.conn.commit()

def oneCycle():

  findFiles()
  findReplicas()
  findFinishedRequests()
  findStalledAbortedJobs()

#
# PROGRAM MAIN
#

if __name__ == '__main__':

  if (os.fork() != 0):
    sys.exit() # first parent

  else:
    os.chdir("/")
    os.setsid()
    os.umask(0)

    if os.fork() != 0:
      sys.exit() # second parent

    else:

      try:
        os.makedirs(wfs.conf.wfsRunDir,         
                    stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | 
                    stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
      except:
        pass
        
      try:
        f = open(wfs.conf.wfsRunDir + '/finder.pid', 'w')
        f.write(str(os.getpid()) + '\n')
        f.close()
      except:
        print('Failed to create '+wfs.conf.wfsRunDir+'/finder.pid - exiting')
        sys.exit(1)

      # Close stdin now
      si = open('/dev/null', 'r')
      os.dup2(si.fileno(), sys.stdin.fileno())

      while True:

        # Ensure /var/log/wfs directory exists
        try:
          os.makedirs('/var/log/wfs', 
                      stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR|stat.S_IRGRP|stat.S_IXGRP|stat.S_IROTH|stat.S_IXOTH)
        except:
          pass

        # Close and reopen stdout->log file, in case of logrotate
        try:
          close(so)
        except:
          pass

        so = open('/var/log/wfs/finder', 'a+')
        os.dup2(so.fileno(), sys.stdout.fileno())

        # Close and reopen stderr->log file, in case of logrotate
        try:
          close(se)
        except:
          pass
          
        se = open('/var/log/wfs/finder', 'a+')
        os.dup2(se.fileno(), sys.stderr.fileno())

        try:
          pf = open(wfs.conf.wfsRunDir + '/finder.pid', 'r')
          pid = int(pf.read().strip())
          pf.close()

          if pid != os.getpid():
            print('new ' + wfs.conf.wfsRunDir + '/finder.pid - exiting')
            break

        except:
          print('no ' + wfs.conf.wfsRunDir + '/finder.pid - exiting')
          break

        # Fork a subprocess to run each cycle
        cyclePid = os.fork()

        if cyclePid == 0:
          logLine('=============== Start cycle ===============')
          
          wfs.conf.readConf()
          
          try:
            wfs.db.conn = MySQLdb.connect(host=wfs.conf.mysqlHostname, 
                                  user=wfs.conf.mysqlUsername,
                                  passwd=wfs.conf.mysqlPassword, 
                                  db=wfs.conf.mysqlDbName)
            wfs.db.conn.autocommit(False)
            wfs.db.cur = wfs.db.conn.cursor(MySQLdb.cursors.DictCursor)
          except Exception as e:
            logLine('Failed to create database connection (' + str(e) + ') - skipping cycle')
          else:
            try:
              oneCycle()
            except Exception as e:
              print('Cycle fails with exception ' + str(e))

          logLine('================ End cycle ================')
          sys.exit(0)

        # wait for cyclePid subprocess to finish
        os.waitpid(cyclePid, 0)

        # wait the allotted time between cycles
        time.sleep(sleepSeconds)

      sys.exit(0) # if we break out of the while loop then we exit

