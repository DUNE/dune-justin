#!/usr/bin/env python3
#
#  wfs-job-factory - WFS Job Factory
# 
#  Andrew McNab, University of Manchester.
#  Copyright (c) 2013-22. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or
#  without modification, are permitted provided that the following
#  conditions are met:
#
#    o Redistributions of source code must retain the above
#      copyright notice, this list of conditions and the following
#      disclaimer.
#    o Redistributions in binary form must reproduce the above
#      copyright notice, this list of conditions and the following
#      disclaimer in the documentation and/or other materials
#      provided with the distribution.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
#  CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
#  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
#  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
#  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
#  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
#  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#

import os
import sys
import stat
import time
import tempfile
import subprocess

# Needs MySQL-python RPM
import MySQLdb

# wfs/conf.py must define these variables in a way that is both
# valid Python and valid Bash!
#
# mysqlUser='username'
# mysqlPassword='PAsSWoRd'
#
import wfs

sleepSeconds      = 60
jobsPerCluster    = 128
maxSubmittedRatio = 2

class wfsError(Exception):
  pass

def logLine(text):
  sys.stdout.write(time.strftime('%b %d %H:%M:%S [') + str(os.getpid()) + ']: ' + text + '\n')
  sys.stdout.flush()

def parseJobsubQ():

  try: 
    outcome = subprocess.run(['/var/lib/wfs/run-jobsub-q'],
                             stdin   = subprocess.DEVNULL,
                             stderr  = subprocess.STDOUT,
                             stdout  = subprocess.PIPE,
                             timeout = 60
                            ) 
  except Exception as e:
    logLine("run-jobsub-q fails with error: " + str(e))
    return

  logLine(outcome.stdout.decode())
  
  for line in outcome.stdout.decode().splitlines():
    if '@jobsub' in line and 'wfs-generic-job' in line:
      jobsubID = line.split()[0]
      state    = line.split()[5]

      try:
        wfs.db.cur.execute('UPDATE jobs '
                    'SET jobsub_state="%s" '
                    'WHERE jobsub_id="%s"'
                    % (state, jobsubID)
                   )

      except Exception as e:
        # But try to keep going
        logLine('Update jobsub job ' + jobsubID + ' fails with: ' + str(e))

  # Commit whatever we found - no rush
  wfs.db.conn.commit()

def parseJobsubHistory():

  try: 
    outcome = subprocess.run(['/var/lib/wfs/run-jobsub-history'],
                             stdin   = subprocess.DEVNULL,
                             stderr  = subprocess.STDOUT,
                             stdout  = subprocess.PIPE,
                             timeout = 60
                            ) 
  except Exception as e:
    logLine("run-jobsub-history fails with error: " + str(e))
    return

  logLine(outcome.stdout.decode())
  
  for line in outcome.stdout.decode().splitlines():
    if '@jobsub' in line and 'wfs-generic-job' in line:
      jobsubID = line.split()[0]
      try:
        state = line.split()[6]
      except:
        state = 'X'

      try:
        wfs.db.cur.execute('UPDATE jobs '
                    'SET jobsub_state="%s" '
                    'WHERE jobsub_id="%s"'
                    % (state, jobsubID)
                   )

      except Exception as e:
        # But try to keep going
        logLine('Update jobs fails with: ' + str(e))

  # Commit whatever we found - no rush
  wfs.db.conn.commit()

def updateSiteCounts():

  try:
    wfs.db.cur.execute('UPDATE sites SET '
        'submitted_jobs='
        '(SELECT COUNT(*) FROM jobs WHERE '
         '(sites.site_id = jobs.site_id) AND '
         '(jobs.submitted_time > DATE_SUB(NOW(),INTERVAL 24 HOUR)) AND '
         '(allocation_state = "submitted")),'
        'running_jobs='
        '(SELECT COUNT(*) FROM jobs WHERE '
         'sites.site_id=jobs.site_id AND allocation_state '
         'IN ("started","processing","outputting"))')
  except Exception as e:
    logLine('Update site counts fails with: ' + str(e))
  else:
    wfs.db.conn.commit()
    logLine('Updated site job counts')
   
def submitJobs(numberToSubmit, 
               siteID,
               jobsubSiteName,
               minProcessors,
               maxProcessors,
               minRssBytes,
               maxRssBytes,
               maxWallSeconds,
               ignoreStr,
               forWtf = False):

  logLine('submitJobs %d %s %s %d-%d %d-%d %d %s' %
          (numberToSubmit,
           siteID,
           jobsubSiteName,
           minProcessors,
           maxProcessors,
           minRssBytes,
           maxRssBytes,
           maxWallSeconds,
           ignoreStr))

  try: 
    outcome = subprocess.run(
               ["/var/lib/wfs/run-jobsub-submit",
                str(numberToSubmit),
                jobsubSiteName,
                str(int(maxRssBytes / 1024)),
                str(maxProcessors),
                str(maxWallSeconds),
                ignoreStr
               ],
               stdin   = subprocess.DEVNULL,
               stderr  = subprocess.STDOUT,
               stdout  = subprocess.PIPE,
               timeout = 60
                            ) 
  except Exception as e:
    logLine("run-jobsub-submit fails with error: " + str(e))
    return

  logLine(outcome.stdout.decode())
  logLine('run-jobsub-submit exit code: ' + str(outcome.returncode))

  # Scrape the stdout to find the Jobsub job ID
  majorJobsubJobID = None
  jobsubHost       = None
  
  for line in outcome.stdout.decode().splitlines():
    if line.startswith('JobsubJobId of first job:'):
      try:
        jobsubJobID      = line.split()[4]
        majorJobsubJobID = jobsubJobID.split('.')[0]
        jobsubHost       = jobsubJobID.split('@')[1]
        break
      except:
        pass
   
  if not majorJobsubJobID or not jobsubHost:
    # What??
    logLine("Valid jobsub job ID not found after submitting job(s)!")
    return

  logLine("Submitted cluster %s to %s%s" % 
          (jobsubJobID, 
           jobsubSiteName,
           ' (WTF job)' if forWtf else ''))

  # Record the job(s) in the database
  for i in range(0, numberToSubmit):
    try:
      wfs.db.cur.execute('INSERT INTO jobs '
                  'SET factory_name="%s",'
                  'site_id=%d,'
                  'min_processors=%d,'
                  'max_processors=%d,'
                  'min_rss_bytes=%d,'
                  'max_rss_bytes=%d,'
                  'max_wall_seconds=%d,'
                  'submitted_time=NOW(),'
                  'need_to_fetch_jobsub_log=%s,'
                  'for_wtf=%s,'
                  'jobsub_id="%s.%d@%s"'
                  % (os.uname()[1],
                     siteID,
                     minProcessors,
                     maxProcessors,
                     minRssBytes,
                     maxRssBytes,
                     maxWallSeconds,
                     "TRUE" if i == 0 else "FALSE",
                     "TRUE" if forWtf else "FALSE",
                     majorJobsubJobID, i, jobsubHost)
                 )

    except Exception as e:
      # But try to keep going
      logLine('INSERT INTO jobs fails with: ' + str(e))

  # Record that we've done a submission for this site
  try:
    wfs.db.cur.execute('UPDATE sites SET last_submitted_time=NOW() '
                'WHERE site_id=%d' % siteID
               )

  except Exception as e:
    # But try to keep going
    logLine('Update last_submitted_time fails with: ' + str(e))

  # Commit it all to the DB
  wfs.db.conn.commit()

def recordUnallocatedCounts(unallocatedCounts):

  for processors in range(1, 9):
    for bytesPerProcessor in [2000 * 1024 * 1024, 4000 * 1024 * 1024]:
      
      try:
        matches = wfs.db.select('SELECT COUNT(*) AS count FROM files '
                                'LEFT JOIN requests '
                                'ON requests.request_id = files.request_id '
                                'LEFT JOIN stages '
                                'ON stages.request_id = files.request_id AND '
                                'stages.stage_id = files.stage_id '
                                'WHERE files.state = "unallocated" AND '
                                'requests.state="running" AND '
                                'stages.processors = %d AND '
                                'stages.rss_bytes > %d AND '
                                'stages.rss_bytes <= %d' %
                                (processors,
                                 bytesPerProcessor * (processors - 1),
                                 bytesPerProcessor * processors
                                ), justOne = True
                               )

        if matches['count']:
          unallocatedCounts.append((processors, 
                                    bytesPerProcessor,
                                    matches['count']
                                  ))
      except Exception as e:
        logLine('Failed getting count of unallocated: ' + str(e))
        continue

def anySiteJobs(unallocatedCounts, ignoreSites):

  for (processors, bytesPerProcessor, numberUnallocated) in unallocatedCounts:
    logLine('%d processor(s) %d MB: %d unallocated files' % 
            (processors, 
            int((bytesPerProcessor * processors) / (1024 * 1024)), 
            numberUnallocated))

    if numberUnallocated > jobsPerCluster:
      numberUnallocated = jobsPerCluster

    try:
        submitted = wfs.db.select('SELECT COUNT(*) AS count FROM jobs '
                                  'WHERE allocation_state = "submitted" AND '
                                  'processors = %d AND '
                                  'rss_bytes > %d AND '
                                  'rss_bytes <= %d' %
                                  (processors,
                                   bytesPerProcessor * (processors - 1),
                                   bytesPerProcessor * processors
                                  ), justOne = True
                                 )
        numberSubmitted = submitted['count']
    except Exception as e:
        logLine('Failed getting count of submitted jobs: ' + str(e))
        continue
            
    if numberUnallocated > numberSubmitted:    
      ignoreStr = ','.join(ignoreSites[(processors,bytesPerProcessor)])    
      if not ignoreStr:
        ignoreStr = ' '
      
      logLine('Submit jobs with blacklist: ' + ignoreStr)
      submitJobs(numberToSubmit = numberUnallocated - numberSubmitted,
                     siteID         = 0,
                     jobsubSiteName = 'ANY',
                     minProcessors  = processors - 1,
                     maxProcessors  = processors,
                     minRssBytes    = bytesPerProcessor * (processors - 1),
                     maxRssBytes    = bytesPerProcessor * processors,
                     maxWallSeconds = 86400,
                     ignoreStr      = ignoreStr,
                     forWtf         = False)
        
      

def perSiteJobs():  
  # Go through the sites deciding what to submit for that site

  try:
    siteRows = wfs.db.select('SELECT sites.site_id,'
      'site_name,'
      'jobsub_site_name,'
      'max_rss_bytes,'
      'max_processors,'
      'max_wall_seconds,'
      'submitted_jobs,'
      'running_jobs,'
      'max_jobs '
      'FROM sites '
      'WHERE enabled AND '
      '(submitted_jobs + running_jobs < max_jobs) '
      'ORDER BY site_name'
               )

  except Exception as e:
    logLine('Failed getting list of sites for per-site jobs: ' + str(e))
    return
  
  for siteRow in siteRows:
    for processors in range(1, siteRow['max_processors'] + 1):

      jobDict = { "error_message"   : None,
                  "site_id"         : siteRow['site_id'],
                  "site_name"       : siteRow['site_name'],
                  "min_processors"  : processors - 1,
                  "max_processors"  : processors,
                  "min_rss_bytes"   : int(((processors - 1) * 
                                       siteRow['max_rss_bytes'])
                                       / siteRow['max_processors']),
                  "max_rss_bytes"   : int((processors * 
                                       siteRow['max_rss_bytes'])
                                       / siteRow['max_processors']),
                  "max_wall_seconds": siteRow['max_wall_seconds']
                }
                      
      try:
        print(jobDict)
        stage = wfs.allocator.findStage(jobDict, 
                                        limit = jobsPerCluster,
                                        forUpdate = False)
        print(stage)
      except Exception as e:
        logLine('Update findStage fails with: ' + str(e))
        stage = None
   
      if stage:
        logLine('Matches found - submit %d job(s)' % stage['matches'])
        submitJobs(  numberToSubmit = stage['matches'],
                     siteID         = siteRow['site_id'],
                     jobsubSiteName = siteRow['jobsub_site_name'],
                     minProcessors  = jobDict['min_processors'],
                     maxProcessors  = jobDict['max_processors'],
                     minRssBytes    = jobDict['min_rss_bytes'],
                     maxRssBytes    = jobDict['max_rss_bytes'],
                     maxWallSeconds = jobDict['max_wall_seconds'],
                     ignoreStr      = ' ',
                     forWtf         = False)

def cacheFindFileResults(siteID, requestID, stageID, maxDistance):
  # Cache best replicas info for the best stage for a site, relative
  # to that site

  try:
    replicaRows = wfs.db.select('SELECT replica_id,'
                   'replicas.rse_id,'
                   'files.file_id,'
                   'distance '
                   'FROM files '
                   'LEFT JOIN replicas ON files.file_id=replicas.file_id '
                   'LEFT JOIN storages ON replicas.rse_id=storages.rse_id '
                   'LEFT JOIN sites_storages ON '
                   'replicas.rse_id=sites_storages.rse_id AND '
                   'sites_storages.site_id=%d '
                   'WHERE request_id=%d AND stage_id=%d AND '
                   'files.state="unallocated" AND '
                   'distance<=%f AND '
                   'accessible_until > NOW() '
                   'ORDER by distance,files.file_id LIMIT 500' % 
                   (siteID, requestID, stageID, maxDistance))
  except Exception as e:
    logLine('Failed getting replica info to cache: %s' % str(e))
    return

  #Â Go through the replicas, caching them
  for replicaRow in replicaRows:
    logLine('Replica %d for %d,%d' % 
            (replicaRow['replica_id'], 
             requestID,
             stageID))
    try:
      wfs.db.insertUpdate('INSERT INTO find_file_cache SET '
                          'site_id=%d,'
                          'request_id=%d,'
                          'stage_id=%d,'
                          'distance=%f,'
                          'file_id=%d,'
                          'rse_id=%d,'
                          'replica_id=%d,'
                          'cache_time=NOW()' %
                          (siteID,
                           requestID,
                           stageID,
                           replicaRow['distance'],
                           replicaRow['file_id'],
                           replicaRow['rse_id'],
                           replicaRow['replica_id']
                          )
                         )
    except Exception as e:
      logLine('Failed caching replica info: %s' % str(e))
      continue

def cacheFindStageResults(unallocatedCounts, ignoreSites):
  # Go through the sites recording what findStage() returns

  # We use this time to remove previous cache entries
  cutoffTime = int(time.time())

  try:
    siteRows = wfs.db.select('SELECT site_id,site_name,'
                             'enabled,jobsub_site_name '
                             'FROM sites ORDER by site_name')
  except Exception as e:
    logLine('Failed getting list of sites for get_stage_cache: ' + str(e))
    return
  
  for (processors,bytesPerProcessor,numberUnallocated) in unallocatedCounts:   
    ignoreSites[(processors,bytesPerProcessor)] = []
    
    for siteRow in siteRows:

      if siteRow['enabled']:
        jobDict = { "error_message"   : None,
                  "site_id"         : siteRow['site_id'],
                  "site_name"       : siteRow['site_name'],
                  "min_processors"  : processors - 1,
                  "max_processors"  : processors,
                  "min_rss_bytes"   : bytesPerProcessor * (processors - 1),
                  "max_rss_bytes"   : bytesPerProcessor * processors,
                  "max_wall_seconds": 86400
                }
                      
        try:
          print(jobDict)
          stage = wfs.allocator.findStage(jobDict, 
                                          limit = 1,
                                          forUpdate = False)
          print(stage)
        except Exception as e:
          logLine('Update findStage fails with: ' + str(e))
          stage = None
      else:
        stage = None
   
      if not stage:
        requestID = 0
        stageID   = 0
        ignoreSites[(processors,bytesPerProcessor)].append(
                                                siteRow['jobsub_site_name'])
      else:
        requestID   = stage['request_id']
        stageID     = stage['stage_id']
        maxDistance = stage['max_distance']
        logLine('Match(es) found (%d,%d) for site %s - caching' % 
                (requestID, stageID, siteRow['site_name']))

        try:
          wfs.db.insertUpdate('INSERT INTO get_stage_cache SET '
                              'site_id=%d,'
                              'min_processors=%d,'
                              'max_processors=%d,'
                              'min_rss_bytes=%d,'
                              'max_rss_bytes=%d,'
                              'max_wall_seconds=%d,'
                              'request_id=%d,'
                              'stage_id=%d,'
                              'cache_time=NOW() '
                              'ON DUPLICATE KEY UPDATE ' 
                              'request_id=%d,'
                              'stage_id=%d,'
                              'cache_time=NOW() ' % 
                              (jobDict['site_id'],
                               jobDict['min_processors'],
                               jobDict['max_processors'],
                               jobDict['min_rss_bytes'],
                               jobDict['max_rss_bytes'],
                               jobDict['max_wall_seconds'],
                               requestID,
                               stageID,
                               requestID,
                               stageID
                              )
                             )

        except Exception as e:
          logLine('Record  fails with: ' + str(e))

        cacheFindFileResults(jobDict['site_id'], 
                             requestID, 
                             stageID, 
                             maxDistance)
   
  try:
    wfs.db.insertUpdate('DELETE FROM get_stage_cache '
                        'WHERE UNIX_TIMESTAMP(cache_time) < %d' % cutoffTime)
  except Exception as e:
    logLine('Delete previous get_stage_cache entries fails with: ' + str(e))

  try:
    wfs.db.insertUpdate('DELETE FROM find_file_cache '
                        'WHERE UNIX_TIMESTAMP(cache_time) < %d' % cutoffTime)
  except Exception as e:
    logLine('Delete previous find_file_cache entries fails with: ' + str(e))

  # Commit what we did    
  wfs.db.conn.commit()

def wtfJobsToSites():
  # Go through the sites deciding where to submit WTF jobs

  try:
    rows = wfs.db.select('SELECT site_id,'
      'site_name,'
      'jobsub_site_name '
      'FROM sites '
      'WHERE '
      '(SELECT COUNT(*) FROM jobs WHERE'
      ' jobs.site_id=sites.site_id AND for_wtf AND'
      ' submitted_time > DATE_SUB(NOW(),INTERVAL 12 HOUR)) = 0 '
      'ORDER BY site_name'
      # Should change this to random order?
               )

  except Exception as e:
    logLine('Failed getting list of sites for WTF jobs: ' + str(e))
    return
  
  for row in rows:
      submitJobs(numberToSubmit = 1,
                 siteID         = row['site_id'],
                 jobsubSiteName = row['jobsub_site_name'],
                 minProcessors  = 0,
                 maxProcessors  = 1,
                 minRssBytes    = 0,
                 maxRssBytes    = 1024 * 1024 * 1024,
                 maxWallSeconds = 3600,
                 ignoreStr      = ' ',
                 forWtf         = True)
    
def oneCycle():
  # Update the database with the states of submitted jobsub jobs

#  parseJobsubQ()
#  parseJobsubHistory()
  updateSiteCounts()

  wtfJobsToSites()
#  perSiteJobs()

  unallocatedCounts = []
  recordUnallocatedCounts(unallocatedCounts)

  ignoreSites = {}
  cacheFindStageResults(unallocatedCounts, ignoreSites)
  anySiteJobs(unallocatedCounts, ignoreSites)

#
# PROGRAM MAIN
#

if __name__ == '__main__':

  if (os.fork() != 0):
    sys.exit() # first parent

  else:
    os.chdir("/")
    os.setsid()
    os.umask(0)

    if os.fork() != 0:
      sys.exit() # second parent

    else:

      try:
        os.makedirs('/var/run/wfs',         
                    stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | 
                    stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
      except:
        pass
        
      try:
        f = open('/var/run/wfs/job-factory.pid', 'w')
        f.write(str(os.getpid()) + '\n')
        f.close()
      except:
        print('Failed to create /var/run/wfs/job-factory.pid - exiting')
        sys.exit(1)

      # Close stdin now
      si = open('/dev/null', 'r')
      os.dup2(si.fileno(), sys.stdin.fileno())

      while True:

        # Ensure /var/log/wfs directory exists
        try:
          os.makedirs('/var/log/wfs', 
                      stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR|stat.S_IRGRP|stat.S_IXGRP|stat.S_IROTH|stat.S_IXOTH)
        except:
          pass

        # Close and reopen stdout->log file, in case of logrotate
        try:
          close(so)
        except:
          pass

        so = open('/var/log/wfs/job-factory', 'a+')
        os.dup2(so.fileno(), sys.stdout.fileno())

        # Close and reopen stderr->log file, in case of logrotate
        try:
          close(se)
        except:
          pass
          
        se = open('/var/log/wfs/job-factory', 'a+')
        os.dup2(se.fileno(), sys.stderr.fileno())

        try:
          pf = open('/var/run/wfs/job-factory.pid', 'r')
          pid = int(pf.read().strip())
          pf.close()

          if pid != os.getpid():
            print('new /var/run/wfs/job-factory.pid - exiting')
            break

        except:
          print('no /var/run/wfs/job-factory.pid - exiting')
          break

        # Fork a subprocess to run each cycle
        cyclePid = os.fork()

        if cyclePid == 0:
          logLine('=============== Start cycle ===============')
          
          wfs.conf.readConf()
          
          try:
            wfs.db.conn = MySQLdb.connect(host=wfs.conf.mysqlHostname, 
                                  user=wfs.conf.mysqlUsername,
                                  passwd=wfs.conf.mysqlPassword, 
                                  db=wfs.conf.mysqlDbName)
            wfs.db.conn.autocommit(False)
            wfs.db.cur = wfs.db.conn.cursor(MySQLdb.cursors.DictCursor)
          except Exception as e:
            logLine('Failed to create database connection (' + str(e) + ') - skipping cycle')
          else:
            try:
              oneCycle()
            except Exception as e:
              print('Cycle fails with exception ' + str(e))

          logLine('================ End cycle ================')
          sys.exit(0)

        # wait for cyclePid subprocess to finish
        os.waitpid(cyclePid, 0)

        # wait the allotted time between cycles
        time.sleep(sleepSeconds)

      sys.exit(0) # if we break out of the while loop then we exit

