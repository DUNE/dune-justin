#!/usr/bin/python3
#
#  wfa-cgi - Workflow Allocator CGI service
#
#  Andrew McNab, University of Manchester.
#  Copyright (c) 2013-21. All rights reserved.
#
#  Redistribution and use in source and binary forms, with or
#  without modification, are permitted provided that the following
#  conditions are met:
#
#    o Redistributions of source code must retain the above
#      copyright notice, this list of conditions and the following
#      disclaimer. 
#    o Redistributions in binary form must reproduce the above
#      copyright notice, this list of conditions and the following
#      disclaimer in the documentation and/or other materials
#      provided with the distribution. 
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
#  CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
#  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
#  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
#  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
#  EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
#  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
#  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
#  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.
#

import os
import re
import sys
import time
import json
import uuid
import string
import MySQLdb

# wfs/conf.py must define these variables:
#
# mysqlUser     = 'username'
# mysqlPassword = 'PAsSWoRd'
#
import wfs.conf

# Global database connection and ID, usable anywhere
db          = None
allocatorID = None

# Return various SQL terms where are used in subsequent queries
# by allocateMethod()
def makeStorageQueryTerms(jsonDict, duneSite):

  cur = db.cursor(MySQLdb.cursors.DictCursor)

  # duneSite is checked for bad characters earlier
  # which prevents SQL injection attacks
  cur.execute('SELECT rse_id,location FROM sites_storages '
              'WHERE site_name="%s";' % duneSite)

  storageRows = cur.fetchall()
 
  samesiteList   = []
  nearbyList     = []
  accessibleList = []

  for storageRow in storageRows:
    if storageRow['location'] == 'accessible':
      accessibleList.append('replicas.rse_id=%s' % storageRow['rse_id'])
    elif storageRow['location'] == 'nearby':
      nearbyList.append('replicas.rse_id=%s' % storageRow['rse_id'])
    elif storageRow['location'] == 'samesite':
      samesiteList.append('replicas.rse_id=%s' % storageRow['rse_id'])

  storageWhere = ' OR '.join(samesiteList + nearbyList)

  if accessibleList:
    if storageWhere:
      storageWhere += ' OR '

    storageWhere += ('(stages.any_location AND (' + 
                     ' OR '.join(accessibleList) + '))')

  if storageWhere:
    storageWhere = ' AND ' + storageWhere
 
  if samesiteList:
    storageOrder = '3*(' + ' OR '.join(samesiteList) + ')'
  else:
    storageOrder = ''

  if nearbyList:
    if storageOrder:
      storageOrder += ' OR '
  
    storageOrder += '2*(' + ' OR '.join(nearbyList) + ')'

  if accessibleList:
    if storageOrder:
      storageOrder += ' OR '

    storageOrder += '1*(' + ' OR '.join(accessibleList) + ')'

  # If we got anything for the storage ordering then complete the
  # expression including the comma; otherwise an empty string
  if storageOrder:
    storageOrder += ' DESC,'

  return { "samesiteList"   : samesiteList,
           "nearbyList"     : nearbyList,
           "accessibleList" : accessibleList,
           "storageWhere"   : storageWhere,
           "storageOrder"   : storageOrder 
         }

# Just In Time decision maming: identify the best request/stage combinations
# based on the immediate situation rather than trying to plan ahead
def candidateStagesQuery(storageQueryTerms):

  cur = db.cursor(MySQLdb.cursors.DictCursor)

  cur.execute(
 "SELECT stages.request_id,stages.stage_id,"
 "stages.min_inputs,stages.max_inputs,stages.any_location FROM files "
 "LEFT JOIN stages ON files.request_id=stages.request_id AND "
 "files.stage_id=stages.stage_id "
 "LEFT JOIN replicas ON files.file_id=replicas.file_id "
 "LEFT JOIN storages ON replicas.rse_id=storages.rse_id "
 "WHERE files.state='unallocated' " + 
 storageQueryTerms["storageWhere"] + 
 " ORDER BY " + 
 storageQueryTerms["storageOrder"] + "files.request_id,files.file_id"
 " LIMIT 100;"
 )
    
  requestStageRows = cur.fetchall()

  print(requestStageRows,file=sys.stderr)

  requestsStagesList = []
  requestsStagesDict = {}

  for requestStageRow in requestStageRows:

      print(requestStageRow, file=sys.stderr)
   
      requestID   = int(requestStageRow['request_id'])
      stageID     = int(requestStageRow['stage_id'])
      minInputs   = int(requestStageRow['min_inputs'])
      maxInputs   = int(requestStageRow['max_inputs'])
      anyLocation = requestStageRow['any_location']

      # Only add combinations not already present
      if (requestID,stageID) not in requestsStagesList:
        requestsStagesList.append((requestID,stageID))
        requestsStagesDict[(requestID, stageID)] = {
                                                     "min_inputs"  : minInputs,
                                                     "max_inputs"  : maxInputs,
                                                     "any_location": anyLocation
                                                   }
        
      # Stop after we have accumulated 10
      if len(requestsStagesList) >= 10:
        break

  return { "list": requestsStagesList,
           "dict": requestsStagesDict 
         }

# Traditional SAM mode: with a hardcoded request/stage in the job
def candidateStagesGiven(jsonDict, requestID):
  
  try:
    stageID = int(jsonDict[stage_id])
  except:
    stageID = 1
      
  try:
    minInputs = int(jsonDict["min_inputs"])
  except:
    minInputs = 1
      
  try:
    maxInputs = int(jsonDict["max_inputs"])
  except:
    maxInputs = 1
            
  try:
    anyLocation = bool(jsonDict["any_location"])
  except:
    anyLocation = False
            
  requestsStagesList = [ (requestID, stageID) ]
  requestsStagesDict = { (requestID, stageID): 
                            { "min_inputs" : minInputs,
                              "max_inputs" : maxInputs,
                              "anyLocation": anyLocation
                            }
                       }
                      
  return { "list": requestStagesList,
           "dict": requestStagesDict 
         }

# Try to make a long enough list of files from this request/stage
# and then update their status to allocated in the files table
def makeAllocatedFiles(cookie, storageQueryTerms, requestID, stageID,
                       executorID,
                       minInputs, maxInputs, anyLocation):
 
  curSelect = db.cursor(MySQLdb.cursors.DictCursor)
  curUpdate = db.cursor(MySQLdb.cursors.DictCursor)

  if anyLocation:
    # If this stage can access data on any accessible storage, then 
    # use all three lists
    storageWhere = ' OR '.join(storageQueryTerms["samesiteList"] + 
                               storageQueryTerms["nearbyList"] + 
                               storageQueryTerms["accessibleList"])
  else:
    # Otherwise just use samesite and nearby lists of storages
    storageWhere = ' OR '.join(storageQueryTerms["samesiteList"] + 
                               storageQueryTerms["nearbyList"])


  # Get an ordered list of unallocated files in this stage with replicas
  # on suitable storages. Use pre_allocations table to prevent races between
  # allocator instances. Transactions might be better for this instead, 
  # but this is more portable for now and will probably deal with high load
  # better since it can tolerate similar queries without blocking
  curSelect.execute(
 "SELECT files.file_id,files.file_did,pre_allocations.file_id,storages.rse_name "
 "FROM files "
 "LEFT JOIN replicas ON files.file_id=replicas.file_id "
 "LEFT JOIN pre_allocations ON files.file_id=pre_allocations.file_id "
 "LEFT JOIN storages ON replicas.rse_id=storages.rse_id "
 "WHERE files.state='unallocated' AND files.request_id=" +
 str(requestID) + " AND files.stage_id=" + str(stageID) + 
 storageWhere + " AND pre_allocations.file_id IS NULL " + 
 " ORDER BY " + 
 storageQueryTerms["storageOrder"] + "files.file_id"
 " LIMIT 100;"
 )
    
  preAllocatedFiles = []
  fileRows = curSelect.fetchall()
  
  # Go through the candidate files for this stage trying to pre-allocate them
  # This prevents them being returned in queries by other allocator instances
  # and INSERT fails if they have been pre-allocated elsewhere
  # Pre-allocations are timestamped and should only last while this query
  # from the executor is processed: can be cleaned up periodically where the
  # allocator instance failed for some reason.
  for fileRow in fileRows:

    try:
      curUpdate.execute(
       "INSERT INTO pre_allocations SET request_id=%d,stage_id=%d,"
       "file_id=%s,created=NOW(),allocator_id='%s'" % 
       (requestID, stageID, fileRow['file_id'], allocatorID))
       
      db.commit()
    except MySQLdb.IntegrityError:
      # This file is already pre-allocated - try next one
      continue

    # Each file we successfully pre-allocate is added to the ordered list
    preAllocatedFiles.append({"file_id" : int(fileRow['file_id']),
                              "file_did": fileRow['file_did'],
                              "rse_name": fileRow['rse_name']
                             })

    # Stop if we have already reached the maximum number of input files
    # in this stage's definition
    if len(preAllocatedFiles) >= maxInputs:
      break
    
  # After the loop, how did we do?
  if len(preAllocatedFiles) < minInputs:
    # Oh dear. This means too few files for this stage available so we cannot
    # allocate any files from this request/stage to process

    # Record that it didn't work out for this request/stage
    preAllocatedFiles = []

  # Update the pre-allocated files' statuses to allocated in files table 
  # and record them 
  allocatedFiles = []

  for fileDict in preAllocatedFiles:
    try: 
      curUpdate.execute("UPDATE files SET state='allocated',"
                        "cookie='" + cookie + "',"
                        "allocator_id='" + allocatorID + "',"
                        "executor_id='" + executorID + "' "
                        "WHERE file_id=" + str(fileDict['file_id']))
      db.commit()
    except:
      # If anything goes wrong, we don't add the file to the final list
      pass
    else:
      # We only include values we will return to the executor
      # So that means we miss out file_id in particular
      # rse_name is a just hint and the executor should use RUCIO to get the
      # best replica and its transfer URL etc to use
      allocatedFiles.append({"file_did": fileDict['file_did'],
                             "rse_name": fileDict['rse_name']
                            })
      
  # Whatever happens, tidy up our pre-allocations
  try:
    curUpdate.execute("DELETE FROM pre_allocations WHERE allocator_id='" + 
                      allocatorID + "'")
    db.commit()
  except:
    # No harm done. Cleanup agent will get them anyway.
    pass

  # Return the list of files for this request/stage or an empty list
  return allocatedFiles

# Successfully identified the request/stage and files so get the 
# bootstrap template for this stage and convert it
def sendBootstrap(cookie, requestID, stageID, allocatedFiles):

  cur = db.cursor(MySQLdb.cursors.DictCursor)

  try:
    cur.execute("SELECT bootstrap FROM bootstraps "
                "WHERE request_id=%d AND stage_id=%s" % (requestID, stageID))

    rows = cur.fetchall()
    script = rows[0]['bootstrap']
  except:
    print('Status: 500 Internal Server Error')
    print()
    print('Failed to get bootstrap template')
    sys.exit(0)

  # Transform template to script by replacing patterns
  fileDID    = ''
  fileDIDRse = ''
  for fileDict in allocatedFiles:
    fileDID    += fileDict['file_did'] + '\n'
    fileDIDRse += fileDict['file_did'] + ' ' + fileDict['rse_name'] + '\n'
    
  script = script.replace('##wfa_cookie##',         cookie)
  script = script.replace('##wfa_files_did##',      fileDID)
  script = script.replace('##wfa_files_did_rse##',  fileDIDRse)
  script = script.replace('##wfa_files_json##',     json.dumps(allocatedFiles))
  script = script.replace('##wfa_request_id##',     str(requestID))
  script = script.replace('##wfa_stage_id##',       str(stageID))

  # Remove any unused patterns from the template
  script = re.sub('##wfa_[a-z,0-9,_]*##', '', script)

  # Return the script to the workflow executor 
  print('Status: 200 OK')
  print('Content-Length: %d' % (len(script) + 1))
  print('Content-Type: text/plain')
  print()
  print(script)

# Try to get the bootstrap script for the highest priority 
# files/stage/request combination
def allocateMethod(jsonDict):

  # Check jsonDict contains required values (eg dunesite)
  for name in ['dunesite', 'executor_id']:
    if name not in jsonDict:
      print('Status: 400 Bad Request')
      print()
      print('Missing value(s) in JSON')
      sys.exit(0)

  # Require that dunesite only contains A-Z a-z 0-9 - and _ 
  if (set(string.ascii_letters + string.digits + '-' + '_') <= 
       set(str(jsonDict['dunesite']))):
    print('Status: 400 Bad Request')
    print()
    print('Invalid dunesite in JSON')
    sys.exit(0)
  else:
    duneSite = str(jsonDict['dunesite'])

  # Make a sanitised string which identifies the executor
  executorID = re.sub('["\']', '_', str(jsonDict['executor_id']).lower())

  # Make strings used in SQL queries
  storageQueryTerms = makeStorageQueryTerms(jsonDict, duneSite)

  # Make a cookie which is given to the executor and must be used when
  # reporting the results of processing the input files
  cookie = str(uuid.uuid4())

  try:
    requestID = int(jsonDict[request_id])
  except:
    # request_id not given so use Just In Time decision making: identify the 
    # best request/stage candidate combinations at this moment
    candidateStages = candidateStagesQuery(storageQueryTerms)
  else:
    # Traditional SAM mode: put the hardcoded request_id/stage_id from the
    # job into the candidates list and dictionary
    candidateStages = candidateStagesGiven(jsonDict, requestID)

  # However we have arrived at the list of requests/stages, go 
  # through them, looking for enough files
  for (requestID,stageID) in candidateStages['list']:
    
    allocatedFiles = makeAllocatedFiles(cookie, 
                                        storageQueryTerms, 
                                        requestID, 
                                        stageID,
                                        executorID,
               candidateStages['dict'][(requestID,stageID)]['min_inputs'],
               candidateStages['dict'][(requestID,stageID)]['max_inputs'],
               candidateStages['dict'][(requestID,stageID)]['any_location'])
                       
    if allocatedFiles:
      sendBootstrap(cookie, requestID, stageID, allocatedFiles)
      sys.exit(0)

  # No files eligible to be processed by this executor
  print('Status: 404 Not Found')
  print('Content-Type: text/plain')
  print()
  print('No eligible files found')
  sys.exit(0)
   
    
def resultsMethod(jsonDict):

  # Check jsonDict contains required values (eg executor_id)
  for name in ['cookie', 'executor_id', 'request_id', 'stage_id', 
               'file_did', 'output_did']:
    if name not in jsonDict:
      print('Status: 400 Bad Request')
      print()
      print('Missing value(s) in JSON')
      sys.exit(0)

  cookie = re.sub('[^a-z,A-Z,0-9,.,_,-]', '', str(jsonDict['cookie']))
  
  # Make a sanitised string which identifies the executor
  executorID = re.sub('["\']', '_', str(jsonDict['executor_id']).lower())

  # Make a sanitised string which identifies the executor
  fileDID = str(jsonDict['file_did'])
  if '"' in fileDID or "'" in fileDID:
    print('Status: 400 Bad Request')
    print()
    print('Illegal quote characters in file_did')
    sys.exit(0)

  # Must give an integer request_id
  try: 
    requestID = int(jsonDict['request_id'])
  except:
    print('Status: 400 Bad Request') 
    print()
    print('Badly formed request_id in JSON')
    sys.exit(0)
  
  # Try to get a stage_id but default to 1 if not given
  try: 
    stageID = int(jsonDict['stage_id'])
  except:
    stageID = 1

  try:
    outputDID = str(jsonDict['output_did'])
  except:
    outputDID = ''
  else:
    if '"' in outputDID or "'" in outputDID:
      outputDID = ''

  # Executor must provide a valid DID for the output file
  if not outputDID:
    print('Status: 400 Bad Request') 
    print()
    print('No valid output file DID provided')
    sys.exit(0)

  cur = db.cursor(MySQLdb.cursors.DictCursor)

  try:
    cur.execute('UPDATE files SET state="processed" '
                'WHERE file_did="%s" AND cookie="%s" AND state="allocated"'
                % (fileDID, cookie))
    db.commit()
  except:
    print('Status: 500 Internal Server Error') 
    print()
    print('Error updating file state')
    sys.exit(0)

  if 'metadata' in jsonDict:
    try:
      # Just put the whole metadata into the queue as raw JSON for now
      cur.execute("INSERT INTO metadata_queue SET queue_time=NOW(),"
                  "file_did='" + outputDID + "',"
                  "request_id=" + str(requestID) + ","
                  "stage_id=" + str(stageID) + ","
                  "metadata='" + json.dumps(jsonDict['metadata']) + "',"
                  "executor_id='" + executorID + "'")
      db.commit()
    except:
      # WE SHOULD WARN THE EXECUTOR IF THIS GOES WRONG
      pass
  
  # ALSO NEED TO ADD FILE FOR NEXT STAGE IF THERE IS ONE

  # Return OK to the workflow executor
  print('Status: 200 OK')
  print('Content-Type: text/plain')
  print()
  sys.exit(0)

#
# PROGRAM MAIN
#

# Quickly reject random GETs etc (if not hanlded by Apache already)
if os.environ['REQUEST_METHOD'] != 'POST':
    print('Status: 405 Method not allowed')
    print()
    print('We only support POST')
    sys.exit(0)

# Create a unique ID string for this instance that may also help in debugging
allocatorID = "%s:%d:%f" % (os.uname()[1], os.getpid(), time.time())

# In future, this will be the DN of the Generic Job Factory
testDN = 'CN=UID:amcnab,CN=Andrew McNab,OU=People,O=Fermi National Accelerator Laboratory,C=US,DC=cilogon,DC=org'
#WE NEED TO TRANSFORM THIS TO ../CN=.. OR OTHERWISE HANDLE PROXY MATCHING
if 'SSL_CLIENT_S_DN' not in os.environ or not os.environ['SSL_CLIENT_S_DN'] or \
  (os.environ['SSL_CLIENT_S_DN'] != testDN and \
   not os.environ['SSL_CLIENT_S_DN'].startswith(testDN + '/CN=')):
    # Unless we found a matching DN then refuse
    print('Status: 403 Forbidden')
    print()
    print('Forbidden - acceptable identity not provided')
    sys.exit(0)

# Get the JSON document POSTed to us
try:
  jsonDict = json.load(sys.stdin)
except:
  print('Status: 400 Bad Request')
  print()
  print('Failed to parse JSON')
  sys.exit(0)

# Check jsonDict specifies a method
if 'method' not in jsonDict:
  print('Status: 400 Bad Request')
  print()
  print('Missing method in JSON')
  sys.exit(0)

# Do as many checks as we can before connecting to the database here
try:
  db  = MySQLdb.connect(host="localhost", user=wfs.conf.mysqlUser, 
                        passwd=wfs.conf.mysqlPassword, db='wfs')
except:
  print('Status: 500 Internal Server Error')
  print()
  print('Problem with database connection')
  sys.exit(0)

if jsonDict['method'] == 'allocate':
  allocateMethod(jsonDict)
  
elif jsonDict['method'] == 'results':
  resultsMethod(jsonDict)

else:
  print('Status: 400 Bad Request')
  print()
  print('Method in JSON not recognised')
  sys.exit(0)

